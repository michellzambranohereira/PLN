{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Clasificación de Sentimientos con una Red Neuronal Multicapa (MLP)\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "En esta actividad vas a construir una red neuronal feedforward multicapa (MLP) usando PyTorch. El objetivo es entrenarla para que pueda clasificar frases en español como positivas o negativas.\n",
    "\n",
    "### Con esto vas a:\n",
    "\n",
    "- Comprender cómo se construye una red con múltiples capas y neuronas\n",
    "- Usar funciones de activación no lineales (ReLU, Sigmoid)\n",
    "- Implementar entrenamiento automático con optimizadores modernos\n",
    "- Observar cómo una MLP mejora respecto al perceptrón simple del laboratorio anterior\n",
    "\n",
    "### ¿Qué es una red neuronal multicapa?\n",
    "\n",
    "A diferencia del perceptrón simple (una sola neurona), una MLP tiene:\n",
    "- **Capa de entrada**: Recibe los features del texto\n",
    "- **Capas ocultas**: Una o más capas intermedias que aprenden representaciones complejas\n",
    "- **Capa de salida**: Produce la predicción final\n",
    "\n",
    "Las capas ocultas permiten aprender patrones **no lineales**, lo que le da mucha más capacidad expresiva al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Preparación del entorno\n",
    "\n",
    "Importamos PyTorch y NumPy para comenzar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch versión: {torch.__version__}\")\n",
    "print(f\"Device disponible: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Datos de entrenamiento\n",
    "\n",
    "Usamos un conjunto más grande de frases típicas de opiniones escritas en Argentina, etiquetadas como positivas (1) o negativas (0).\n",
    "\n",
    "Vamos a incluir casos más variados y complejos que en el laboratorio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    \"La verdad, este lugar está bárbaro. Muy recomendable\",\n",
    "    \"Una porquería de servicio, nunca más vuelvo\",\n",
    "    \"Me encantó la comida, aunque la música estaba muy fuerte\",\n",
    "    \"El envío fue lento y el producto llegó dañado. Qué desastre\",\n",
    "    \"Todo excelente. Atención de diez\",\n",
    "    \"Qué estafa, me arrepiento de haber comprado\",\n",
    "    \"Muy conforme con el resultado final\",\n",
    "    \"No me gustó para nada la experiencia\",\n",
    "    \"Superó mis expectativas, gracias\",\n",
    "    \"No lo recomiendo, mala calidad\"\n",
    "]\n",
    "\n",
    "etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])  # 1 = Positivo, 0 = Negativo\n",
    "\n",
    "print(f\"Total de frases: {len(frases)}\")\n",
    "print(f\"Balance: {sum(etiquetas)} positivas, {len(etiquetas) - sum(etiquetas)} negativas\\n\")\n",
    "print(\"Ejemplos:\")\n",
    "for i in range(3):\n",
    "    sentimiento = \"Positivo\" if etiquetas[i] == 1 else \"Negativo\"\n",
    "    print(f\"  {i+1}. '{frases[i]}' → {sentimiento}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Construcción del vocabulario\n",
    "\n",
    "Definimos manualmente un vocabulario con palabras que suelen aparecer en frases de opinión con carga positiva o negativa.\n",
    "\n",
    "En este caso expandimos el vocabulario para cubrir más términos comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = [\n",
    "    \"bárbaro\", \"recomendable\", \"porquería\", \"nunca\", \"encantó\",\n",
    "    \"fuerte\", \"desastre\", \"excelente\", \"estafa\", \"arrepiento\",\n",
    "    \"conforme\", \"gustó\", \"superó\", \"gracias\", \"recomiendo\", \"mala\"\n",
    "]\n",
    "\n",
    "print(f\"Vocabulario: {len(vocabulario)} palabras clave\")\n",
    "print(f\"\\nPalabras: {vocabulario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento: vectorización de las frases\n",
    "\n",
    "Seguimos usando bag-of-words como en el laboratorio anterior: cada frase se convierte en un vector binario que indica si contiene alguna de las palabras del vocabulario.\n",
    "\n",
    "Luego convertimos estos vectores a tensores de PyTorch para poder usarlos con redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizar(frase, vocabulario):\n",
    "    \"\"\"\n",
    "    Convierte una frase en un vector binario según el vocabulario.\n",
    "    \n",
    "    Args:\n",
    "        frase: String con la frase a vectorizar\n",
    "        vocabulario: Lista de palabras clave\n",
    "    \n",
    "    Returns:\n",
    "        Array de numpy con 1s y 0s (float32 para PyTorch)\n",
    "    \"\"\"\n",
    "    tokens = frase.lower().split()\n",
    "    return np.array([1 if palabra in tokens else 0 for palabra in vocabulario], dtype=np.float32)\n",
    "\n",
    "# Vectorizamos todas las frases\n",
    "X_np = np.array([vectorizar(frase, vocabulario) for frase in frases], dtype=np.float32)\n",
    "y_np = etiquetas.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Convertimos a tensores de PyTorch\n",
    "X = torch.tensor(X_np)\n",
    "y = torch.tensor(y_np)\n",
    "\n",
    "print(\"Datos preprocesados:\")\n",
    "print(f\"  X shape: {X.shape} (frases × features)\")\n",
    "print(f\"  y shape: {y.shape} (frases × 1)\")\n",
    "print(f\"\\nPrimera frase vectorizada: {X[0]}\")\n",
    "print(f\"Etiqueta: {y[0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 5. Definición del modelo MLP\n",
    "\n",
    "Vamos a crear un modelo simple con:\n",
    "- **Capa de entrada**: Tamaño = cantidad de palabras en el vocabulario\n",
    "- **Capa oculta**: 8 neuronas con activación ReLU\n",
    "- **Capa de salida**: 1 neurona con activación Sigmoid (para clasificación binaria)\n",
    "\n",
    "### ¿Por qué estas activaciones?\n",
    "\n",
    "- **ReLU** (Rectified Linear Unit): `f(x) = max(0, x)` → Introduce no linealidad, permite aprender patrones complejos\n",
    "- **Sigmoid**: `f(x) = 1 / (1 + e^(-x))` → Convierte la salida a un valor entre 0 y 1 (probabilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "###############################################################################\n# CONFIGURACIÓN DE LA ARQUITECTURA: DEFINICIÓN DE LA RED NEURONAL MULTICAPA\n###############################################################################\n\n# ¿Qué es input_size?\n# Es la dimensión de entrada de la red: cantidad de features que recibe.\n# En este caso = 16 (tamaño del vocabulario)\n# Cada frase se representa como un vector de 16 posiciones (bag-of-words)\ninput_size = len(vocabulario)\n\n# ¿Qué es hidden_size y por qué 8?\n# Es la cantidad de neuronas en la capa oculta.\n#\n# ¿Cómo elegir este número?\n# No hay una fórmula exacta, es un hiperparámetro que se ajusta experimentalmente.\n#\n# Reglas prácticas:\n# - Muy pequeño (ej: 2): La red no tiene capacidad para aprender patrones complejos\n# - Muy grande (ej: 1000): Riesgo de overfitting, especialmente con pocos datos\n# - Valor típico: Entre input_size/2 y input_size*2\n#\n# ¿Por qué 8 en este caso?\n# - Es la mitad del input_size (16/2 = 8)\n# - Suficiente para aprender patrones simples\n# - No es excesivo para nuestro dataset pequeño (10 ejemplos)\n#\n# Analogía: Es como el número de \"conceptos intermedios\" que la red puede aprender\n# Ej: Cada neurona oculta podría especializarse en detectar:\n#   - Neurona 1: Palabras muy positivas (excelente, encantó)\n#   - Neurona 2: Negaciones (no, nunca)\n#   - Neurona 3: Palabras negativas (porquería, desastre)\n#   - etc.\nhidden_size = 8\n\n###############################################################################\n# DEFINICIÓN DE LA CLASE DEL MODELO\n###############################################################################\n\nclass MLP(nn.Module):\n    \"\"\"\n    Red Neuronal Multicapa (Multi-Layer Perceptron)\n    \n    Arquitectura:\n    Input (16) → Hidden (8) con ReLU → Output (1) con Sigmoid\n    \n    ¿Por qué heredamos de nn.Module?\n    Es la clase base de PyTorch para todos los modelos.\n    Nos da funcionalidades automáticas como:\n    - Gestión de parámetros\n    - Mover el modelo a GPU\n    - Cambiar entre modo train/eval\n    - Serialización (guardar/cargar modelos)\n    \"\"\"\n    \n    def __init__(self):\n        super(MLP, self).__init__()\n        \n        # ¿Qué hace nn.Sequential?\n        # Encadena capas que se ejecutan en orden.\n        # Equivale a: salida = Sigmoid(Linear2(ReLU(Linear1(entrada))))\n        #\n        # Ventaja: Código más limpio y legible\n        # Alternativa: Definir cada capa por separado y llamarlas manualmente en forward()\n        self.net = nn.Sequential(\n            ###################################################################\n            # CAPA 1: Linear (Capa oculta)\n            ###################################################################\n            # nn.Linear(input_size, hidden_size) crea una transformación lineal:\n            # z = W·x + b\n            #\n            # Dimensiones:\n            # - W (pesos): matriz de 8×16 (hidden_size × input_size)\n            # - b (bias): vector de 8 valores\n            #\n            # ¿Cómo se inicializan estos parámetros?\n            # PyTorch usa inicialización Kaiming/He por defecto:\n            # - Pesos: distribución uniforme U(-k, k) donde k = sqrt(1/input_size)\n            # - Bias: también U(-k, k)\n            #\n            # ¿Por qué esta inicialización?\n            # - Evita que las activaciones exploten o se desvanezcan\n            # - Mantiene la varianza de las activaciones estable entre capas\n            #\n            # Parámetros totales en esta capa: (16 × 8) + 8 = 136\n            nn.Linear(input_size, hidden_size),\n            \n            ###################################################################\n            # ACTIVACIÓN 1: ReLU (Rectified Linear Unit)\n            ###################################################################\n            # ReLU(x) = max(0, x)\n            #\n            # ¿Qué hace?\n            # - Si x > 0: deja pasar el valor sin cambios\n            # - Si x ≤ 0: lo convierte en 0\n            #\n            # Ejemplo: ReLU([-2, 0, 3]) = [0, 0, 3]\n            #\n            # ¿Por qué ReLU y no otra función?\n            # Ventajas de ReLU:\n            # - Computacionalmente eficiente (solo una comparación)\n            # - No sufre de \"vanishing gradient\" como Sigmoid/Tanh\n            # - Introduce no linealidad (permite aprender patrones complejos)\n            # - Ha demostrado funcionar muy bien en la práctica\n            #\n            # Sin ReLU, la red sería equivalente a una regresión lineal\n            # (dos capas lineales seguidas = una sola capa lineal)\n            #\n            # Alternativas populares:\n            # - Leaky ReLU: f(x) = max(0.01x, x) (evita neuronas \"muertas\")\n            # - GELU: usada en Transformers modernos\n            # - Tanh: f(x) = (e^x - e^-x)/(e^x + e^-x)\n            nn.ReLU(),\n            \n            ###################################################################\n            # CAPA 2: Linear (Capa de salida)\n            ###################################################################\n            # Transforma de 8 dimensiones (hidden) a 1 dimensión (salida)\n            #\n            # Dimensiones:\n            # - W: matriz de 1×8\n            # - b: escalar (1 valor)\n            #\n            # Parámetros: (8 × 1) + 1 = 9\n            nn.Linear(hidden_size, 1),\n            \n            ###################################################################\n            # ACTIVACIÓN 2: Sigmoid\n            ###################################################################\n            # Sigmoid(x) = 1 / (1 + e^(-x))\n            #\n            # ¿Qué hace?\n            # Convierte cualquier número real a un valor entre 0 y 1\n            #\n            # Ejemplos:\n            # - Sigmoid(-10) ≈ 0.00005 (casi 0)\n            # - Sigmoid(0) = 0.5\n            # - Sigmoid(10) ≈ 0.99995 (casi 1)\n            #\n            # ¿Por qué Sigmoid en la salida?\n            # - Interpretamos la salida como probabilidad: P(clase positiva)\n            # - Rango [0, 1] es perfecto para clasificación binaria\n            # - Si salida ≥ 0.5 → predecimos clase 1 (positivo)\n            # - Si salida < 0.5 → predecimos clase 0 (negativo)\n            #\n            # ¿Por qué NO usamos ReLU acá?\n            # ReLU no está acotada superiormente: ReLU(100) = 100\n            # Necesitamos una salida entre 0 y 1 para interpretarla como probabilidad\n            #\n            # ¿Por qué NO usamos Softmax?\n            # Softmax se usa para clasificación multiclase (>2 clases)\n            # Para clasificación binaria, Sigmoid es más simple y eficiente\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        \"\"\"\n        Propagación hacia adelante (forward pass)\n        \n        ¿Qué hace esta función?\n        Define cómo fluyen los datos desde la entrada hasta la salida.\n        \n        Flujo:\n        1. x entra (batch_size × 16)\n        2. Primera Linear: (batch × 16) @ (16 × 8) + (8) = (batch × 8)\n        3. ReLU: aplica max(0, ·) elemento a elemento\n        4. Segunda Linear: (batch × 8) @ (8 × 1) + (1) = (batch × 1)\n        5. Sigmoid: convierte a probabilidades\n        \n        ¿Por qué se llama 'forward'?\n        En entrenamiento también hay un 'backward' pass (backpropagation)\n        donde se calculan gradientes en dirección opuesta.\n        \n        Args:\n            x: Tensor de entrada (batch_size × input_size)\n        \n        Returns:\n            Tensor de salida (batch_size × 1) con valores entre 0 y 1\n        \"\"\"\n        return self.net(x)\n\n# Creamos una instancia del modelo\nmodelo = MLP()\n\nprint(\"Arquitectura del modelo:\")\nprint(modelo)\n\n# ¿Cuántos parámetros entrenables tiene el modelo?\n# Capa 1: 16×8 + 8 = 136\n# Capa 2: 8×1 + 1 = 9\n# Total: 145 parámetros\n#\n# Comparación:\n# - Perceptrón simple: 16 + 1 = 17 parámetros\n# - Esta MLP: 145 parámetros (8.5 veces más capacidad)\nprint(f\"\\nParámetros totales: {sum(p.numel() for p in modelo.parameters())}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 6. Configuración del entrenamiento\n",
    "\n",
    "Necesitamos definir dos componentes clave:\n",
    "\n",
    "### Función de pérdida (Loss Function)\n",
    "\n",
    "Usamos **Binary Cross Entropy (BCE)**: mide qué tan diferentes son las predicciones del modelo de las etiquetas reales. El objetivo del entrenamiento es minimizar esta pérdida.\n",
    "\n",
    "Fórmula: `BCE = -[y·log(ŷ) + (1-y)·log(1-ŷ)]`\n",
    "\n",
    "### Optimizador\n",
    "\n",
    "Usamos **Adam**: un optimizador moderno que ajusta automáticamente la tasa de aprendizaje para cada parámetro. Es más eficiente que el ajuste manual que hicimos en el perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "###############################################################################\n# CONFIGURACIÓN DEL ENTRENAMIENTO: FUNCIÓN DE PÉRDIDA Y OPTIMIZADOR\n###############################################################################\n\n###############################################################################\n# FUNCIÓN DE PÉRDIDA: Binary Cross Entropy (BCE)\n###############################################################################\n# ¿Qué mide la función de pérdida?\n# Cuantifica qué tan \"equivocadas\" son las predicciones del modelo.\n#\n# BCE (Binary Cross Entropy):\n# Loss = -[y·log(ŷ) + (1-y)·log(1-ŷ)]\n#\n# Donde:\n# - y = etiqueta real (0 o 1)\n# - ŷ = predicción del modelo (entre 0 y 1)\n#\n# Ejemplo numérico:\n# Si y=1 (clase positiva real) y ŷ=0.9 (modelo muy confiado en positivo):\n#   BCE = -[1·log(0.9) + 0·log(0.1)]\n#   BCE = -log(0.9)\n#   BCE ≈ 0.105 (pérdida baja, predicción buena)\n#\n# Si y=1 (clase positiva real) y ŷ=0.1 (modelo predice negativo):\n#   BCE = -[1·log(0.1) + 0·log(0.9)]\n#   BCE = -log(0.1)\n#   BCE ≈ 2.303 (pérdida alta, predicción mala)\n#\n# ¿Por qué BCE y no otra función?\n# - Específicamente diseñada para clasificación binaria\n# - Penaliza más las predicciones muy confiadas pero incorrectas\n# - Tiene buenas propiedades matemáticas para optimización\n# - Es diferenciable (permite calcular gradientes)\n#\n# Alternativas:\n# - MSE (Mean Squared Error): (y - ŷ)²\n#   Funciona, pero BCE converge más rápido en clasificación\n# - Hinge Loss: Usada en SVMs\n# - Focal Loss: Variante de BCE para datasets desbalanceados\ncriterio = nn.BCELoss()\n\n###############################################################################\n# OPTIMIZADOR: Adam (Adaptive Moment Estimation)\n###############################################################################\n# ¿Qué hace un optimizador?\n# Actualiza los pesos de la red para minimizar la función de pérdida.\n#\n# Regla general: peso_nuevo = peso_viejo - learning_rate × gradiente\n#\n# ¿Por qué Adam?\n# Adam es uno de los optimizadores más populares porque:\n#\n# 1. Adaptive learning rate:\n#    Ajusta automáticamente la tasa de aprendizaje para cada parámetro\n#    - Parámetros con gradientes grandes → learning rate más pequeño\n#    - Parámetros con gradientes pequeños → learning rate más grande\n#\n# 2. Momentum:\n#    \"Recuerda\" las actualizaciones previas para acelerar el aprendizaje\n#    - Ayuda a escapar de mínimos locales\n#    - Suaviza el camino hacia la convergencia\n#\n# 3. Bias correction:\n#    Corrige el sesgo de las estimaciones al inicio del entrenamiento\n#\n# ¿Cómo funciona Adam internamente?\n# Mantiene dos \"memorias\":\n# - m (primer momento): promedio móvil de gradientes\n# - v (segundo momento): promedio móvil de gradientes al cuadrado\n#\n# Algoritmo simplificado:\n# 1. Calcular gradiente g = ∂Loss/∂peso\n# 2. Actualizar m = β₁·m + (1-β₁)·g\n# 3. Actualizar v = β₂·v + (1-β₂)·g²\n# 4. Corregir bias: m̂ = m/(1-β₁ᵗ), v̂ = v/(1-β₂ᵗ)\n# 5. Actualizar peso: w = w - lr·m̂/√(v̂ + ε)\n#\n# Valores por defecto en PyTorch:\n# - β₁ = 0.9 (decaimiento del primer momento)\n# - β₂ = 0.999 (decaimiento del segundo momento)\n# - ε = 1e-8 (para estabilidad numérica)\n#\n# modelo.parameters(): ¿Qué es esto?\n# Devuelve TODOS los parámetros entrenables del modelo:\n# - Pesos de la primera capa lineal (16×8)\n# - Bias de la primera capa lineal (8)\n# - Pesos de la segunda capa lineal (8×1)\n# - Bias de la segunda capa lineal (1)\n# Total: 145 parámetros que Adam va a optimizar\n\n# ¿Qué es el learning rate (lr) y por qué 0.01?\n# Es el tamaño del paso que damos en cada actualización de pesos.\n#\n# ¿Por qué 0.01?\n# - Es un valor por defecto razonable para Adam\n# - Más grande que el usado en el perceptrón (0.1) porque Adam es más estable\n# - Valores típicos para Adam: entre 0.001 y 0.01\n#\n# ¿Qué pasa si cambio el learning rate?\n# - lr muy grande (ej: 0.1): Puede diverger, la pérdida sube en lugar de bajar\n# - lr muy pequeño (ej: 0.0001): Aprendizaje muy lento, necesita muchas épocas\n# - lr óptimo: Depende del problema, se encuentra experimentando\n#\n# Comparación con perceptrón:\n# - Perceptrón: Ajuste manual, tasa fija 0.1\n# - MLP con Adam: Ajuste automático, tasa adaptativa basada en 0.01\noptimizador = optim.Adam(modelo.parameters(), lr=0.01)\n\nprint(\"Configuración de entrenamiento:\")\nprint(f\"  Loss function: Binary Cross Entropy\")\nprint(f\"  Optimizador: Adam\")\nprint(f\"  Learning rate: 0.01\")\nprint(f\"\\nAlternativas de optimizadores en PyTorch:\")\nprint(f\"  - SGD: Simple pero requiere tuning de lr\")\nprint(f\"  - AdaGrad: Bueno para datos sparse\")\nprint(f\"  - RMSprop: Precursor de Adam\")\nprint(f\"  - Adam: Balance entre velocidad y estabilidad (elegido)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento del modelo\n",
    "\n",
    "Vamos a entrenar el modelo por varias épocas. En cada época:\n",
    "1. Calculamos las predicciones (forward pass)\n",
    "2. Calculamos la pérdida\n",
    "3. Calculamos los gradientes (backpropagation)\n",
    "4. Actualizamos los pesos (optimizer step)\n",
    "\n",
    "Este proceso es automático gracias a PyTorch, a diferencia del ajuste manual que hicimos en el perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "###############################################################################\n# PARÁMETROS DEL ENTRENAMIENTO\n###############################################################################\n\n# ¿Por qué 200 épocas?\n# Es un número arbitrario pero suficientemente grande para este problema.\n#\n# ¿Cómo saber cuántas épocas usar?\n# - Muy pocas: El modelo no aprende completamente\n# - Muchas: Riesgo de overfitting (memoriza los datos de entrenamiento)\n# - Ideal: Monitorear la pérdida y parar cuando deje de disminuir\n#\n# 200 épocas es razonable para:\n# - Dataset pequeño (10 ejemplos)\n# - Modelo simple (145 parámetros)\n# - Optimizador eficiente (Adam)\n#\n# En la práctica:\n# - Usaríamos \"early stopping\": detener si la pérdida no mejora\n# - Dividiríamos los datos en train/validation para monitorear overfitting\nepocas = 200\n\nprint(\"=\"*60)\nprint(\"INICIANDO ENTRENAMIENTO\")\nprint(\"=\"*60)\nprint(f\"Épocas: {epocas}\\n\")\n\n###############################################################################\n# BUCLE DE ENTRENAMIENTO: GRADIENT DESCENT CON BACKPROPAGATION\n###############################################################################\n#\n# El entrenamiento de redes neuronales sigue estos pasos en cada época:\n# 1. Forward pass: calcular predicciones\n# 2. Calcular pérdida (loss)\n# 3. Backward pass: calcular gradientes (backpropagation)\n# 4. Actualizar pesos usando el optimizador\n#\n# Este proceso es la base del aprendizaje profundo (deep learning)\n#\n###############################################################################\n\nfor epoca in range(epocas):\n    ###########################################################################\n    # PASO 0: Modo entrenamiento\n    ###########################################################################\n    # modelo.train() activa el \"modo entrenamiento\"\n    #\n    # ¿Por qué es necesario?\n    # Algunas capas se comportan diferente en entrenamiento vs evaluación:\n    # - Dropout: Se desactiva aleatoriamente neuronas durante entrenamiento,\n    #            pero NO durante evaluación\n    # - Batch Normalization: Usa estadísticas del batch en train,\n    #                        usa estadísticas globales en eval\n    #\n    # En este modelo simple no afecta (no usamos Dropout ni BatchNorm),\n    # pero es buena práctica incluirlo siempre.\n    modelo.train()\n    \n    ###########################################################################\n    # PASO 1: Forward pass (Propagación hacia adelante)\n    ###########################################################################\n    # Calculamos las predicciones del modelo para TODOS los ejemplos a la vez\n    #\n    # Dimensiones:\n    # - X: (10, 16) - 10 frases, 16 features cada una\n    # - salida: (10, 1) - 10 predicciones, 1 valor por frase\n    #\n    # ¿Qué pasa internamente?\n    # 1. Primera capa: (10, 16) @ (16, 8) = (10, 8)\n    # 2. ReLU: (10, 8) → (10, 8) [elemento a elemento]\n    # 3. Segunda capa: (10, 8) @ (8, 1) = (10, 1)\n    # 4. Sigmoid: (10, 1) → (10, 1) [elemento a elemento]\n    salida = modelo(X)\n    \n    ###########################################################################\n    # PASO 2: Cálculo de la pérdida\n    ###########################################################################\n    # Comparamos las predicciones con las etiquetas reales\n    #\n    # criterio(salida, y) calcula:\n    # Loss = promedio de BCE para las 10 frases\n    # Loss = -1/10 × Σ[yᵢ·log(ŷᵢ) + (1-yᵢ)·log(1-ŷᵢ)]\n    #\n    # Resultado: Un único número que representa el error del modelo\n    # - Loss alta (ej: 2.0): Predicciones malas\n    # - Loss baja (ej: 0.1): Predicciones buenas\n    # - Loss cercana a 0: Predicciones casi perfectas\n    loss = criterio(salida, y)\n    \n    ###########################################################################\n    # PASO 3: Backpropagation (Propagación hacia atrás)\n    ###########################################################################\n    # Este es el corazón del aprendizaje de redes neuronales\n    #\n    # ¿Qué hace optimizador.zero_grad()?\n    # Limpia los gradientes de la iteración anterior.\n    # En PyTorch, los gradientes se ACUMULAN por defecto.\n    # Si no los limpiamos, se sumarían a los gradientes nuevos.\n    #\n    # Analogía: Borrar el pizarrón antes de escribir nuevos cálculos\n    optimizador.zero_grad()\n    \n    # ¿Qué hace loss.backward()?\n    # Calcula los gradientes de la pérdida respecto a TODOS los parámetros.\n    #\n    # Matemáticamente, calcula: ∂Loss/∂w para cada peso w\n    #\n    # ¿Cómo lo hace?\n    # Usa la regla de la cadena del cálculo diferencial:\n    # ∂Loss/∂w₁ = ∂Loss/∂salida × ∂salida/∂z₂ × ∂z₂/∂a₁ × ∂a₁/∂z₁ × ∂z₁/∂w₁\n    #\n    # PyTorch construye un \"grafo computacional\" durante forward pass\n    # y lo recorre en reversa para calcular todos los gradientes automáticamente.\n    #\n    # Esta es la magia de los frameworks de deep learning:\n    # - En el perceptrón calculamos gradientes manualmente\n    # - Acá PyTorch lo hace automáticamente con backward()\n    #\n    # Después de backward(), cada parámetro tiene su atributo .grad actualizado\n    # Ej: modelo.net[0].weight.grad contiene ∂Loss/∂W₁\n    loss.backward()\n    \n    ###########################################################################\n    # PASO 4: Actualización de pesos\n    ###########################################################################\n    # optimizador.step() actualiza TODOS los parámetros usando sus gradientes\n    #\n    # Para cada parámetro w:\n    # w_nuevo = w_viejo - learning_rate × gradiente\n    #\n    # En Adam (nuestro optimizador), la fórmula es más compleja:\n    # - Usa momento (promedio de gradientes pasados)\n    # - Usa learning rate adaptativo para cada parámetro\n    # - Aplica bias correction\n    #\n    # Resultado: Los 145 parámetros del modelo se ajustan ligeramente\n    # para reducir la pérdida en la próxima iteración.\n    optimizador.step()\n    \n    ###########################################################################\n    # Monitoreo del progreso\n    ###########################################################################\n    # Mostramos la pérdida cada 10 épocas para ver cómo aprende el modelo\n    if (epoca + 1) % 10 == 0:\n        # .item() convierte un tensor de PyTorch a un número Python\n        print(f\"Época {epoca+1:3d}, Pérdida: {loss.item():.4f}\")\n        \n        # Interpretación de la pérdida:\n        # Época 10: ~0.7 → El modelo está aprendiendo\n        # Época 100: ~0.3 → Mejorando notablemente\n        # Época 200: ~0.05 → Predicciones muy buenas\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ENTRENAMIENTO FINALIZADO\")\nprint(\"=\"*60)\nprint(\"\\n¿Qué aprendió el modelo?\")\nprint(\"Los 145 parámetros se ajustaron iterativamente para:\")\nprint(\"  1. Reconocer patrones de palabras positivas/negativas\")\nprint(\"  2. Combinar estos patrones de forma no lineal (gracias a ReLU)\")\nprint(\"  3. Producir probabilidades calibradas (gracias a BCE y Sigmoid)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 8. Análisis del entrenamiento\n",
    "\n",
    "Observá cómo la pérdida disminuye con el tiempo. Esto indica que el modelo está aprendiendo a clasificar mejor las frases.\n",
    "\n",
    "Una pérdida cercana a 0 significa que el modelo está muy confiado en sus predicciones correctas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 9. Evaluación con frases nuevas\n",
    "\n",
    "Probamos la red con frases que no estaban en el entrenamiento, para ver cómo generaliza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_prueba = [\n",
    "    \"No me gustó la atención, bastante mala\",\n",
    "    \"Muy buena experiencia, todo excelente\",\n",
    "    \"Una estafa total, no lo recomiendo\",\n",
    "    \"Súper conforme con el servicio\",\n",
    "    \"Nada que ver con lo prometido, una decepción\"\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUACIÓN EN FRASES NUEVAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vectorizamos las frases de prueba\n",
    "X_prueba_np = np.array([vectorizar(frase, vocabulario) for frase in frases_prueba], dtype=np.float32)\n",
    "X_prueba = torch.tensor(X_prueba_np)\n",
    "\n",
    "# Modo evaluación (desactiva dropout, batch norm, etc.)\n",
    "modelo.eval()\n",
    "\n",
    "# Predicción sin calcular gradientes (más eficiente)\n",
    "with torch.no_grad():\n",
    "    predicciones = modelo(X_prueba)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, (frase, pred) in enumerate(zip(frases_prueba, predicciones), 1):\n",
    "    probabilidad = pred.item()\n",
    "    clase = \"Positivo\" if probabilidad >= 0.5 else \"Negativo\"\n",
    "    print(f\"\\nFrase {i}: '{frase}'\")\n",
    "    print(f\"  Predicción: {clase} (probabilidad: {probabilidad:.2f})\")\n",
    "    \n",
    "    # Indicador visual de confianza\n",
    "    if probabilidad >= 0.8 or probabilidad <= 0.2:\n",
    "        print(f\"  Confianza: Alta\")\n",
    "    elif probabilidad >= 0.6 or probabilidad <= 0.4:\n",
    "        print(f\"  Confianza: Media\")\n",
    "    else:\n",
    "        print(f\"  Confianza: Baja (ambiguo)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 10. Reflexión final\n",
    "\n",
    "### ¿Qué aprendimos?\n",
    "\n",
    "1. **Arquitectura multicapa**: Vimos cómo una red con capas ocultas puede aprender representaciones más complejas que un perceptrón simple.\n",
    "\n",
    "2. **Activaciones no lineales**: ReLU permite que la red aprenda patrones no lineales, algo imposible con un perceptrón simple.\n",
    "\n",
    "3. **Entrenamiento automático**: PyTorch maneja automáticamente el cálculo de gradientes (backpropagation) y la actualización de pesos, a diferencia del ajuste manual del perceptrón.\n",
    "\n",
    "4. **Probabilidades vs decisiones binarias**: La salida Sigmoid nos da una probabilidad (0-1) en lugar de solo 0 o 1, lo que permite medir la confianza del modelo.\n",
    "\n",
    "### Ventajas sobre el perceptrón simple\n",
    "\n",
    "- Puede aprender patrones más complejos (no lineales)\n",
    "- Mejor capacidad de generalización\n",
    "- Optimización más eficiente con Adam\n",
    "- Salida probabilística (más informativa)\n",
    "\n",
    "### Limitaciones que aún persisten\n",
    "\n",
    "1. **No considera el orden de las palabras**: Bag-of-words sigue sin capturar secuencias\n",
    "2. **Vocabulario fijo**: Solo conoce palabras predefinidas\n",
    "3. **Sin contexto global**: Cada palabra se procesa independientemente\n",
    "4. **Dataset pequeño**: Con solo 10 ejemplos, la generalización es limitada\n",
    "\n",
    "### ¿Qué sigue?\n",
    "\n",
    "En la próxima actividad vamos a ver cómo las **redes recurrentes (LSTM)** pueden procesar secuencias de palabras manteniendo memoria del contexto. Esto nos va a permitir:\n",
    "\n",
    "- Capturar el orden de las palabras\n",
    "- Entender dependencias temporales\n",
    "- Procesar frases de longitud variable\n",
    "- Aprovechar embeddings de palabras\n",
    "\n",
    "Las LSTM son el paso previo a entender los Transformers, que revolucionaron el NLP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}