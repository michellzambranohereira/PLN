{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbItsSIpr8zV"
      },
      "source": [
        "Spanish Word Embeddings: [link](https://github.com/dccuchile/spanish-word-embeddings?tab=readme-ov-file)\n",
        "\n",
        "Word vectors for 157 languages: [link](https://fasttext.cc/docs/en/crawl-vectors.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC3Nbshfag5I"
      },
      "outputs": [],
      "source": [
        "# Para manipulación de datos y operaciones numéricas\n",
        "import numpy as np\n",
        "# Para vectorización y modelos de Machine Learning\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Para evaluación\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "# Para visualización (opcional, para la matriz de confusión)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Librerías principales importadas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAMTuMWecRBB"
      },
      "outputs": [],
      "source": [
        "# Demostración: CountVectorizer (Bag-of-Words) vs TfidfVectorizer\n",
        "\n",
        "# Corpus de ejemplo (textos cortos en español)\n",
        "corpus = [\n",
        "    \"qué bueno está el mate amargo\",\n",
        "    \"el mate dulce no me va\",\n",
        "    \"qué amargo está este mate che\",\n",
        "    \"me gusta el mate bien caliente\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LvsNM3pcbQr"
      },
      "outputs": [],
      "source": [
        "# 1. Usando CountVectorizer (Bolsa de Palabras simple)\n",
        "print(\"--- CountVectorizer (BoW) ---\")\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_matrix = count_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Mostramos el vocabulario (las \"features\")\n",
        "print(\"Vocabulario (Features):\")\n",
        "print(count_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Mostramos la matriz BoW (dispersa)\n",
        "print(\"\\nMatriz BoW (Documento x Palabra):\")\n",
        "print(bow_matrix.toarray()) # .toarray() para verla densa (cuidado con corpus grandes)\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v0MjIMHcW4l"
      },
      "outputs": [],
      "source": [
        "# 2. Usando TfidfVectorizer\n",
        "print(\"\\n--- TfidfVectorizer ---\")\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# El vocabulario es el mismo (si no cambiamos parámetros)\n",
        "# print(\"Vocabulario (Features):\") # Ya lo mostramos arriba\n",
        "# print(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Mostramos la matriz TF-IDF\n",
        "print(\"Matriz TF-IDF (Documento x Palabra):\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- Observaciones ---\n",
        "# Nota 1: Compara los valores de palabras comunes como 'mate', 'el', 'está'.\n",
        "#         En BoW son solo cuentas. En TF-IDF, su peso se ajusta por la frecuencia\n",
        "#         inversa en los documentos (IDF). Palabras más 'distintivas' de un\n",
        "#         documento (ej. 'dulce', 'caliente', 'che') tienden a tener mayor peso TF-IDF\n",
        "#         relativo que palabras muy comunes en *todo* el corpus.\n",
        "# Nota 2: Ambas matrices son 'dispersas' (muchos ceros)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E93RnN-vc6cS"
      },
      "outputs": [],
      "source": [
        "# --- Demostración: Añadiendo N-Gramas a TF-IDF ---\n",
        "\n",
        "print(\"\\n--- TfidfVectorizer con N-Gramas (bigramas) ---\")\n",
        "\n",
        "# Usamos el mismo corpus de antes\n",
        "# Creamos un nuevo vectorizador, ahora especificando ngram_range\n",
        "# ngram_range=(1, 2) significa: usa unigramas (palabras solas) Y bigramas (pares de palabras)\n",
        "tfidf_ngram_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "tfidf_ngram_matrix = tfidf_ngram_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Mostramos el NUEVO vocabulario, que ahora incluye bigramas\n",
        "print(\"Vocabulario con unigramas y bigramas:\")\n",
        "print(tfidf_ngram_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Mostramos la nueva matriz TF-IDF (será más ancha)\n",
        "print(\"\\nMatriz TF-IDF con N-Gramas:\")\n",
        "print(tfidf_ngram_matrix.toarray())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- Observaciones ---\n",
        "# Nota 1: Fíjate cómo aparecen términos como \"mate amargo\", \"qué bueno\", \"no me\", etc.\n",
        "#         Estos bigramas capturan un poco del contexto local y pueden ser features\n",
        "#         muy útiles para los modelos. Por ejemplo, 'amargo' solo y 'mate amargo'\n",
        "#         aportan información diferente.\n",
        "# Nota 2: El número de features (columnas) aumenta considerablemente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "144lGGePdGcM"
      },
      "outputs": [],
      "source": [
        "# --- Demostración: Pipeline de Clasificación y Evaluación ---\n",
        "\n",
        "# 1. Datos de Ejemplo (Simples, para clasificación binaria: Positivo/Negativo)\n",
        "textos = [\n",
        "    \"La milanesa a caballo estaba espectacular!\", # Positivo\n",
        "    \"Qué buena onda la atención en el bar.\",     # Positivo\n",
        "    \"El flan con dulce de leche es lo más.\",    # Positivo\n",
        "    \"El bife de chorizo llegó frío y duro.\",     # Negativo\n",
        "    \"Mucho quilombo, tardaron una banda en traer la cuenta.\", # Negativo\n",
        "    \"La verdad, la pizza dejaba bastante que deseear.\", # Negativo\n",
        "]\n",
        "# Etiquetas: 1 para Positivo, 0 para Negativo\n",
        "labels = np.array([1, 1, 1, 0, 0, 0])\n",
        "\n",
        "# 2. Dividir datos en Entrenamiento y Prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(textos, labels, test_size=0.33, random_state=42)\n",
        "# test_size=0.33 significa que ~1/3 va para prueba. random_state para reproducibilidad.\n",
        "\n",
        "print(f\"Textos de entrenamiento: {len(X_train)}\")\n",
        "print(f\"Textos de prueba: {len(X_test)}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 3. Crear y Entrenar un Pipeline (TF-IDF + Naive Bayes)\n",
        "# El Pipeline encadena pasos: primero vectoriza, luego clasifica.\n",
        "pipeline_nb = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1,1))), # Usamos solo unigramas aquí por simplicidad\n",
        "    ('clf', MultinomialNB()) # Clasificador Naive Bayes Multinomial\n",
        "])\n",
        "\n",
        "print(\"\\nEntrenando el Pipeline (TF-IDF + Naive Bayes)...\")\n",
        "# Entrenamos el pipeline COMPLETO con los datos de texto CRUDOS de entrenamiento\n",
        "pipeline_nb.fit(X_train, y_train)\n",
        "print(\"Entrenamiento completado.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 4. Realizar Predicciones sobre los datos de Prueba\n",
        "print(\"\\nRealizando predicciones sobre el conjunto de prueba...\")\n",
        "y_pred_nb = pipeline_nb.predict(X_test)\n",
        "\n",
        "print(f\"Predicciones: {y_pred_nb}\")\n",
        "print(f\"Etiquetas Reales: {y_test}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 5. Evaluar el Modelo\n",
        "print(\"\\n--- Evaluación del Modelo (Naive Bayes) ---\")\n",
        "print(classification_report(y_test, y_pred_nb, target_names=['Negativo (0)', 'Positivo (1)']))\n",
        "\n",
        "# Matriz de Confusión\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "disp_nb = ConfusionMatrixDisplay(confusion_matrix=cm_nb, display_labels=['Negativo (0)', 'Positivo (1)'])\n",
        "disp_nb.plot(cmap=plt.cm.Blues)\n",
        "plt.show() # Muestra el gráfico\n",
        "\n",
        "# --- Observaciones ---\n",
        "# Nota 1: El Pipeline simplifica enormemente el flujo. Entrenamos con texto crudo,\n",
        "#         predice con texto crudo. La vectorización ocurre dentro del pipeline.\n",
        "# Nota 2: El 'classification_report' es CLAVE. Muestra Precision, Recall y F1-Score\n",
        "#         para cada clase. Fijarse si el modelo funciona igual de bien para ambas.\n",
        "#         'support' indica cuántas muestras de cada clase había en el test set.\n",
        "# Nota 3: La Matriz de Confusión ayuda a ver *dónde* se equivoca.\n",
        "#         Diagonal principal = Aciertos. Fuera de la diagonal = Errores.\n",
        "#         (Fila = Real, Columna = Predicción)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsB4y6sTd0Qf"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade numpy scipy gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_MiyeCrgDxJ"
      },
      "outputs": [],
      "source": [
        "!pip uninstall gensim -y # Remove the existing gensim installation\n",
        "!pip install gensim # Reinstall gensim to align with the NumPy version\n",
        "# Restart the kernel to ensure the changes take effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVEZQNiGfzw8"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLr2HtO4gQGp"
      },
      "outputs": [],
      "source": [
        "# List available models to find the correct name\n",
        "print(api.info()['models'].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNLrzOM0guF9"
      },
      "outputs": [],
      "source": [
        "model_name = 'fasttext-wiki-news-subwords-300'\n",
        "word_vectors = api.load(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1be2041c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkdGy4t9gx5d"
      },
      "outputs": [],
      "source": [
        "print(f\"Modelo cargado. Vocabulario: {len(word_vectors.index_to_key)} palabras.\")\n",
        "modelo_cargado = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVWDSm2omO7c"
      },
      "outputs": [],
      "source": [
        "if modelo_cargado:\n",
        "    # a) Obtener el vector de una palabra\n",
        "    try:\n",
        "        vector_auto = word_vectors['auto']\n",
        "        print(f\"Vector para 'auto' (primeros 10 de {len(vector_auto)} dimensiones):\")\n",
        "        print(vector_auto[:10])\n",
        "        print(f\"Forma del vector: {vector_auto.shape}\") # Debería ser (300,) si usas SBWC de 300d\n",
        "    except KeyError:\n",
        "        print(\"La palabra 'auto' no está en el vocabulario.\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C49jaXGBmfej"
      },
      "outputs": [],
      "source": [
        "# b) Encontrar palabras similares (similitud coseno)\n",
        "try:\n",
        "  similares_mate = word_vectors.most_similar('elefante', topn=10)\n",
        "  print(\"Palabras más similares a 'elefante':\")\n",
        "  for palabra, score in similares_mate:\n",
        "    print(f\"- {palabra}: {score:.5f}\") # Muestra la palabra y su puntaje de similitud\n",
        "except KeyError:\n",
        "  print(\"La palabra 'elefante' no está en el vocabulario.\")\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxvWNAbkm7a9"
      },
      "outputs": [],
      "source": [
        "# c) Realizar analogías vectoriales (el famoso ejemplo rey/reina)\n",
        "try:\n",
        "  analogia = word_vectors.most_similar(positive=['casa', 'edificio'], negative=['carpa'], topn=2)\n",
        "  print(\"Analogía: rey - varón + mujer ≈ ???\")\n",
        "  print(f\"Resultado más probable: {analogia[0][0]} (Score: {analogia[0][1]:.4f})\")\n",
        "except KeyError as e:\n",
        "  print(f\"Error en la analogía: Falta la palabra '{e.args[0]}' en el vocabulario.\")\n",
        "print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GUÍA DE ESTUDIO - SÍNTESIS E INTEGRACIÓN\n",
        "\n",
        "## Preguntas y Respuestas Clave\n",
        "\n",
        "### **Integración de Técnicas**\n",
        "\n",
        "**P: ¿Cuál es la ventaja principal de usar Pipeline en scikit-learn?**  \n",
        "R: Encadena automáticamente pasos (vectorización + clasificación) y evita data leakage aplicando transformaciones solo en datos de entrenamiento durante fit.\n",
        "\n",
        "**P: ¿Por qué usar train_test_split antes de crear el pipeline?**  \n",
        "R: Para evaluar objetivamente el rendimiento en datos no vistos y detectar overfitting del modelo completo.\n",
        "\n",
        "**P: ¿Qué información proporciona classification_report?**  \n",
        "R: Precision (de predicciones positivas, cuántas son correctas), Recall (de casos reales positivos, cuántos detectamos), y F1-score (balance entre ambas).\n",
        "\n",
        "### **Comparación de Métodos**\n",
        "\n",
        "**P: ¿Cuándo añadir n-gramas a TF-IDF?**  \n",
        "R: Cuando el contexto local es importante (\"muy bueno\" vs \"bueno muy\"), pero aumenta dimensionalidad y complejidad.\n",
        "\n",
        "**P: ¿Cómo comparar objetivamente BoW vs TF-IDF vs Embeddings?**  \n",
        "R: Usar mismo pipeline, mismos datos de train/test, comparar métricas finales (F1-score, accuracy) en tarea específica.\n",
        "\n",
        "**P: ¿Por qué la matriz de confusión es importante?**  \n",
        "R: Muestra patrones de error específicos: ¿confunde más falsos positivos o falsos negativos? ¿Qué clases se confunden entre sí?\n",
        "\n",
        "### **Embeddings en Pipelines**\n",
        "\n",
        "**P: ¿Cómo integrar word embeddings en un pipeline de clasificación?**  \n",
        "R: Promediando vectores de palabras del documento o usando representaciones más sofisticadas como weighted averages por TF-IDF.\n",
        "\n",
        "**P: ¿Qué ventajas tienen embeddings sobre TF-IDF en clasificación?**  \n",
        "R: Capturan semántica (sinónimos contribuyen similarmente), menor dimensionalidad, mejor generalización a vocabulario no visto.\n",
        "\n",
        "### **Decisiones Prácticas**\n",
        "\n",
        "**P: ¿Cómo decidir entre Naive Bayes y Logistic Regression?**  \n",
        "R: NB asume independencia de features, rápido, bueno para texto. LR más flexible, maneja correlaciones, mejor con features continuas.\n",
        "\n",
        "**P: ¿Cuándo usar cada método en producción?**  \n",
        "R: BoW/TF-IDF para baseline rápido, FastText para robustez OOV, Word2Vec para análisis semántico, según requirements específicos.\n",
        "\n",
        "### **Evaluación Integral**\n",
        "\n",
        "**P: ¿Qué métricas usar para comparar sistemas de NLP?**  \n",
        "R: Accuracy (básico), F1-score (balanceado), Precision/Recall específicos según costo de errores, tiempo de inferencia.\n",
        "\n",
        "**P: ¿Cómo detectar overfitting en NLP?**  \n",
        "R: Gran diferencia entre performance train/validation, alta dimensionalidad vs pocos datos, memorización de vocabulario específico.\n",
        "\n",
        "## Puntos Clave para Recordar\n",
        "\n",
        "1. **Pipeline automatiza y previene errores** en flujo ML\n",
        "2. **Evaluación objetiva require train/test split** apropiado\n",
        "3. **Diferentes métodos para diferentes problemas** - no hay silver bullet\n",
        "4. **Métricas específicas revelan fortalezas/debilidades** de cada approach\n",
        "5. **Embeddings aportan semántica** pero requieren más setup\n",
        "6. **Integración práctica** considera tiempo, memoria, interpretabilidad\n",
        "\n",
        "## Errores Comunes a Evitar\n",
        "\n",
        "- Aplicar transformaciones a todo el dataset antes del split\n",
        "- Comparar métodos con diferentes preprocessings\n",
        "- Elegir solo por accuracy sin considerar precision/recall\n",
        "- No validar assumptions de algoritmos (ej: independencia en NB)\n",
        "- Ignorar computational requirements en producción\n",
        "\n",
        "## Conexión con Próxima Clase\n",
        "\n",
        "Esta integración de métodos tradicionales y modernos prepara para **aplicaciones avanzadas**: extracción de información, análisis de entidades, y sistemas de NLP end-to-end.\n",
        "\n",
        "---\n",
        "*Consejo: Siempre establece baseline simple (BoW + NB) antes de probar métodos complejos. Te da referencia para validar si la complejidad adicional vale la pena.*"
      ],
      "metadata": {
        "id": "Gadt7-mqhSb2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}