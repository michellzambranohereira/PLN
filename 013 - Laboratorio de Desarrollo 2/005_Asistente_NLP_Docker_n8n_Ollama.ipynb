{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento del Lenguaje Natural\n",
    "## Asistente NLP con Docker, n8n y Ollama\n",
    "\n",
    "**Materia:** Procesamiento del Lenguaje Natural e Introducci√≥n a LLMs  \n",
    "**M√≥dulo:** Infraestructura y Despliegue de Aplicaciones NLP\n",
    "\n",
    "---\n",
    "\n",
    "## Introducci√≥n\n",
    "\n",
    "En esta gu√≠a vas a aprender a construir un sistema completo de procesamiento de lenguaje natural usando herramientas de c√≥digo abierto. El objetivo es que entiendas c√≥mo funcionan las aplicaciones de NLP en entornos reales, m√°s all√° de los notebooks de Jupyter.\n",
    "\n",
    "### ¬øQu√© vamos a construir?\n",
    "\n",
    "Un asistente de lenguaje natural que puede realizar m√∫ltiples tareas:\n",
    "\n",
    "- **Named Entity Recognition (NER):** Extracci√≥n de entidades nombradas\n",
    "- **An√°lisis de Sentimiento:** Clasificaci√≥n emocional de textos\n",
    "- **Sumarizaci√≥n:** Generaci√≥n de res√∫menes autom√°ticos\n",
    "- **Clasificaci√≥n de Textos:** Identificaci√≥n de tipo y tema\n",
    "- **Extracci√≥n de Keywords:** T√©rminos m√°s relevantes\n",
    "\n",
    "### Stack Tecnol√≥gico\n",
    "\n",
    "- **Docker + Docker Compose:** Containerizaci√≥n y orquestaci√≥n\n",
    "- **n8n:** Plataforma de automatizaci√≥n de workflows\n",
    "- **Ollama:** Servidor para ejecutar modelos de lenguaje localmente\n",
    "- **IBM Granite 4:** Modelo de lenguaje de √∫ltima generaci√≥n\n",
    "- **Streamlit:** Framework para crear interfaces web (opcional)\n",
    "\n",
    "### Objetivos de Aprendizaje\n",
    "\n",
    "Al finalizar este laboratorio vas a poder:\n",
    "\n",
    "1. Comprender qu√© es Docker y por qu√© se usa en proyectos de IA\n",
    "2. Configurar y orquestar servicios con Docker Compose\n",
    "3. Trabajar con modelos de lenguaje locales sin depender de APIs externas\n",
    "4. Crear workflows de NLP de forma visual con n8n\n",
    "5. Implementar un asistente multimodal de procesamiento de lenguaje\n",
    "6. Crear im√°genes Docker personalizadas\n",
    "7. Entender los fundamentos del despliegue en servidores\n",
    "\n",
    "### Nota Importante sobre el Entorno de Ejecuci√≥n\n",
    "\n",
    "**Este proyecto NO puede ejecutarse en Google Colab** porque requiere Docker, que no est√° disponible en entornos Jupyter en la nube. Vas a necesitar trabajar en tu m√°quina local con Docker Desktop instalado.\n",
    "\n",
    "Este notebook funciona como una **gu√≠a de referencia** que vas a consultar mientras trabaj√°s en tu terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conceptos Fundamentales\n",
    "\n",
    "Antes de comenzar con la implementaci√≥n, es fundamental que entiendas los conceptos detr√°s de las tecnolog√≠as que vamos a usar.\n",
    "\n",
    "### Docker: Containerizaci√≥n de Aplicaciones\n",
    "\n",
    "Docker es una plataforma que permite empaquetar aplicaciones con todas sus dependencias en **contenedores**. Un contenedor es como una caja aislada que contiene:\n",
    "\n",
    "- El c√≥digo de tu aplicaci√≥n\n",
    "- Las librer√≠as y dependencias necesarias\n",
    "- Configuraciones del sistema\n",
    "- Un mini sistema operativo base\n",
    "\n",
    "**¬øPor qu√© es importante Docker?**\n",
    "\n",
    "El problema cl√°sico en desarrollo de software es: \"en mi m√°quina funciona\". Docker lo resuelve garantizando que tu aplicaci√≥n corra exactamente igual en cualquier lugar: tu laptop, el servidor de producci√≥n, la m√°quina de un colega.\n",
    "\n",
    "**Ventajas:**\n",
    "- **Portabilidad:** El mismo contenedor corre en Windows, Mac, Linux\n",
    "- **Reproducibilidad:** Mismo entorno siempre\n",
    "- **Aislamiento:** Cada servicio en su propio contenedor\n",
    "- **Eficiencia:** Los contenedores comparten el kernel del sistema operativo, son m√°s livianos que m√°quinas virtuales\n",
    "\n",
    "### Docker Compose: Orquestaci√≥n de Servicios\n",
    "\n",
    "Docker Compose es una herramienta para definir y ejecutar aplicaciones Docker con m√∫ltiples contenedores. En lugar de levantar cada contenedor manualmente, defin√≠s todos los servicios en un archivo YAML y los levant√°s con un solo comando.\n",
    "\n",
    "En nuestro proyecto vamos a orquestar dos servicios:\n",
    "- **n8n:** El motor de workflows\n",
    "- **Ollama:** El servidor de modelos de lenguaje\n",
    "\n",
    "### n8n: Automatizaci√≥n Visual de Workflows\n",
    "\n",
    "n8n (\"node-to-node\") es una plataforma open source de automatizaci√≥n que te permite crear flujos de trabajo conectando diferentes servicios. Es similar a herramientas como Zapier o Make, pero autohospedada y con m√°s control.\n",
    "\n",
    "**¬øPor qu√© usar n8n?**\n",
    "\n",
    "Podr√≠amos escribir todo el c√≥digo en Python, pero n8n nos da:\n",
    "- **Visualizaci√≥n:** Ves el flujo de datos gr√°ficamente\n",
    "- **Debugging:** Pod√©s ejecutar paso a paso y ver resultados intermedios\n",
    "- **Flexibilidad:** F√°cil de modificar sin tocar c√≥digo\n",
    "- **Integraciones:** Conectores pre-construidos para cientos de servicios\n",
    "\n",
    "En nuestro proyecto, n8n va a:\n",
    "1. Recibir consultas del usuario v√≠a webhook\n",
    "2. Detectar qu√© tipo de tarea de NLP quiere realizar\n",
    "3. Construir el prompt apropiado para el modelo\n",
    "4. Enviar la solicitud a Ollama\n",
    "5. Formatear y devolver la respuesta\n",
    "\n",
    "### Ollama: Ejecuci√≥n Local de Modelos de Lenguaje\n",
    "\n",
    "Ollama es una herramienta que facilita la ejecuci√≥n de modelos de lenguaje grandes (LLMs) en tu propia m√°quina. Maneja autom√°ticamente la descarga, configuraci√≥n y ejecuci√≥n de modelos.\n",
    "\n",
    "**Ventajas de LLMs locales:**\n",
    "- **Sin costos por uso:** No pag√°s por cada llamada a la API\n",
    "- **Privacidad:** Tus datos no salen de tu infraestructura\n",
    "- **Sin l√≠mites de rate:** No hay restricciones de requests por minuto\n",
    "- **Funciona offline:** No depend√©s de conexi√≥n a internet\n",
    "\n",
    "**Desventajas:**\n",
    "- Requiere recursos computacionales (RAM, CPU/GPU)\n",
    "- Los modelos ocupan espacio en disco\n",
    "- Generalmente son menos potentes que los modelos comerciales m√°s grandes\n",
    "\n",
    "### IBM Granite 4: El Modelo de Lenguaje\n",
    "\n",
    "Granite 4 es la √∫ltima generaci√≥n de modelos de IBM, lanzada en octubre 2025. Tiene una arquitectura h√≠brida innovadora que combina capas Mamba-2 con capas Transformer tradicionales.\n",
    "\n",
    "**Caracter√≠sticas principales:**\n",
    "- **Eficiencia de memoria:** Reduce el uso de RAM en m√°s del 70% comparado con modelos transformer puros\n",
    "- **Multiling√ºe:** Soporta espa√±ol, ingl√©s, franc√©s, alem√°n, japon√©s, portugu√©s, √°rabe, chino, entre otros\n",
    "- **Contexto largo:** Puede procesar hasta 512K tokens\n",
    "- **Optimizado para empresas:** Excelente en seguimiento de instrucciones y function calling\n",
    "\n",
    "**Tama√±os disponibles:**\n",
    "- **granite4:micro** (3B par√°metros) - Ideal para laptops, muy r√°pido\n",
    "- **granite4:tiny** (7B MoE, ~1B activos) - Balance entre velocidad y calidad\n",
    "- **granite4:latest** (32B MoE, ~9B activos) - M√°xima calidad, requiere m√°s recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prerrequisitos\n",
    "\n",
    "### Requisitos de Software\n",
    "\n",
    "#### 1. Docker Desktop\n",
    "\n",
    "**Para Windows o Mac:**\n",
    "1. Descargar desde: https://www.docker.com/products/docker-desktop\n",
    "2. Instalar siguiendo el asistente\n",
    "3. Reiniciar tu computadora\n",
    "4. Verificar que Docker Desktop est√° corriendo (icono de ballena en la barra de tareas)\n",
    "\n",
    "**Para Linux (Ubuntu/Debian):**\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install docker.io docker-compose\n",
    "sudo systemctl start docker\n",
    "sudo systemctl enable docker\n",
    "sudo usermod -aG docker $USER\n",
    "```\n",
    "\n",
    "Despu√©s de instalar, verific√° que funciona:\n",
    "```bash\n",
    "docker --version\n",
    "docker-compose --version\n",
    "```\n",
    "\n",
    "Deber√≠as ver algo como:\n",
    "```\n",
    "Docker version 24.0.7, build afdd53b\n",
    "Docker Compose version v2.23.0\n",
    "```\n",
    "\n",
    "#### 2. Editor de Texto\n",
    "\n",
    "Cualquier editor sirve: VSCode (recomendado), Sublime Text, Notepad++, Atom.\n",
    "\n",
    "#### 3. Terminal/Consola\n",
    "\n",
    "- **Windows:** PowerShell, CMD o Windows Terminal\n",
    "- **Mac:** Terminal (incluida en el sistema)\n",
    "- **Linux:** La terminal de tu distribuci√≥n\n",
    "\n",
    "### Requisitos de Hardware\n",
    "\n",
    "**M√≠nimos (para granite4:micro):**\n",
    "- RAM: 8GB\n",
    "- Espacio en disco: 10GB libres\n",
    "- Procesador: Cualquier CPU moderna de los √∫ltimos 5 a√±os\n",
    "\n",
    "**Recomendados (para granite4:tiny o latest):**\n",
    "- RAM: 16GB o m√°s\n",
    "- Espacio en disco: 20GB libres\n",
    "- Procesador: CPU multin√∫cleo o GPU (opcional pero mejora la velocidad)\n",
    "\n",
    "### Conocimientos Previos Necesarios\n",
    "\n",
    "- Uso b√°sico de la terminal/l√≠nea de comandos\n",
    "- Conceptos b√°sicos de redes (qu√© es un puerto, localhost)\n",
    "- Conocimientos previos de la materia (modelos de lenguaje, tareas de NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 1: Preparar el Proyecto\n",
    "\n",
    "### Crear el Directorio del Proyecto\n",
    "\n",
    "Abr√≠ tu terminal y ejecut√° los siguientes comandos:\n",
    "\n",
    "**En Windows (PowerShell o CMD):**\n",
    "```powershell\n",
    "# Navegar a donde quieras crear el proyecto (ej: Documentos)\n",
    "cd C:\\Users\\TuUsuario\\Documents\n",
    "\n",
    "# Crear directorio\n",
    "mkdir asistente-nlp\n",
    "cd asistente-nlp\n",
    "```\n",
    "\n",
    "**En Mac o Linux:**\n",
    "```bash\n",
    "# Navegar a donde quieras crear el proyecto (ej: Documentos)\n",
    "cd ~/Documents\n",
    "\n",
    "# Crear directorio\n",
    "mkdir asistente-nlp\n",
    "cd asistente-nlp\n",
    "```\n",
    "\n",
    "### Crear el archivo docker-compose.yml\n",
    "\n",
    "Este archivo es el coraz√≥n de nuestro proyecto. Define qu√© servicios vamos a levantar y c√≥mo van a interactuar entre s√≠.\n",
    "\n",
    "Abr√≠ tu editor de texto y cre√° un archivo llamado `docker-compose.yml` en el directorio `asistente-nlp` con el siguiente contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: NO ejecutes esta celda. \n",
    "# Copia el contenido en un archivo llamado docker-compose.yml\n",
    "\n",
    "\"\"\"\n",
    "services:\n",
    "  n8n:\n",
    "    image: docker.n8n.io/n8nio/n8n\n",
    "    container_name: n8n\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"5678:5678\"\n",
    "    environment:\n",
    "      - GENERIC_TIMEZONE=America/Argentina/Buenos_Aires\n",
    "      - TZ=America/Argentina/Buenos_Aires\n",
    "      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true\n",
    "      - N8N_RUNNERS_ENABLED=true\n",
    "    volumes:\n",
    "      - n8n_data:/home/node/.n8n\n",
    "    networks:\n",
    "      - n8n-network\n",
    "    depends_on:\n",
    "      - ollama\n",
    "\n",
    "  ollama:\n",
    "    image: ollama/ollama:latest\n",
    "    container_name: ollama\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"11434:11434\"\n",
    "    environment:\n",
    "      - TZ=America/Argentina/Buenos_Aires\n",
    "    volumes:\n",
    "      - ollama_data:/root/.ollama\n",
    "    networks:\n",
    "      - n8n-network\n",
    "\n",
    "volumes:\n",
    "  n8n_data:\n",
    "  ollama_data:\n",
    "\n",
    "networks:\n",
    "  n8n-network:\n",
    "    driver: bridge\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendiendo el docker-compose.yml\n",
    "\n",
    "Vamos a analizar cada secci√≥n:\n",
    "\n",
    "#### Servicio n8n\n",
    "\n",
    "```yaml\n",
    "n8n:\n",
    "  image: docker.n8n.io/n8nio/n8n\n",
    "```\n",
    "Esto le dice a Docker que descargue la imagen oficial de n8n desde su registro.\n",
    "\n",
    "```yaml\n",
    "  ports:\n",
    "    - \"5678:5678\"\n",
    "```\n",
    "Mapea el puerto 5678 del contenedor al puerto 5678 de tu m√°quina. Esto significa que vas a poder acceder a n8n en `http://localhost:5678`.\n",
    "\n",
    "```yaml\n",
    "  environment:\n",
    "    - GENERIC_TIMEZONE=America/Argentina/Buenos_Aires\n",
    "    - TZ=America/Argentina/Buenos_Aires\n",
    "```\n",
    "Configura la zona horaria. Pod√©s cambiarla a la tuya si no est√°s en Argentina.\n",
    "\n",
    "```yaml\n",
    "  volumes:\n",
    "    - n8n_data:/home/node/.n8n\n",
    "```\n",
    "Esto es crucial. Un **volumen** es un espacio de almacenamiento persistente. Los contenedores Docker son ef√≠meros: si los borr√°s, perd√©s todo lo que estaba adentro. Los vol√∫menes permiten guardar datos importantes (como tus workflows de n8n) que sobreviven aunque elimines el contenedor.\n",
    "\n",
    "```yaml\n",
    "  networks:\n",
    "    - n8n-network\n",
    "```\n",
    "Conecta este contenedor a una red privada llamada `n8n-network`. Esto permite que n8n y Ollama se comuniquen entre s√≠.\n",
    "\n",
    "```yaml\n",
    "  depends_on:\n",
    "    - ollama\n",
    "```\n",
    "Le indica a Docker que levante primero Ollama y despu√©s n8n.\n",
    "\n",
    "#### Servicio Ollama\n",
    "\n",
    "La configuraci√≥n es similar. Cosas importantes:\n",
    "\n",
    "```yaml\n",
    "  ports:\n",
    "    - \"11434:11434\"\n",
    "```\n",
    "Ollama expone su API en el puerto 11434.\n",
    "\n",
    "```yaml\n",
    "  volumes:\n",
    "    - ollama_data:/root/.ollama\n",
    "```\n",
    "Ac√° se guardan los modelos descargados. Si descarg√°s Granite 4 (que puede pesar varios GB), quer√©s que se guarde en un volumen persistente para no tener que descargarlo de nuevo cada vez.\n",
    "\n",
    "#### Secci√≥n de Vol√∫menes y Redes\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  n8n_data:\n",
    "  ollama_data:\n",
    "```\n",
    "Declara los vol√∫menes que vamos a usar.\n",
    "\n",
    "```yaml\n",
    "networks:\n",
    "  n8n-network:\n",
    "    driver: bridge\n",
    "```\n",
    "Crea una red tipo \"bridge\" (puente) que conecta los contenedores. Dentro de esta red, los contenedores pueden referirse entre s√≠ por su nombre (ej: n8n puede hacer requests a `http://ollama:11434`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 2: Levantar los Servicios\n",
    "\n",
    "### Verificar Docker\n",
    "\n",
    "Antes de continuar, asegurate de que Docker Desktop est√© corriendo. Deber√≠as ver el √≠cono de la ballena en tu barra de tareas.\n",
    "\n",
    "En tu terminal, ejecut√°:\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Si ves una tabla (aunque est√© vac√≠a), Docker est√° funcionando. Si ves un error, revis√° que Docker Desktop est√© iniciado.\n",
    "\n",
    "### Levantar los Contenedores\n",
    "\n",
    "Desde el directorio donde est√° tu `docker-compose.yml`, ejecut√°:\n",
    "\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "**¬øQu√© hace este comando?**\n",
    "- `docker-compose up`: Levanta los servicios definidos en docker-compose.yml\n",
    "- `-d`: \"Detached mode\" - corre los contenedores en segundo plano\n",
    "\n",
    "**¬øQu√© va a pasar?**\n",
    "\n",
    "La primera vez que ejecutes este comando:\n",
    "\n",
    "1. Docker va a descargar las im√°genes de n8n y Ollama (esto puede tardar varios minutos seg√∫n tu conexi√≥n)\n",
    "2. Va a crear los vol√∫menes `n8n_data` y `ollama_data`\n",
    "3. Va a crear la red `n8n-network`\n",
    "4. Va a iniciar ambos contenedores\n",
    "\n",
    "Vas a ver una salida similar a esta:\n",
    "```\n",
    "[+] Running 5/5\n",
    " ‚úî Network asistente-nlp_n8n-network  Created\n",
    " ‚úî Volume \"asistente-nlp_n8n_data\"    Created\n",
    " ‚úî Volume \"asistente-nlp_ollama_data\" Created\n",
    " ‚úî Container ollama                   Started\n",
    " ‚úî Container n8n                      Started\n",
    "```\n",
    "\n",
    "### Verificar que los Servicios Est√°n Corriendo\n",
    "\n",
    "```bash\n",
    "docker-compose ps\n",
    "```\n",
    "\n",
    "Deber√≠as ver:\n",
    "```\n",
    "NAME      IMAGE                       STATUS         PORTS\n",
    "n8n       docker.n8n.io/n8nio/n8n    Up 2 minutes   0.0.0.0:5678->5678/tcp\n",
    "ollama    ollama/ollama:latest        Up 2 minutes   0.0.0.0:11434->11434/tcp\n",
    "```\n",
    "\n",
    "La columna STATUS debe decir \"Up\" para ambos servicios.\n",
    "\n",
    "### Ver los Logs (√ötil para debugging)\n",
    "\n",
    "Si quer√©s ver qu√© est√°n haciendo los contenedores:\n",
    "\n",
    "```bash\n",
    "# Ver logs de ambos servicios\n",
    "docker-compose logs -f\n",
    "\n",
    "# Ver logs solo de n8n\n",
    "docker-compose logs -f n8n\n",
    "\n",
    "# Ver logs solo de Ollama\n",
    "docker-compose logs -f ollama\n",
    "```\n",
    "\n",
    "Presion√° `Ctrl + C` para salir de los logs.\n",
    "\n",
    "### Comandos √ötiles de Docker Compose\n",
    "\n",
    "Para referencia futura:\n",
    "\n",
    "```bash\n",
    "# Detener servicios (mantiene contenedores y datos)\n",
    "docker-compose stop\n",
    "\n",
    "# Iniciar servicios previamente detenidos\n",
    "docker-compose start\n",
    "\n",
    "# Reiniciar servicios\n",
    "docker-compose restart\n",
    "\n",
    "# Detener y eliminar contenedores (mantiene vol√∫menes)\n",
    "docker-compose down\n",
    "\n",
    "# CUIDADO: Eliminar TODO incluyendo vol√∫menes (perd√©s tus datos)\n",
    "docker-compose down -v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 3: Configurar Ollama y Descargar el Modelo\n",
    "\n",
    "### Verificar que Ollama est√° Funcionando\n",
    "\n",
    "Primero, verific√° que Ollama est√© respondiendo:\n",
    "\n",
    "```bash\n",
    "curl http://localhost:11434\n",
    "```\n",
    "\n",
    "Deber√≠as ver: `Ollama is running`\n",
    "\n",
    "Si no ten√©s `curl` instalado en Windows, pod√©s abrir `http://localhost:11434` en tu navegador y deber√≠as ver el mismo mensaje.\n",
    "\n",
    "### Descargar el Modelo IBM Granite 4\n",
    "\n",
    "Ahora viene una decisi√≥n importante: elegir qu√© tama√±o de modelo descargar. Esto depende de tu hardware.\n",
    "\n",
    "#### Opci√≥n A: granite4:micro (Recomendado para empezar)\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Tama√±o: ~1.7GB\n",
    "- RAM necesaria: 4-6GB\n",
    "- Velocidad: Muy r√°pida\n",
    "- Ideal para: Laptops con recursos limitados, pruebas r√°pidas\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama pull granite4:micro\n",
    "```\n",
    "\n",
    "#### Opci√≥n B: granite4:tiny\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Tama√±o: ~4GB\n",
    "- RAM necesaria: 8GB\n",
    "- Velocidad: Balanceada\n",
    "- Ideal para: PCs de escritorio con recursos moderados\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama pull granite4:tiny\n",
    "```\n",
    "\n",
    "#### Opci√≥n C: granite4:latest\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Tama√±o: ~18GB\n",
    "- RAM necesaria: 16GB o m√°s\n",
    "- Velocidad: M√°s lenta, pero mejor calidad\n",
    "- Ideal para: Workstations potentes, cuando necesit√°s la mejor calidad\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama pull granite4:latest\n",
    "```\n",
    "\n",
    "### Entendiendo el Comando\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama pull granite4:micro\n",
    "```\n",
    "\n",
    "- `docker exec`: Ejecuta un comando dentro de un contenedor que ya est√° corriendo\n",
    "- `-it`: Modo interactivo con terminal (para ver el progreso de la descarga)\n",
    "- `ollama`: Nombre del contenedor donde queremos ejecutar el comando\n",
    "- `ollama pull granite4:micro`: El comando espec√≠fico de Ollama para descargar un modelo\n",
    "\n",
    "La descarga puede tardar varios minutos. Vas a ver una barra de progreso.\n",
    "\n",
    "### Verificar que el Modelo se Descarg√≥\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama list\n",
    "```\n",
    "\n",
    "Deber√≠as ver algo como:\n",
    "```\n",
    "NAME                  ID              SIZE      MODIFIED\n",
    "granite4:micro        abc123def456    1.7 GB    2 minutes ago\n",
    "```\n",
    "\n",
    "### Probar el Modelo Interactivamente\n",
    "\n",
    "Antes de integrarlo con n8n, es buena idea probarlo para verificar que funciona:\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama run granite4:micro\n",
    "```\n",
    "\n",
    "Esto abre una sesi√≥n interactiva. Pod√©s escribir consultas y el modelo va a responder. Por ejemplo, prob√°:\n",
    "\n",
    "```\n",
    ">>> Hola, ¬øc√≥mo est√°s?\n",
    "```\n",
    "\n",
    "o\n",
    "\n",
    "```\n",
    ">>> Extrae las entidades nombradas de: Mar√≠a Garc√≠a trabaja en Microsoft Argentina\n",
    "```\n",
    "\n",
    "Para salir de la sesi√≥n interactiva, escrib√≠:\n",
    "```\n",
    "/bye\n",
    "```\n",
    "\n",
    "### Comandos √ötiles de Ollama\n",
    "\n",
    "```bash\n",
    "# Listar modelos instalados\n",
    "docker exec -it ollama ollama list\n",
    "\n",
    "# Ver informaci√≥n detallada de un modelo\n",
    "docker exec -it ollama ollama show granite4:micro\n",
    "\n",
    "# Eliminar un modelo (para liberar espacio)\n",
    "docker exec -it ollama ollama rm granite4:micro\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 4: Configuraci√≥n Inicial de n8n\n",
    "\n",
    "### Acceder a n8n\n",
    "\n",
    "Abr√≠ tu navegador web y and√° a:\n",
    "\n",
    "```\n",
    "http://localhost:5678\n",
    "```\n",
    "\n",
    "### Primera Configuraci√≥n\n",
    "\n",
    "Si es la primera vez que acced√©s a n8n, vas a ver una pantalla de bienvenida. \n",
    "\n",
    "1. **Email:** Ingres√° un email (puede ser cualquiera, es solo para tu sesi√≥n local)\n",
    "2. **First name y Last name:** Tu nombre\n",
    "3. **Password:** Eleg√≠ una contrase√±a segura\n",
    "4. Click en **\"Get Started\"**\n",
    "\n",
    "**Nota:** Esta configuraci√≥n se guarda en el volumen Docker `n8n_data`. Si elimin√°s ese volumen, vas a perder tu usuario y tus workflows.\n",
    "\n",
    "### Interfaz de n8n\n",
    "\n",
    "Vas a ver el dashboard de n8n con:\n",
    "- **Workflows:** Lista de tus workflows (vac√≠a por ahora)\n",
    "- **Credentials:** Donde guard√°s claves API y configuraciones\n",
    "- **Executions:** Historial de ejecuciones de workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 5: Construir el Workflow de NLP\n",
    "\n",
    "Ahora viene la parte central del proyecto: construir el workflow que va a procesar las solicitudes de NLP. En lugar de importar un archivo JSON, vamos a construirlo paso a paso para que entiendas c√≥mo funciona cada componente.\n",
    "\n",
    "### Crear un Nuevo Workflow\n",
    "\n",
    "1. En n8n, click en el bot√≥n **\"+ Add workflow\"** (esquina superior derecha)\n",
    "2. Dale un nombre al workflow: **\"Asistente NLP\"**\n",
    "3. Vas a ver un canvas en blanco donde vamos a armar el flujo\n",
    "\n",
    "### Arquitectura del Workflow\n",
    "\n",
    "Nuestro workflow va a tener 5 nodos conectados en secuencia:\n",
    "\n",
    "```\n",
    "1. Webhook           ‚Üí    Recibe solicitudes HTTP POST\n",
    "2. Extraer Mensaje   ‚Üí    Extrae el campo \"mensaje\" del JSON\n",
    "3. Detectar Tarea    ‚Üí    Identifica qu√© tarea de NLP hacer\n",
    "4. Ollama            ‚Üí    Env√≠a el prompt al modelo\n",
    "5. Formatear         ‚Üí    Prepara la respuesta final\n",
    "```\n",
    "\n",
    "### Nodo 1: Webhook (Punto de Entrada)\n",
    "\n",
    "El webhook es el punto de entrada de nuestro sistema. Va a recibir solicitudes HTTP POST con las consultas del usuario.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. Click en **\"+ Add first step\"** (en el canvas vac√≠o)\n",
    "2. En el buscador, escrib√≠ **\"Webhook\"**\n",
    "3. Seleccion√° **\"Webhook\"** de la categor√≠a \"Core Nodes\"\n",
    "4. Configur√° el nodo:\n",
    "   - **HTTP Method:** POST\n",
    "   - **Path:** asistente-nlp\n",
    "   - **Response Mode:** Last Node\n",
    "   - Dej√° el resto como est√°\n",
    "\n",
    "**¬øQu√© hace este nodo?**\n",
    "\n",
    "Crea un endpoint HTTP en: `http://localhost:5678/webhook/asistente-nlp`\n",
    "\n",
    "Cuando alguien env√≠a un POST a esa URL con un JSON como:\n",
    "```json\n",
    "{\"mensaje\": \"Extrae entidades de: Mar√≠a vive en Buenos Aires\"}\n",
    "```\n",
    "\n",
    "El webhook lo recibe y pasa los datos al siguiente nodo.\n",
    "\n",
    "### Nodo 2: Extraer Mensaje\n",
    "\n",
    "Este nodo va a extraer el campo \"mensaje\" del JSON recibido y tambi√©n va a agregar un timestamp.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. Hover sobre el webhook y click en el **+** que aparece a la derecha\n",
    "2. Busc√° y seleccion√° **\"Edit Fields (Set)\"**\n",
    "3. Cambi√° el nombre del nodo a: **\"Extraer Mensaje\"**\n",
    "4. En **\"Fields to Set\"**, agreg√° dos campos:\n",
    "\n",
    "   **Campo 1:**\n",
    "   - **Name:** mensaje_usuario\n",
    "   - **Type:** String\n",
    "   - **Value:** `{{ $json.body.mensaje || '' }}`\n",
    "   \n",
    "   **Campo 2:**\n",
    "   - **Name:** timestamp\n",
    "   - **Type:** String  \n",
    "   - **Value:** `{{ $now.toISO() }}`\n",
    "\n",
    "**¬øQu√© hace este nodo?**\n",
    "\n",
    "- Extrae el campo `mensaje` del body del request\n",
    "- Crea un timestamp con la hora actual\n",
    "- Pasa estos datos al siguiente nodo\n",
    "\n",
    "La sintaxis `{{ }}` es la forma de acceder a datos en n8n. Es similar a templates en otros frameworks.\n",
    "\n",
    "### Nodo 3: Detectar Tarea NLP\n",
    "\n",
    "Este es el cerebro de nuestro sistema. Va a analizar el mensaje del usuario y decidir qu√© tipo de tarea de NLP quiere realizar, construyendo un prompt especializado.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. Click en el **+** despu√©s de \"Extraer Mensaje\"\n",
    "2. Busc√° y seleccion√° **\"Code\"**\n",
    "3. Cambi√° el nombre a: **\"Detectar Tarea NLP\"**\n",
    "4. Seleccion√° **\"Run Once for All Items\"** en Mode\n",
    "5. En el editor de c√≥digo JavaScript, peg√° el siguiente c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo JavaScript para el nodo \"Detectar Tarea NLP\"\n",
    "# Copiar y pegar en el editor de n8n\n",
    "\n",
    "\"\"\"\n",
    "const inputData = $input.first().json;\n",
    "const mensaje = (inputData.mensaje_usuario || '').toString().toLowerCase();\n",
    "const timestamp = inputData.timestamp;\n",
    "\n",
    "let prompt_final = \"\";\n",
    "let tarea_detectada = \"general\";\n",
    "let instrucciones = \"\";\n",
    "\n",
    "// Detecci√≥n de tarea NER\n",
    "if (mensaje.includes(\"ner\") || mensaje.includes(\"entidades\") || mensaje.includes(\"nombres\")) {\n",
    "  tarea_detectada = \"NER\";\n",
    "  instrucciones = \"Extrae todas las entidades nombradas y clasif√≠calas.\";\n",
    "  prompt_final = `Eres un experto en Named Entity Recognition (NER).\n",
    "\n",
    "Tarea: Extrae TODAS las entidades nombradas del texto y clasif√≠calas en:\n",
    "- PERSONA: nombres de personas\n",
    "- ORGANIZACI√ìN: empresas, instituciones\n",
    "- LUGAR: ciudades, pa√≠ses, lugares\n",
    "- FECHA: fechas, per√≠odos temporales\n",
    "- CANTIDAD: n√∫meros, porcentajes, montos\n",
    "\n",
    "Formato de respuesta:\n",
    "Entidad | Tipo | Contexto\n",
    "\n",
    "Texto a analizar:\n",
    "${mensaje}`;\n",
    "\n",
    "// Detecci√≥n de an√°lisis de sentimiento\n",
    "} else if (mensaje.includes(\"sentimiento\") || mensaje.includes(\"sentiment\") || mensaje.includes(\"emoci√≥n\")) {\n",
    "  tarea_detectada = \"An√°lisis de Sentimiento\";\n",
    "  instrucciones = \"Analiza el sentimiento del texto.\";\n",
    "  prompt_final = `Eres un experto en An√°lisis de Sentimiento.\n",
    "\n",
    "Tarea: Analiza el sentimiento del siguiente texto.\n",
    "\n",
    "Clasif√≠calo como:\n",
    "- POSITIVO\n",
    "- NEGATIVO\n",
    "- NEUTRAL\n",
    "\n",
    "Proporciona:\n",
    "1. Clasificaci√≥n del sentimiento\n",
    "2. Nivel de confianza (0-100%)\n",
    "3. Palabras clave que indican el sentimiento\n",
    "4. Explicaci√≥n breve\n",
    "\n",
    "Texto a analizar:\n",
    "${mensaje}`;\n",
    "\n",
    "// Detecci√≥n de sumarizaci√≥n\n",
    "} else if (mensaje.includes(\"resume\") || mensaje.includes(\"resumen\") || mensaje.includes(\"sumari\")) {\n",
    "  tarea_detectada = \"Sumarizaci√≥n\";\n",
    "  instrucciones = \"Resume el texto en puntos clave.\";\n",
    "  prompt_final = `Eres un experto en Sumarizaci√≥n de textos.\n",
    "\n",
    "Tarea: Resume el siguiente texto de forma concisa.\n",
    "\n",
    "Proporciona:\n",
    "1. Resumen en 3-5 puntos clave\n",
    "2. Idea principal\n",
    "3. Longitud aproximada: 20% del texto original\n",
    "\n",
    "Texto a analizar:\n",
    "${mensaje}`;\n",
    "\n",
    "// Detecci√≥n de clasificaci√≥n\n",
    "} else if (mensaje.includes(\"clasifica\") || mensaje.includes(\"categor√≠a\") || mensaje.includes(\"tipo de texto\")) {\n",
    "  tarea_detectada = \"Clasificaci√≥n\";\n",
    "  instrucciones = \"Clasifica el tipo y tema del texto.\";\n",
    "  prompt_final = `Eres un experto en Clasificaci√≥n de Textos.\n",
    "\n",
    "Tarea: Clasifica el siguiente texto.\n",
    "\n",
    "Proporciona:\n",
    "1. Tipo de texto (noticia, opini√≥n, t√©cnico, narrativo, etc.)\n",
    "2. Tema principal\n",
    "3. Temas secundarios\n",
    "4. Nivel de formalidad (formal/informal)\n",
    "5. Audiencia objetivo\n",
    "\n",
    "Texto a analizar:\n",
    "${mensaje}`;\n",
    "\n",
    "// Detecci√≥n de extracci√≥n de keywords\n",
    "} else if (mensaje.includes(\"palabras clave\") || mensaje.includes(\"keywords\") || mensaje.includes(\"t√©rminos importantes\")) {\n",
    "  tarea_detectada = \"Extracci√≥n de Keywords\";\n",
    "  instrucciones = \"Extrae las palabras clave m√°s importantes.\";\n",
    "  prompt_final = `Eres un experto en Extracci√≥n de Palabras Clave.\n",
    "\n",
    "Tarea: Extrae las palabras clave m√°s relevantes del texto.\n",
    "\n",
    "Proporciona:\n",
    "1. Top 10 palabras clave\n",
    "2. Relevancia de cada una (Alta/Media/Baja)\n",
    "3. Bigramas importantes (frases de 2 palabras)\n",
    "4. Tema central\n",
    "\n",
    "Texto a analizar:\n",
    "${mensaje}`;\n",
    "\n",
    "// Ayuda\n",
    "} else if (mensaje.includes(\"ayuda\") || mensaje.includes(\"help\") || mensaje.includes(\"qu√© puedes hacer\")) {\n",
    "  tarea_detectada = \"Ayuda\";\n",
    "  prompt_final = `ASISTENTE NLP - TAREAS DISPONIBLES\n",
    "\n",
    "Puedo ayudarte con las siguientes tareas de Procesamiento de Lenguaje Natural:\n",
    "\n",
    "1. NER (Named Entity Recognition)\n",
    "   Comando: \"Extrae entidades de: [tu texto]\"\n",
    "   Ejemplo: \"Extrae entidades de: Juan viaj√≥ a Madrid en 2024\"\n",
    "\n",
    "2. An√°lisis de Sentimiento\n",
    "   Comando: \"Analiza el sentimiento de: [tu texto]\"\n",
    "   Ejemplo: \"Analiza el sentimiento de: Me encanta este producto\"\n",
    "\n",
    "3. Sumarizaci√≥n\n",
    "   Comando: \"Resume: [tu texto]\"\n",
    "   Ejemplo: \"Resume: [texto largo]\"\n",
    "\n",
    "4. Clasificaci√≥n de Texto\n",
    "   Comando: \"Clasifica: [tu texto]\"\n",
    "   Ejemplo: \"Clasifica: Este art√≠culo habla sobre inteligencia artificial\"\n",
    "\n",
    "5. Extracci√≥n de Palabras Clave\n",
    "   Comando: \"Palabras clave de: [tu texto]\"\n",
    "   Ejemplo: \"Palabras clave de: [tu texto]\"\n",
    "\n",
    "Tip: Simplemente escribe tu solicitud de forma natural`;\n",
    "\n",
    "// Caso general\n",
    "} else {\n",
    "  tarea_detectada = \"Consulta General\";\n",
    "  instrucciones = \"Responde la consulta del usuario.\";\n",
    "  prompt_final = mensaje;\n",
    "}\n",
    "\n",
    "// Retornar datos estructurados\n",
    "return [{\n",
    "  json: {\n",
    "    prompt: prompt_final,\n",
    "    tarea: tarea_detectada,\n",
    "    instrucciones: instrucciones,\n",
    "    mensaje_original: mensaje,\n",
    "    timestamp: timestamp\n",
    "  }\n",
    "}];\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬øQu√© hace este c√≥digo?**\n",
    "\n",
    "1. Lee el mensaje del usuario\n",
    "2. Lo convierte a min√∫sculas para facilitar la detecci√≥n\n",
    "3. Busca palabras clave (\"ner\", \"sentimiento\", \"resume\", etc.)\n",
    "4. Seg√∫n las palabras encontradas, construye un prompt especializado para esa tarea\n",
    "5. Retorna un objeto con el prompt, el tipo de tarea detectada y metadata\n",
    "\n",
    "Por ejemplo, si el usuario escribe:\n",
    "```\n",
    "Extrae entidades de: Mar√≠a trabaja en Google\n",
    "```\n",
    "\n",
    "El c√≥digo detecta \"entidades\" y construye un prompt especializado que le pide al modelo que act√∫e como experto en NER.\n",
    "\n",
    "### Nodo 4: Ollama (Conexi√≥n con el Modelo)\n",
    "\n",
    "Este nodo env√≠a el prompt al modelo de lenguaje y recibe la respuesta.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. Click en el **+** despu√©s de \"Detectar Tarea NLP\"\n",
    "2. Busc√° y seleccion√° **\"HTTP Request\"**\n",
    "3. Cambi√° el nombre a: **\"Ollama\"**\n",
    "4. Configur√°:\n",
    "   - **Method:** POST\n",
    "   - **URL:** `http://ollama:11434/api/generate`\n",
    "   - **Authentication:** None\n",
    "   - **Send Body:** Activado\n",
    "   - **Body Content Type:** JSON\n",
    "   - **Specify Body:** Using JSON\n",
    "5. En el campo **JSON**, peg√°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON para el nodo Ollama\n",
    "# Copiar en el campo JSON del HTTP Request\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "  \"model\": \"granite4:micro\",\n",
    "  \"prompt\": \"={{ $json.prompt }}\",\n",
    "  \"stream\": false,\n",
    "  \"temperature\": 0.7\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante:** Si descargaste otro tama√±o de modelo (tiny o latest), cambi√° `\"granite4:micro\"` por el que descargaste.\n",
    "\n",
    "**¬øQu√© hace este nodo?**\n",
    "\n",
    "Env√≠a un request POST a la API de Ollama con:\n",
    "- **model:** El modelo a usar\n",
    "- **prompt:** El prompt construido por el nodo anterior (accede con `$json.prompt`)\n",
    "- **stream:** false (queremos la respuesta completa, no por streaming)\n",
    "- **temperature:** 0.7 (controla la creatividad del modelo, 0=determinista, 1=creativo)\n",
    "\n",
    "**¬øPor qu√© `http://ollama:11434` y no `http://localhost:11434`?**\n",
    "\n",
    "Dentro de la red Docker, los contenedores se refieren entre s√≠ por su nombre. n8n est√° en un contenedor y Ollama en otro. Ambos est√°n en la red `n8n-network`, entonces n8n puede acceder a Ollama usando `http://ollama:11434`.\n",
    "\n",
    "### Nodo 5: Formatear Respuesta\n",
    "\n",
    "Este nodo final formatea la respuesta para devolver al usuario.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. Click en el **+** despu√©s de \"Ollama\"\n",
    "2. Seleccion√° **\"Edit Fields (Set)\"**\n",
    "3. Cambi√° el nombre a: **\"Formatear Respuesta\"**\n",
    "4. Agreg√° los siguientes campos:\n",
    "\n",
    "   **Campo 1:**\n",
    "   - **Name:** respuesta\n",
    "   - **Type:** String\n",
    "   - **Value:** `{{ $json.response }}`\n",
    "   \n",
    "   **Campo 2:**\n",
    "   - **Name:** tarea_realizada\n",
    "   - **Type:** String\n",
    "   - **Value:** `{{ $('Detectar Tarea NLP').item.json.tarea }}`\n",
    "   \n",
    "   **Campo 3:**\n",
    "   - **Name:** mensaje_original\n",
    "   - **Type:** String\n",
    "   - **Value:** `{{ $('Detectar Tarea NLP').item.json.mensaje_original }}`\n",
    "   \n",
    "   **Campo 4:**\n",
    "   - **Name:** timestamp\n",
    "   - **Type:** String\n",
    "   - **Value:** `{{ $now.toISO() }}`\n",
    "\n",
    "**¬øQu√© hace este nodo?**\n",
    "\n",
    "Crea un objeto JSON estructurado con:\n",
    "- La respuesta del modelo\n",
    "- Qu√© tipo de tarea se realiz√≥\n",
    "- El mensaje original del usuario\n",
    "- Un timestamp de cu√°ndo se complet√≥\n",
    "\n",
    "Este es el formato que se devuelve al usuario.\n",
    "\n",
    "### Guardar y Activar el Workflow\n",
    "\n",
    "1. Click en **\"Save\"** (esquina superior derecha)\n",
    "2. **MUY IMPORTANTE:** Activ√° el workflow con el toggle **\"Active\"** (debe ponerse en verde/azul)\n",
    "\n",
    "Si no activ√°s el workflow, no va a responder a las solicitudes.\n",
    "\n",
    "### Probar el Workflow desde n8n\n",
    "\n",
    "Antes de probar desde fuera, pod√©s probar directamente en n8n:\n",
    "\n",
    "1. Click en el nodo **\"Webhook\"**\n",
    "2. Click en **\"Listen for Test Event\"**\n",
    "3. En otra pesta√±a del navegador, o desde tu terminal, envi√° un request:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://localhost:5678/webhook/asistente-nlp \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"mensaje\": \"Extrae entidades de: Mar√≠a trabaja en Google en Buenos Aires\"}'\n",
    "```\n",
    "\n",
    "4. Vas a ver que n8n recibe el request y pod√©s hacer click en **\"Execute Workflow\"** para ejecutar todo el flujo\n",
    "5. Observ√° c√≥mo los datos van pasando por cada nodo\n",
    "\n",
    "Esto te permite debuggear y ver exactamente qu√© est√° pasando en cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 6: Crear la Interfaz de Usuario\n",
    "\n",
    "Ahora que ten√©s el workflow funcionando, necesit√°s una forma para que los usuarios interact√∫en con √©l. Vamos a crear una interfaz web simple.\n",
    "\n",
    "### Opci√≥n A: Interfaz HTML B√°sica\n",
    "\n",
    "Cre√° un archivo `index.html` en tu directorio del proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenido del archivo index.html\n",
    "# Guardar en tu directorio del proyecto\n",
    "\n",
    "\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Asistente NLP</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            max-width: 800px;\n",
    "            margin: 50px auto;\n",
    "            padding: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }\n",
    "        h1 {\n",
    "            color: #333;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .info-box {\n",
    "            background-color: #fff;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 5px;\n",
    "            padding: 20px;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        textarea {\n",
    "            width: 100%;\n",
    "            padding: 10px;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 5px;\n",
    "            font-size: 14px;\n",
    "            font-family: Arial, sans-serif;\n",
    "            resize: vertical;\n",
    "        }\n",
    "        button {\n",
    "            background-color: #007bff;\n",
    "            color: white;\n",
    "            padding: 12px 30px;\n",
    "            border: none;\n",
    "            border-radius: 5px;\n",
    "            font-size: 16px;\n",
    "            cursor: pointer;\n",
    "            display: block;\n",
    "            margin: 20px auto;\n",
    "        }\n",
    "        button:hover {\n",
    "            background-color: #0056b3;\n",
    "        }\n",
    "        #respuesta {\n",
    "            background-color: #f9f9f9;\n",
    "        }\n",
    "        .example {\n",
    "            color: #666;\n",
    "            font-size: 13px;\n",
    "            margin: 5px 0;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Asistente de Procesamiento de Lenguaje Natural</h1>\n",
    "    \n",
    "    <div class=\"info-box\">\n",
    "        <h3>¬øC√≥mo usar el asistente?</h3>\n",
    "        <p>Inici√° tu mensaje con alguna de estas palabras clave:</p>\n",
    "        <ul>\n",
    "            <li><strong>\"ner\"</strong> o <strong>\"entidades\"</strong> ‚Üí Extracci√≥n de entidades nombradas</li>\n",
    "            <li><strong>\"sentimiento\"</strong> ‚Üí An√°lisis de sentimiento</li>\n",
    "            <li><strong>\"resumen\"</strong> o <strong>\"resume\"</strong> ‚Üí Sumarizaci√≥n</li>\n",
    "            <li><strong>\"clasifica\"</strong> ‚Üí Clasificaci√≥n de texto</li>\n",
    "            <li><strong>\"palabras clave\"</strong> ‚Üí Extracci√≥n de keywords</li>\n",
    "            <li><strong>\"ayuda\"</strong> ‚Üí Ver informaci√≥n completa</li>\n",
    "        </ul>\n",
    "        <p class=\"example\"><strong>Ejemplo:</strong> Extrae entidades de: Mar√≠a Garc√≠a trabaja en Microsoft Argentina</p>\n",
    "    </div>\n",
    "\n",
    "    <div>\n",
    "        <h3>Tu consulta:</h3>\n",
    "        <textarea id=\"mensaje\" rows=\"6\" placeholder=\"Escrib√≠ ac√° tu consulta o texto para analizar...\"></textarea>\n",
    "    </div>\n",
    "\n",
    "    <button onclick=\"enviar()\">Enviar</button>\n",
    "\n",
    "    <div>\n",
    "        <h3>Respuesta del asistente:</h3>\n",
    "        <textarea id=\"respuesta\" rows=\"15\" readonly></textarea>\n",
    "    </div>\n",
    "\n",
    "    <p style=\"text-align: center; color: #666; margin-top: 30px;\">\n",
    "        Asistente NLP - Procesamiento de Lenguaje Natural con n8n + Ollama\n",
    "    </p>\n",
    "\n",
    "    <script>\n",
    "        async function enviar() {\n",
    "            const mensaje = document.getElementById('mensaje').value;\n",
    "            const respuestaTextarea = document.getElementById('respuesta');\n",
    "\n",
    "            if (!mensaje.trim()) {\n",
    "                respuestaTextarea.value = 'Por favor, escrib√≠ tu consulta antes de enviar.';\n",
    "                return;\n",
    "            }\n",
    "\n",
    "            respuestaTextarea.value = 'Procesando tu consulta...\\n\\nEsto puede tomar unos segundos.';\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('http://localhost:5678/webhook/asistente-nlp', {\n",
    "                    method: 'POST',\n",
    "                    headers: { 'Content-Type': 'application/json' },\n",
    "                    body: JSON.stringify({ mensaje: mensaje })\n",
    "                });\n",
    "\n",
    "                if (!response.ok) {\n",
    "                    throw new Error(`HTTP ${response.status}: ${await response.text()}`);\n",
    "                }\n",
    "                \n",
    "                const data = await response.json();\n",
    "                \n",
    "                let output = '';\n",
    "                if (data.respuesta) {\n",
    "                    output += data.respuesta;\n",
    "                } else {\n",
    "                    output = JSON.stringify(data, null, 2);\n",
    "                }\n",
    "                \n",
    "                if (data.tarea_realizada) {\n",
    "                    output += '\\n\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n';\n",
    "                    output += 'Tarea: ' + data.tarea_realizada + '\\n';\n",
    "                    output += 'Timestamp: ' + data.timestamp;\n",
    "                }\n",
    "                \n",
    "                respuestaTextarea.value = output;\n",
    "            } catch (error) {\n",
    "                respuestaTextarea.value = 'Error al procesar la solicitud:\\n\\n' + error.message + \n",
    "                    '\\n\\nVerific√° que el workflow est√© activo en n8n y que Ollama est√© ejecut√°ndose.';\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Permitir enviar con Ctrl+Enter\n",
    "        document.getElementById('mensaje').addEventListener('keydown', function(e) {\n",
    "            if (e.ctrlKey && e.key === 'Enter') {\n",
    "                enviar();\n",
    "            }\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar esta interfaz:\n",
    "\n",
    "1. Abr√≠ el archivo `index.html` con tu navegador (doble click o arrastrar al navegador)\n",
    "2. Escrib√≠ tu consulta\n",
    "3. Click en \"Enviar\"\n",
    "\n",
    "### Opci√≥n B: Interfaz con Streamlit (M√°s Avanzada)\n",
    "\n",
    "Ya conoc√©s Streamlit de clases anteriores. Pod√©s crear una interfaz m√°s profesional.\n",
    "\n",
    "Cre√° un archivo `app_streamlit.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_streamlit.py\n",
    "import streamlit as st\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Asistente NLP\",\n",
    "    page_icon=\"ü§ñ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"Asistente de Procesamiento de Lenguaje Natural\")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Sidebar con informaci√≥n\n",
    "with st.sidebar:\n",
    "    st.header(\"Tareas Disponibles\")\n",
    "    st.markdown(\"\"\"\n",
    "    - **NER**: Extracci√≥n de entidades\n",
    "    - **Sentimiento**: An√°lisis emocional\n",
    "    - **Resumen**: Sumarizaci√≥n de textos\n",
    "    - **Clasificaci√≥n**: Tipo y tema\n",
    "    - **Keywords**: Palabras clave\n",
    "    \"\"\")\n",
    "    \n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"**Ejemplos:**\")\n",
    "    st.code('Extrae entidades de: Juan vive en Madrid')\n",
    "    st.code('Analiza el sentimiento de: Me encant√≥')\n",
    "\n",
    "# √Årea principal\n",
    "mensaje = st.text_area(\n",
    "    \"Tu consulta:\",\n",
    "    height=150,\n",
    "    placeholder=\"Escrib√≠ ac√° tu consulta o texto para analizar...\"\n",
    ")\n",
    "\n",
    "if st.button(\"Analizar\", use_container_width=True, type=\"primary\"):\n",
    "    if mensaje.strip():\n",
    "        with st.spinner('Procesando tu consulta...'):\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    \"http://localhost:5678/webhook/asistente-nlp\",\n",
    "                    json={\"mensaje\": mensaje},\n",
    "                    timeout=60\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    \n",
    "                    st.success(\"An√°lisis completado\")\n",
    "                    \n",
    "                    st.markdown(\"### Resultado:\")\n",
    "                    st.markdown(data.get('respuesta', 'Sin respuesta'))\n",
    "                    \n",
    "                    st.markdown(\"---\")\n",
    "                    col1, col2 = st.columns(2)\n",
    "                    with col1:\n",
    "                        st.metric(\"Tarea\", data.get('tarea_realizada', 'N/A'))\n",
    "                    with col2:\n",
    "                        timestamp = data.get('timestamp', '')\n",
    "                        if timestamp:\n",
    "                            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))\n",
    "                            st.metric(\"Hora\", dt.strftime('%H:%M:%S'))\n",
    "                else:\n",
    "                    st.error(f\"Error HTTP {response.status_code}\")\n",
    "                    st.code(response.text)\n",
    "                    \n",
    "            except requests.exceptions.ConnectionError:\n",
    "                st.error(\"No se pudo conectar con n8n. Verific√° que est√© corriendo.\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error: {str(e)}\")\n",
    "    else:\n",
    "        st.warning(\"Por favor, escrib√≠ tu consulta antes de enviar.\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Asistente NLP - n8n + Ollama + Granite 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar la app Streamlit:\n",
    "\n",
    "```bash\n",
    "# Instalar Streamlit (si no lo ten√©s)\n",
    "pip install streamlit requests\n",
    "\n",
    "# Ejecutar\n",
    "streamlit run app_streamlit.py\n",
    "```\n",
    "\n",
    "La app se va a abrir en `http://localhost:8501`\n",
    "\n",
    "### Pruebas Sugeridas\n",
    "\n",
    "Prob√° tu asistente con estas consultas:\n",
    "\n",
    "**1. NER:**\n",
    "```\n",
    "Extrae entidades de: Mar√≠a Garc√≠a trabaja en Microsoft Argentina en Buenos Aires desde marzo de 2023\n",
    "```\n",
    "\n",
    "**2. Sentimiento:**\n",
    "```\n",
    "Analiza el sentimiento de: El curso me pareci√≥ excelente, aprend√≠ much√≠simo y los profesores fueron muy claros en sus explicaciones\n",
    "```\n",
    "\n",
    "**3. Resumen:**\n",
    "```\n",
    "Resume: Docker es una plataforma de containerizaci√≥n que permite empaquetar aplicaciones con todas sus dependencias. Los contenedores son m√°s livianos que las m√°quinas virtuales porque comparten el kernel del sistema operativo. Docker Compose facilita la orquestaci√≥n de m√∫ltiples contenedores, permitiendo definir toda la infraestructura en un archivo YAML.\n",
    "```\n",
    "\n",
    "**4. Clasificaci√≥n:**\n",
    "```\n",
    "Clasifica: La inteligencia artificial est√° revolucionando el procesamiento del lenguaje natural mediante el uso de modelos de lenguaje grandes\n",
    "```\n",
    "\n",
    "**5. Keywords:**\n",
    "```\n",
    "Palabras clave de: El procesamiento del lenguaje natural es una rama de la inteligencia artificial que se enfoca en la interacci√≥n entre computadoras y humanos usando lenguaje natural\n",
    "```\n",
    "\n",
    "**6. Ayuda:**\n",
    "```\n",
    "ayuda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 7: Crear una Imagen Docker Personalizada\n",
    "\n",
    "Hasta ahora usamos im√°genes pre-construidas (n8n y Ollama). Ahora vas a aprender a crear tu propia imagen Docker que contenga tu aplicaci√≥n Streamlit.\n",
    "\n",
    "### ¬øPor qu√© crear una imagen?\n",
    "\n",
    "- **Portabilidad:** Pod√©s compartir tu aplicaci√≥n completa, no solo el c√≥digo\n",
    "- **Reproducibilidad:** La imagen incluye todas las dependencias exactas\n",
    "- **Despliegue:** Facilita el deployment en servidores\n",
    "- **Versionado:** Pod√©s tener m√∫ltiples versiones (v1.0, v1.1, v2.0)\n",
    "\n",
    "### Crear el Dockerfile\n",
    "\n",
    "Un Dockerfile es un archivo de texto con instrucciones para construir una imagen.\n",
    "\n",
    "Cre√° un archivo llamado `Dockerfile` (sin extensi√≥n) en tu proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenido del Dockerfile\n",
    "\n",
    "\"\"\"\n",
    "# Imagen base: Python 3.11 slim (versi√≥n liviana)\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Metadata de la imagen\n",
    "LABEL maintainer=\"tu_email@example.com\"\n",
    "LABEL description=\"Asistente NLP con Streamlit\"\n",
    "LABEL version=\"1.0\"\n",
    "\n",
    "# Directorio de trabajo dentro del contenedor\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar archivo de dependencias\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Instalar dependencias Python\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copiar archivos de la aplicaci√≥n\n",
    "COPY app_streamlit.py .\n",
    "\n",
    "# Exponer puerto de Streamlit\n",
    "EXPOSE 8501\n",
    "\n",
    "# Comando para ejecutar la aplicaci√≥n\n",
    "CMD [\"streamlit\", \"run\", \"app_streamlit.py\", \"--server.address\", \"0.0.0.0\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el archivo requirements.txt\n",
    "\n",
    "Lista las dependencias Python de tu aplicaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenido de requirements.txt\n",
    "\n",
    "\"\"\"\n",
    "streamlit==1.32.0\n",
    "requests==2.31.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir la Imagen\n",
    "\n",
    "Desde tu directorio del proyecto, ejecut√°:\n",
    "\n",
    "```bash\n",
    "docker build -t asistente-nlp-frontend:v1.0 .\n",
    "```\n",
    "\n",
    "**¬øQu√© significa cada parte?**\n",
    "- `docker build`: Comando para construir una imagen\n",
    "- `-t asistente-nlp-frontend:v1.0`: Tag (nombre y versi√≥n) de la imagen\n",
    "- `.`: Contexto de build (directorio actual)\n",
    "\n",
    "El proceso puede tardar unos minutos. Docker va a:\n",
    "1. Descargar la imagen base Python\n",
    "2. Copiar tu c√≥digo\n",
    "3. Instalar las dependencias\n",
    "4. Crear la imagen final\n",
    "\n",
    "### Verificar la Imagen\n",
    "\n",
    "```bash\n",
    "docker images\n",
    "```\n",
    "\n",
    "Deber√≠as ver:\n",
    "```\n",
    "REPOSITORY                  TAG       SIZE\n",
    "asistente-nlp-frontend      v1.0      450MB\n",
    "```\n",
    "\n",
    "### Actualizar docker-compose.yml\n",
    "\n",
    "Agreg√° tu nueva imagen al docker-compose existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar al final de docker-compose.yml (despu√©s del servicio ollama)\n",
    "\n",
    "\"\"\"\n",
    "  streamlit-app:\n",
    "    image: asistente-nlp-frontend:v1.0\n",
    "    container_name: asistente-frontend\n",
    "    restart: unless-stopped\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    networks:\n",
    "      - n8n-network\n",
    "    depends_on:\n",
    "      - n8n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora reinici√° los servicios:\n",
    "\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "Ten√©s tres servicios corriendo:\n",
    "- **Ollama** en puerto 11434\n",
    "- **n8n** en puerto 5678  \n",
    "- **Streamlit** en puerto 8501\n",
    "\n",
    "### Compartir tu Imagen\n",
    "\n",
    "**Opci√≥n A: Guardar como archivo**\n",
    "\n",
    "```bash\n",
    "# Exportar imagen a archivo .tar\n",
    "docker save asistente-nlp-frontend:v1.0 -o asistente-nlp-frontend.tar\n",
    "\n",
    "# Comprimir (opcional)\n",
    "gzip asistente-nlp-frontend.tar\n",
    "```\n",
    "\n",
    "Ahora pod√©s compartir el archivo `.tar.gz`. Para importarlo en otra m√°quina:\n",
    "\n",
    "```bash\n",
    "docker load -i asistente-nlp-frontend.tar\n",
    "```\n",
    "\n",
    "**Opci√≥n B: Subir a Docker Hub**\n",
    "\n",
    "Docker Hub es un registro p√∫blico de im√°genes (como GitHub para c√≥digo).\n",
    "\n",
    "```bash\n",
    "# 1. Crear cuenta en hub.docker.com (gratis)\n",
    "\n",
    "# 2. Login desde terminal\n",
    "docker login\n",
    "\n",
    "# 3. Taggear con tu usuario\n",
    "docker tag asistente-nlp-frontend:v1.0 tuusuario/asistente-nlp-frontend:v1.0\n",
    "\n",
    "# 4. Subir a Docker Hub\n",
    "docker push tuusuario/asistente-nlp-frontend:v1.0\n",
    "```\n",
    "\n",
    "Ahora cualquiera puede descargar tu imagen con:\n",
    "```bash\n",
    "docker pull tuusuario/asistente-nlp-frontend:v1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 8: Despliegue en Servidores\n",
    "\n",
    "Docker se usa masivamente en servidores y en la nube. Esta secci√≥n te introduce a los conceptos de deployment en producci√≥n.\n",
    "\n",
    "### ¬øPor qu√© Desplegar en un Servidor?\n",
    "\n",
    "Hasta ahora tu aplicaci√≥n corre en tu m√°quina local. Para que otros puedan usarla necesit√°s:\n",
    "\n",
    "- **Disponibilidad 24/7:** Servidores que no se apagan\n",
    "- **Acceso p√∫blico:** Direcci√≥n IP p√∫blica o dominio\n",
    "- **Recursos:** Servidores con m√°s capacidad\n",
    "- **Confiabilidad:** Infraestructura con backups y redundancia\n",
    "\n",
    "### Docker en Servidores\n",
    "\n",
    "Docker es extremadamente popular en servidores porque:\n",
    "\n",
    "1. **Simplicidad:** El mismo `docker-compose.yml` funciona en tu laptop y en el servidor\n",
    "2. **Aislamiento:** M√∫ltiples aplicaciones pueden correr sin interferir entre s√≠\n",
    "3. **Escalabilidad:** Pod√©s replicar contenedores f√°cilmente\n",
    "4. **Portabilidad:** Migr√°s entre providers sin cambiar nada\n",
    "\n",
    "### Opciones de Hosting\n",
    "\n",
    "#### Proveedores Cloud Principales\n",
    "\n",
    "**1. DigitalOcean (Recomendado para empezar)**\n",
    "- **Droplets:** Servidores virtuales simples\n",
    "- **Costo:** Desde $6/mes\n",
    "- **Ventaja:** Muy f√°cil de usar, buena documentaci√≥n\n",
    "- **Ideal para:** Proyectos peque√±os, aprendizaje\n",
    "\n",
    "**2. Amazon Web Services (AWS)**\n",
    "- **EC2:** M√°quinas virtuales con Docker\n",
    "- **Lightsail:** Opci√≥n m√°s simple (similar a DigitalOcean)\n",
    "- **Costo:** Desde $3.50/mes (Lightsail)\n",
    "- **Ventaja:** Escalabilidad casi infinita\n",
    "- **Desventaja:** Curva de aprendizaje empinada\n",
    "\n",
    "**3. Google Cloud Platform (GCP)**\n",
    "- **Compute Engine:** VMs con Docker\n",
    "- **Cloud Run:** Deploy directo de contenedores (serverless)\n",
    "- **Ventaja:** Integraci√≥n con servicios de Google\n",
    "\n",
    "**4. Railway (Recomendado para estudiantes)**\n",
    "- **Ventaja:** $5 gratis por mes para estudiantes\n",
    "- **Deploy autom√°tico** desde GitHub\n",
    "- **Ideal para:** Prototipos, proyectos educativos\n",
    "\n",
    "### Proceso General de Despliegue\n",
    "\n",
    "El proceso es similar en todos los providers:\n",
    "\n",
    "**1. Crear un servidor**\n",
    "```bash\n",
    "# En el provider elegido:\n",
    "# - Seleccionar Ubuntu 22.04 LTS\n",
    "# - Elegir plan (m√≠nimo 2GB RAM)\n",
    "# - Configurar SSH key\n",
    "# - Crear servidor\n",
    "```\n",
    "\n",
    "**2. Conectarse por SSH**\n",
    "```bash\n",
    "ssh root@tu-servidor-ip\n",
    "```\n",
    "\n",
    "**3. Instalar Docker**\n",
    "```bash\n",
    "# Actualizar sistema\n",
    "apt update && apt upgrade -y\n",
    "\n",
    "# Instalar Docker\n",
    "curl -fsSL https://get.docker.com -o get-docker.sh\n",
    "sh get-docker.sh\n",
    "\n",
    "# Instalar Docker Compose\n",
    "apt install docker-compose -y\n",
    "```\n",
    "\n",
    "**4. Subir tu proyecto**\n",
    "```bash\n",
    "# Opci√≥n A: Clonar desde Git (recomendado)\n",
    "git clone https://github.com/tuusuario/asistente-nlp.git\n",
    "cd asistente-nlp\n",
    "\n",
    "# Opci√≥n B: Copiar archivos con SCP desde tu m√°quina\n",
    "# scp -r /ruta/local/proyecto root@servidor-ip:/root/\n",
    "```\n",
    "\n",
    "**5. Levantar servicios**\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "**6. Configurar firewall**\n",
    "```bash\n",
    "# Permitir puertos necesarios\n",
    "ufw allow 5678/tcp   # n8n\n",
    "ufw allow 8501/tcp   # Streamlit\n",
    "ufw allow 22/tcp     # SSH\n",
    "ufw enable\n",
    "```\n",
    "\n",
    "**7. Acceder a tu aplicaci√≥n**\n",
    "```\n",
    "http://tu-servidor-ip:8501  (Streamlit)\n",
    "http://tu-servidor-ip:5678  (n8n)\n",
    "```\n",
    "\n",
    "### Consideraciones de Producci√≥n\n",
    "\n",
    "Para un deployment serio consider√°:\n",
    "\n",
    "**Seguridad:**\n",
    "- Cambiar puertos por defecto\n",
    "- Usar variables de entorno para secrets\n",
    "- Configurar SSL/TLS (HTTPS)\n",
    "- Actualizar regularmente\n",
    "- Configurar fail2ban (protecci√≥n contra ataques)\n",
    "\n",
    "**Disponibilidad:**\n",
    "- Configurar backups autom√°ticos\n",
    "- Monitoreo de servicios\n",
    "- Logs centralizados\n",
    "- Alertas ante ca√≠das\n",
    "\n",
    "**Rendimiento:**\n",
    "- Usar un reverse proxy (Nginx)\n",
    "- Configurar l√≠mites de recursos\n",
    "- Cach√© cuando sea apropiado\n",
    "- CDN para contenido est√°tico\n",
    "\n",
    "### Costos Estimados\n",
    "\n",
    "Para este proyecto:\n",
    "\n",
    "**Opci√≥n B√°sica:**\n",
    "- DigitalOcean Droplet 2GB: $12/mes\n",
    "- Dominio: $10-15/a√±o\n",
    "- SSL: Gratis (Let's Encrypt)\n",
    "- **Total:** ~$13-15/mes\n",
    "\n",
    "**Opci√≥n Estudiante:**\n",
    "- Railway: $5 cr√©dito/mes (gratis con GitHub Student Pack)\n",
    "- **Total:** Gratis durante estudios\n",
    "\n",
    "### Pr√≥ximos Pasos en Deployment\n",
    "\n",
    "Para profundizar:\n",
    "\n",
    "1. **Dominio personalizado:** En lugar de IP, usar `asistente-nlp.tudominio.com`\n",
    "2. **HTTPS:** Configurar SSL con Let's Encrypt\n",
    "3. **CI/CD:** Deploy autom√°tico cuando hac√©s push a Git\n",
    "4. **Kubernetes:** Para proyectos grandes que necesitan escalar\n",
    "5. **Monitoring:** Grafana + Prometheus para observabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Soluci√≥n de Problemas Comunes\n",
    "\n",
    "### Docker no inicia\n",
    "\n",
    "**S√≠ntoma:** Errores al ejecutar comandos Docker\n",
    "\n",
    "**Soluci√≥n:**\n",
    "1. Verificar que Docker Desktop est√© corriendo\n",
    "2. En Windows, reiniciar el servicio Docker\n",
    "3. En Linux: `sudo systemctl restart docker`\n",
    "\n",
    "### Puerto en uso\n",
    "\n",
    "**S√≠ntoma:** Error \"port is already allocated\"\n",
    "\n",
    "**Soluci√≥n:**\n",
    "```bash\n",
    "# Ver qu√© est√° usando el puerto (ej: 5678)\n",
    "# Windows:\n",
    "netstat -ano | findstr :5678\n",
    "\n",
    "# Mac/Linux:\n",
    "lsof -i :5678\n",
    "\n",
    "# Matar el proceso o cambiar puerto en docker-compose.yml\n",
    "```\n",
    "\n",
    "### n8n no se conecta con Ollama\n",
    "\n",
    "**S√≠ntoma:** Timeout o error de conexi√≥n\n",
    "\n",
    "**Soluci√≥n:**\n",
    "1. Verificar que ambos contenedores est√©n UP: `docker-compose ps`\n",
    "2. Verificar la URL en el nodo HTTP Request: debe ser `http://ollama:11434` (NO localhost)\n",
    "3. Verificar que est√©n en la misma red: `docker network inspect nombreproyecto_n8n-network`\n",
    "\n",
    "### Modelo muy lento\n",
    "\n",
    "**S√≠ntoma:** Respuestas tardan minutos\n",
    "\n",
    "**Soluci√≥n:**\n",
    "1. Verificar uso de recursos: `docker stats`\n",
    "2. Si ten√©s poca RAM, usar un modelo m√°s chico (granite4:micro)\n",
    "3. Cerrar otras aplicaciones pesadas\n",
    "4. Aumentar timeout en el nodo HTTP Request\n",
    "\n",
    "### Sin espacio en disco\n",
    "\n",
    "**S√≠ntoma:** \"no space left on device\"\n",
    "\n",
    "**Soluci√≥n:**\n",
    "```bash\n",
    "# Limpiar im√°genes y contenedores sin usar\n",
    "docker system prune -a\n",
    "\n",
    "# Eliminar modelos de Ollama que no uses\n",
    "docker exec -it ollama ollama rm nombre_modelo\n",
    "```\n",
    "\n",
    "### Perd√≠ mis workflows\n",
    "\n",
    "**S√≠ntoma:** Despu√©s de `docker-compose down -v` se perdi√≥ todo\n",
    "\n",
    "**Prevenci√≥n:**\n",
    "- NUNCA uses `-v` a menos que quieras borrar datos\n",
    "- Export√° workflows regularmente desde n8n\n",
    "- Hac√© backups del volumen:\n",
    "```bash\n",
    "docker run --rm -v nombreproyecto_n8n_data:/data -v $(pwd):/backup \\\n",
    "  ubuntu tar czf /backup/n8n_backup.tar.gz /data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicios Pr√°cticos\n",
    "\n",
    "### Ejercicio 1: Experimentaci√≥n con Modelos\n",
    "\n",
    "**Objetivo:** Comparar diferentes tama√±os de Granite 4\n",
    "\n",
    "1. Descarg√° granite4:micro, granite4:tiny\n",
    "2. Prob√° la misma consulta con ambos\n",
    "3. Med√≠ tiempo de respuesta y calidad\n",
    "4. Document√° tus conclusiones\n",
    "\n",
    "### Ejercicio 2: Extender el Workflow\n",
    "\n",
    "**Objetivo:** Agregar nueva tarea de NLP\n",
    "\n",
    "Implement√° soporte para **Correcci√≥n gramatical**:\n",
    "1. Edit√° el nodo \"Detectar Tarea NLP\"\n",
    "2. Agreg√° detecci√≥n para \"corrige\" o \"correcci√≥n\"\n",
    "3. Cre√° un prompt especializado\n",
    "4. Prob√° con texto con errores\n",
    "\n",
    "### Ejercicio 3: Mejorar la Interfaz\n",
    "\n",
    "**Objetivo:** Agregar funcionalidades a Streamlit\n",
    "\n",
    "1. Implement√° historial de consultas\n",
    "2. Agreg√° estad√≠sticas de uso\n",
    "3. Permit√≠ exportar resultados a TXT/JSON\n",
    "\n",
    "### Ejercicio 4: Despliegue Local Completo\n",
    "\n",
    "**Objetivo:** Crear sistema completamente funcional\n",
    "\n",
    "1. Cre√° tu imagen Docker personalizada\n",
    "2. Actualiz√° docker-compose.yml con todos los servicios\n",
    "3. Document√° el proceso de instalaci√≥n\n",
    "4. Compart√≠ la imagen con un compa√±ero\n",
    "\n",
    "### Proyecto Final: Sistema Multiagente\n",
    "\n",
    "**Objetivo:** Implementar arquitectura avanzada\n",
    "\n",
    "Cre√° m√∫ltiples workflows especializados:\n",
    "1. Workflow coordinador que decide qu√© workflow llamar\n",
    "2. Workflow especializado en NER\n",
    "3. Workflow especializado en an√°lisis de sentimiento\n",
    "4. Workflow que combina resultados de m√∫ltiples an√°lisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comandos de Referencia R√°pida\n",
    "\n",
    "### Docker Compose\n",
    "```bash\n",
    "docker-compose up -d          # Levantar servicios\n",
    "docker-compose down           # Detener y eliminar contenedores\n",
    "docker-compose ps             # Ver estado de servicios\n",
    "docker-compose logs -f        # Ver logs en tiempo real\n",
    "docker-compose restart        # Reiniciar servicios\n",
    "```\n",
    "\n",
    "### Docker B√°sico\n",
    "```bash\n",
    "docker ps                     # Contenedores corriendo\n",
    "docker ps -a                  # Todos los contenedores\n",
    "docker images                 # Listar im√°genes\n",
    "docker logs nombre            # Ver logs de un contenedor\n",
    "docker exec -it nombre bash   # Entrar a un contenedor\n",
    "docker stats                  # Ver uso de recursos\n",
    "```\n",
    "\n",
    "### Ollama\n",
    "```bash\n",
    "docker exec -it ollama ollama list         # Listar modelos\n",
    "docker exec -it ollama ollama pull modelo  # Descargar modelo\n",
    "docker exec -it ollama ollama rm modelo    # Eliminar modelo\n",
    "docker exec -it ollama ollama run modelo   # Ejecutar interactivamente\n",
    "```\n",
    "\n",
    "### Limpieza\n",
    "```bash\n",
    "docker system prune           # Limpiar recursos sin usar\n",
    "docker system prune -a        # Limpiar TODO sin usar\n",
    "docker volume prune           # Limpiar vol√∫menes sin usar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "### Lo que Aprendiste\n",
    "\n",
    "En este laboratorio desarrollaste habilidades fundamentales:\n",
    "\n",
    "1. **Fundamentos de Docker:** Contenedores, im√°genes, vol√∫menes, redes\n",
    "2. **Docker Compose:** Orquestaci√≥n de servicios multi-contenedor\n",
    "3. **n8n:** Automatizaci√≥n visual de workflows\n",
    "4. **Ollama:** Ejecuci√≥n local de modelos de lenguaje\n",
    "5. **Granite 4:** Modelo de lenguaje h√≠brido de √∫ltima generaci√≥n\n",
    "6. **Construcci√≥n de im√°genes:** Dockerfiles y distribuci√≥n\n",
    "7. **Conceptos de deployment:** Despliegue en servidores\n",
    "\n",
    "### Aplicabilidad Profesional\n",
    "\n",
    "Estas habilidades son altamente demandadas en:\n",
    "- DevOps Engineer\n",
    "- MLOps Engineer\n",
    "- Backend Developer\n",
    "- Data Engineer\n",
    "- NLP Engineer\n",
    "\n",
    "### Recursos para Profundizar\n",
    "\n",
    "**Docker:**\n",
    "- Documentaci√≥n oficial: https://docs.docker.com/\n",
    "- Docker Curriculum: https://docker-curriculum.com/\n",
    "\n",
    "**n8n:**\n",
    "- Documentaci√≥n: https://docs.n8n.io/\n",
    "- Templates de workflows: https://n8n.io/workflows/\n",
    "\n",
    "**Ollama:**\n",
    "- Cat√°logo de modelos: https://ollama.ai/library\n",
    "- GitHub: https://github.com/ollama/ollama\n",
    "\n",
    "### Preguntas de Reflexi√≥n\n",
    "\n",
    "Antes de finalizar, reflexion√° sobre:\n",
    "\n",
    "1. **LLMs locales vs APIs:** ¬øCu√°ndo preferir√≠as cada opci√≥n en un proyecto real?\n",
    "2. **Arquitectura:** ¬øC√≥mo escalar√≠as este sistema para 100 usuarios simult√°neos?\n",
    "3. **Seguridad:** ¬øQu√© vulnerabilidades identific√°s en el sistema actual?\n",
    "4. **Costos:** ¬øQu√© ser√≠a m√°s econ√≥mico: Ollama local o usar APIs de OpenAI/Anthropic?\n",
    "\n",
    "---\n",
    "\n",
    "**√öltima actualizaci√≥n:** Noviembre 2025  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
