{"cells":[{"cell_type":"markdown","metadata":{"id":"zl2Uzj9hih3r"},"source":["# Clasificaci√≥n de Texto con Scikit-learn y TF-IDF\n","\n","**Materiales desarrollados por Mat√≠as Barreto, 2025**\n","\n","**Tecnicatura en Ciencia de Datos - IFTS**\n","\n","**Asignatura:** Procesamiento de Lenguaje Natural\n","\n","---\n","\n","## Introducci√≥n\n","\n","En este notebook vas a aprender los fundamentos de la clasificaci√≥n de texto usando m√©todos cl√°sicos de Machine Learning. Antes de meternos con redes neuronales, es fundamental establecer un **baseline** (l√≠nea de base) que nos permita comparar resultados y entender qu√© mejoras aportan las arquitecturas m√°s complejas.\n","\n","### Objetivos de aprendizaje\n","\n","1. Comprender el flujo completo de un proyecto de clasificaci√≥n de texto\n","2. Dominar t√©cnicas de vectorizaci√≥n: **Bag of Words** (BoW) y **TF-IDF**\n","3. Entrenar un modelo de **Regresi√≥n Log√≠stica** para an√°lisis de sentimiento\n","4. Evaluar el modelo con m√©tricas apropiadas\n","5. Interpretar resultados y hacer predicciones sobre datos nuevos\n","\n","### ¬øQu√© vamos a construir?\n","\n","Vamos a construir un clasificador de sentimientos que pueda analizar **rese√±as de productos en espa√±ol** y determinar si son **positivas** o **negativas**. Este tipo de sistemas se usan en la industria para an√°lisis de opiniones de clientes, moderaci√≥n de contenido y detecci√≥n de tendencias en redes sociales."]},{"cell_type":"markdown","metadata":{"id":"iCwE5RVVih3u"},"source":["---\n","\n","## 1Ô∏è‚É£ Instalaci√≥n de Dependencias\n","\n","Instalamos Faker para generar un dataset sint√©tico pero realista en espa√±ol."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8wMisJQIih3u","executionInfo":{"status":"ok","timestamp":1759443225968,"user_tz":180,"elapsed":17441,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"f6b5df1a-f201-4085-d31a-f15fd131d547"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/2.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úì Dependencias instaladas correctamente.\n"]}],"source":["# Instalaci√≥n de librer√≠as necesarias\n","# Faker: Para generar datos sint√©ticos realistas\n","!pip install -q faker\n","\n","print(\"‚úì Dependencias instaladas correctamente.\")"]},{"cell_type":"markdown","metadata":{"id":"FkqopKuzih3v"},"source":["---\n","\n","## 2Ô∏è‚É£ Importaci√≥n de Librer√≠as\n","\n","Importamos las herramientas necesarias: scikit-learn para ML, pandas para datos, y datasets para cargar el corpus."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdBYUVfpih3w","executionInfo":{"status":"ok","timestamp":1759443226032,"user_tz":180,"elapsed":46,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"309accd1-e87c-4ec6-b36b-37433f9123f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Librer√≠as importadas correctamente.\n"]}],"source":["# Librer√≠as para manipulaci√≥n de datos\n","import pandas as pd\n","import numpy as np\n","import random\n","\n","# Vectorizaci√≥n de texto de scikit-learn\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Divisi√≥n de datos y modelo\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","\n","# M√©tricas de evaluaci√≥n\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Para generar datos sint√©ticos realistas\n","from faker import Faker\n","\n","print(\"‚úì Librer√≠as importadas correctamente.\")"]},{"cell_type":"markdown","metadata":{"id":"v_tu_CyGih3w"},"source":["---\n","\n","## 3Ô∏è‚É£ Generaci√≥n del Dataset\n","\n","Vamos a crear un dataset **sint√©tico pero realista** de rese√±as de productos en espa√±ol argentino usando t√©cnicas profesionales de generaci√≥n de datos.\n","\n","Este dataset incluye:\n","- ‚úÖ **Variedad ling√º√≠stica**: Espa√±ol rioplatense con expresiones locales\n","- ‚úÖ **Casos complejos**: Iron√≠a, sarcasmo, negaciones\n","- ‚úÖ **Realismo**: Combinaciones naturales de adjetivos y contextos\n","- ‚úÖ **Balance**: Distribuci√≥n equilibrada de sentimientos\n","\n","### ¬øPor qu√© sint√©tico?\n","\n","Los datasets p√∫blicos de reviews en espa√±ol tienen limitaciones (deprecated, poco balanceados, o en otros dialectos). Un dataset sint√©tico bien dise√±ado nos permite:\n","\n","1. Controlar el balance de clases\n","2. Incluir casos pedag√≥gicamente √∫tiles (iron√≠a, negaciones)\n","3. Usar espa√±ol argentino aut√©ntico\n","4. Ajustar el tama√±o seg√∫n necesidad (clase vs TP)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGKY0ti_ih3w","executionInfo":{"status":"ok","timestamp":1759443381610,"user_tz":180,"elapsed":90,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"3797db2c-7774-42af-a94a-9b1fff253245"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","DATASET GENERADO\n","======================================================================\n","\n","Total de rese√±as: 820\n","\n","Distribuci√≥n por tipo:\n","tipo\n","ambiguo_negativo      40\n","ambiguo_positivo      40\n","ironia_negativo       80\n","ironia_positivo       80\n","negacion_negativo     40\n","negacion_positivo     40\n","simple_negativo      250\n","simple_positivo      250\n","Name: count, dtype: int64\n","\n","Distribuci√≥n de sentimientos:\n","sentiment\n","0    410\n","1    410\n","Name: count, dtype: int64\n","\n","Balance de clases:\n","  Positivas: 50.0%\n","  Negativas: 50.0%\n"]}],"source":["# Configuramos seeds para reproducibilidad\n","fake = Faker('es_ES')\n","Faker.seed(42)\n","random.seed(42)\n","np.random.seed(42)\n","\n","# ============================================================================\n","# TEMPLATES DE RESE√ëAS POSITIVAS SIMPLES\n","# ============================================================================\n","\n","# Adjetivos positivos (espa√±ol rioplatense)\n","adjetivos_positivos = [\n","    \"excelente\", \"genial\", \"buen√≠simo\", \"espectacular\", \"incre√≠ble\",\n","    \"perfecto\", \"maravilloso\", \"b√°rbaro\", \"copado\", \"grosso\",\n","    \"de primera\", \"impecable\", \"fant√°stico\", \"hermoso\", \"divino\"\n","]\n","\n","# Verbos positivos\n","verbos_positivos = [\n","    \"me encant√≥\", \"me fascina\", \"lo recomiendo\", \"super√≥ mis expectativas\",\n","    \"cumple perfectamente\", \"funciona de diez\", \"vale la pena\",\n","    \"estoy re contento\", \"no me arrepiento\", \"la rompe\"\n","]\n","\n","# Contextos positivos\n","contextos_positivos = [\n","    \"Lleg√≥ antes de tiempo y en perfecto estado.\",\n","    \"La calidad es superior a lo que esperaba.\",\n","    \"El vendedor fue muy atento y respondi√≥ todas mis dudas.\",\n","    \"Por este precio, es una ganga total.\",\n","    \"Mis amigos quedaron fascinados cuando lo vieron.\",\n","    \"Ya es la segunda vez que compro y sigue siendo excelente.\",\n","    \"Lo uso todos los d√≠as y sigue como nuevo.\",\n","    \"Mi familia est√° encantada con la compra.\",\n","]\n","\n","templates_positivos = [\n","    \"{adj} producto, {verbo}. {contexto}\",\n","    \"{verbo}, {adj} compra. {contexto}\",\n","    \"El producto es {adj}. {contexto} {verbo}.\",\n","    \"{contexto} Realmente {adj}, {verbo}.\",\n","    \"{adj} en todo sentido. {verbo}. {contexto}\",\n","]\n","\n","# ============================================================================\n","# TEMPLATES DE RESE√ëAS NEGATIVAS SIMPLES\n","# ============================================================================\n","\n","# Adjetivos negativos (espa√±ol rioplatense)\n","adjetivos_negativos = [\n","    \"horrible\", \"mal√≠simo\", \"p√©simo\", \"terrible\", \"espantoso\",\n","    \"desastroso\", \"deplorable\", \"trucho\", \"berreta\", \"choto\",\n","    \"un desastre\", \"una porquer√≠a\", \"un fiasco\", \"decepcionante\", \"lamentable\"\n","]\n","\n","# Verbos negativos\n","verbos_negativos = [\n","    \"no lo recomiendo\", \"me arrepiento de comprarlo\", \"p√©rdida de plata\",\n","    \"tuve que devolverlo\", \"no funciona\", \"se rompi√≥ enseguida\",\n","    \"no vale la pena\", \"es una estafa\", \"no cumple lo prometido\",\n","    \"qued√© re decepcionado\"\n","]\n","\n","# Contextos negativos\n","contextos_negativos = [\n","    \"Se rompi√≥ a los pocos d√≠as de uso.\",\n","    \"La calidad es muy inferior a la descripci√≥n.\",\n","    \"El vendedor no responde los mensajes.\",\n","    \"Tard√≥ m√°s de un mes en llegar.\",\n","    \"Lleg√≥ todo golpeado y con partes faltantes.\",\n","    \"No se parece en nada a las fotos.\",\n","    \"Hace ruidos extra√±os y se sobrecalienta.\",\n","    \"El material es pl√°stico barato de mala calidad.\",\n","]\n","\n","templates_negativos = [\n","    \"{adj} producto, {verbo}. {contexto}\",\n","    \"{verbo}, {adj} experiencia. {contexto}\",\n","    \"El producto es {adj}. {contexto} {verbo}.\",\n","    \"{contexto} Realmente {adj}, {verbo}.\",\n","    \"{adj} en todo sentido. {verbo}. {contexto}\",\n","]\n","\n","# ============================================================================\n","# CASOS DIF√çCILES: IRON√çA Y SARCASMO (Sin se√±ales obvias)\n","# ============================================================================\n","\n","# IRON√çA POSITIVA: Empieza mal pero termina bien (se√±al confusa al principio)\n","casos_ironia_positiva = [\n","    \"Pens√© que iba a ser horrible, pero me equivoqu√© completamente.\",\n","    \"Las primeras impresiones eran malas, termin√≥ siendo muy √∫til.\",\n","    \"No confiaba en este producto, ahora lo uso todos los d√≠as.\",\n","    \"Dudaba mucho, pero result√≥ ser mejor que productos m√°s caros.\",\n","    \"Parec√≠a trucho, funciona mejor que otras marcas conocidas.\",\n","    \"Ten√≠a miedo de que fuera malo, pero fue una grata sorpresa.\",\n","    \"Cre√≠ que me iban a estafar, result√≥ ser confiable.\",\n","    \"Me arrepent√≠a de comprarlo, ahora pienso que fue buena idea.\",\n","    \"Al principio desconfi√©, termin√≥ superando expectativas.\",\n","    \"Ven√≠a con dudas, result√≥ mejor de lo imaginado.\",\n","]\n","\n","# IRON√çA NEGATIVA SUTIL: Sarcasmo sin palabras negativas expl√≠citas\n","# Estos son genuinamente dif√≠ciles porque solo tienen palabras positivas\n","casos_ironia_negativa = [\n","    \"Claro, porque yo tengo plata para tirar. S√∫per recomendable.\",\n","    \"Hermoso, justo lo que necesitaba para decorar la basura.\",\n","    \"Fant√°stico, ahora tengo un pisapapeles muy caro.\",\n","    \"Perfecto, me encanta cuando las cosas duran una semana.\",\n","    \"Genial, ideal para regalarle a alguien que no te cae bien.\",\n","    \"Excelente, porque a qui√©n no le gusta perder el tiempo.\",\n","    \"Maravilloso, especialmente si disfrut√°s de las decepciones.\",\n","    \"Divino, lo mejor para aprender a no confiar en las reviews.\",\n","    \"Espectacular, perfecto para quienes aman tirar dinero.\",\n","    \"Incre√≠ble, nunca hab√≠a visto algo tan in√∫til por tanto dinero.\",\n","]\n","\n","# NEGACI√ìN POSITIVA - M√°s variedad de patrones\n","casos_negacion_positiva = [\n","    \"No tengo quejas, cumple perfectamente su funci√≥n.\",\n","    \"Jam√°s tuve problemas, funciona muy bien.\",\n","    \"No me arrepiento, fue buena compra.\",\n","    \"No esperaba tanto, super√≥ lo que imaginaba.\",\n","    \"Para nada malo, al contrario, bastante bueno.\",\n","    \"Sin ning√∫n defecto que mencionar, todo correcto.\",\n","    \"No encuentro fallas, todo funciona perfecto.\",\n","    \"Nunca me fall√≥, siempre anda bien.\",\n","]\n","\n","# NEGACI√ìN NEGATIVA - Patrones variados\n","casos_negacion_negativa = [\n","    \"No funciona, no sirve, no lo compren.\",\n","    \"Jam√°s vuelvo a comprar esto, mala experiencia.\",\n","    \"No lo recomiendo, tuve muchos problemas.\",\n","    \"Para nada lo que esperaba, muy decepcionante.\",\n","    \"Sin dudas la peor compra, no vale la pena.\",\n","    \"No cumple lo prometido, perd√≠ plata.\",\n","    \"Nunca anduvo bien, siempre con fallas.\",\n","    \"Ni funciona ni vale lo que cuesta.\",\n","]\n","\n","# CASOS VERDADERAMENTE AMBIGUOS - Equilibrio perfecto de positivo/negativo\n","# Estos deber√≠an confundir al modelo porque tienen IGUAL cantidad de se√±ales\n","casos_ambiguos_positivos = [\n","    \"Tiene defectos, pero en general funciona bien.\",\n","    \"No es perfecto, aunque cumple lo esperado.\",\n","    \"Algunos aspectos mejorables, pero satisfecho con la compra.\",\n","    \"Podr√≠a ser mejor, igual lo uso sin problemas.\",\n","    \"Esperaba m√°s calidad, pero el precio compensa.\",\n","    \"Fallos menores, en conjunto buena experiencia.\",\n","    \"Ciertos detalles negativos, a√∫n as√≠ lo recomiendo.\",\n","]\n","\n","casos_ambiguos_negativos = [\n","    \"Funciona bien, pero no justifica el precio alto.\",\n","    \"Lindo dise√±o, l√°stima que no sirve.\",\n","    \"Cumple lo b√°sico, pero esperaba algo superior.\",\n","    \"Buena presentaci√≥n, terrible calidad interna.\",\n","    \"Lo positivo no alcanza para compensar los problemas.\",\n","    \"Algunos aspectos buenos, pero demasiados defectos.\",\n","    \"Precio razonable, rendimiento inaceptable.\",\n","]\n","\n","# ============================================================================\n","# GENERACI√ìN DEL DATASET\n","# ============================================================================\n","\n","def generar_review_positiva():\n","    \"\"\"Genera una rese√±a positiva realista\"\"\"\n","    template = random.choice(templates_positivos)\n","    adj = random.choice(adjetivos_positivos)\n","    verbo = random.choice(verbos_positivos)\n","    contexto = random.choice(contextos_positivos)\n","\n","    return template.format(adj=adj, verbo=verbo, contexto=contexto)\n","\n","def generar_review_negativa():\n","    \"\"\"Genera una rese√±a negativa realista\"\"\"\n","    template = random.choice(templates_negativos)\n","    adj = random.choice(adjetivos_negativos)\n","    verbo = random.choice(verbos_negativos)\n","    contexto = random.choice(contextos_negativos)\n","\n","    return template.format(adj=adj, verbo=verbo, contexto=contexto)\n","\n","# Configuraci√≥n del dataset: reducimos casos simples y aumentamos dif√≠ciles\n","n_simples_por_clase = 250  # Reviews simples (reducido para dar m√°s peso a casos dif√≠ciles)\n","n_casos_especiales = 80    # Casos dif√≠ciles (aumentado significativamente)\n","\n","reviews = []\n","sentiments = []\n","tipos = []\n","\n","# 1. Reviews positivas simples\n","for _ in range(n_simples_por_clase):\n","    reviews.append(generar_review_positiva())\n","    sentiments.append(1)\n","    tipos.append('simple_positivo')\n","\n","# 2. Reviews negativas simples\n","for _ in range(n_simples_por_clase):\n","    reviews.append(generar_review_negativa())\n","    sentiments.append(0)\n","    tipos.append('simple_negativo')\n","\n","# 3. Iron√≠a positiva (empieza negativo, termina positivo)\n","for _ in range(n_casos_especiales):\n","    caso = random.choice(casos_ironia_positiva)\n","    reviews.append(caso)\n","    sentiments.append(1)\n","    tipos.append('ironia_positivo')\n","\n","# 4. Iron√≠a negativa (sarcasmo - usa palabras positivas pero es negativo)\n","for _ in range(n_casos_especiales):\n","    caso = random.choice(casos_ironia_negativa)\n","    reviews.append(caso)\n","    sentiments.append(0)\n","    tipos.append('ironia_negativo')\n","\n","# 5. Negaci√≥n positiva\n","for _ in range(n_casos_especiales // 2):\n","    caso = random.choice(casos_negacion_positiva)\n","    reviews.append(caso)\n","    sentiments.append(1)\n","    tipos.append('negacion_positivo')\n","\n","# 6. Negaci√≥n negativa\n","for _ in range(n_casos_especiales // 2):\n","    caso = random.choice(casos_negacion_negativa)\n","    reviews.append(caso)\n","    sentiments.append(0)\n","    tipos.append('negacion_negativo')\n","\n","# 7. Casos ambiguos positivos\n","for _ in range(n_casos_especiales // 2):\n","    caso = random.choice(casos_ambiguos_positivos)\n","    reviews.append(caso)\n","    sentiments.append(1)\n","    tipos.append('ambiguo_positivo')\n","\n","# 8. Casos ambiguos negativos\n","for _ in range(n_casos_especiales // 2):\n","    caso = random.choice(casos_ambiguos_negativos)\n","    reviews.append(caso)\n","    sentiments.append(0)\n","    tipos.append('ambiguo_negativo')\n","\n","# Creamos DataFrame\n","df_full = pd.DataFrame({\n","    'review_body': reviews,\n","    'sentiment': sentiments,\n","    'tipo': tipos,\n","    'stars': [5 if s == 1 else 1 for s in sentiments],\n","    'review_title': [''] * len(reviews)\n","})\n","\n","# Mezclamos aleatoriamente\n","df_full = df_full.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","print(\"=\" * 70)\n","print(\"DATASET GENERADO\")\n","print(\"=\" * 70)\n","print(f\"\\nTotal de rese√±as: {len(df_full):,}\")\n","print(f\"\\nDistribuci√≥n por tipo:\")\n","print(df_full['tipo'].value_counts().sort_index())\n","print(f\"\\nDistribuci√≥n de sentimientos:\")\n","print(df_full['sentiment'].value_counts())\n","print(f\"\\nBalance de clases:\")\n","print(f\"  Positivas: {(df_full['sentiment']==1).sum()/len(df_full)*100:.1f}%\")\n","print(f\"  Negativas: {(df_full['sentiment']==0).sum()/len(df_full)*100:.1f}%\")"]},{"cell_type":"markdown","metadata":{"id":"jLJWN5Ldih3x"},"source":["### An√°lisis del dataset generado\n","\n","Veamos la distribuci√≥n de tipos de rese√±as y algunos ejemplos de cada categor√≠a."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHNDbmGDih3x","executionInfo":{"status":"ok","timestamp":1759443476892,"user_tz":180,"elapsed":60,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"9218fdd7-aeaa-4c1a-86f4-55a06a7f78a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","EJEMPLOS DE RESE√ëAS POR CATEGOR√çA\n","================================================================================\n","\n","================================================================================\n","TIPO: AMBIGUO_NEGATIVO\n","================================================================================\n","\n","  [NEGATIVO ‚úó] Precio razonable, rendimiento inaceptable.\n","\n","  [NEGATIVO ‚úó] Lindo dise√±o, l√°stima que no sirve.\n","\n","  [NEGATIVO ‚úó] Algunos aspectos buenos, pero demasiados defectos.\n","\n","================================================================================\n","TIPO: AMBIGUO_POSITIVO\n","================================================================================\n","\n","  [POSITIVO ‚úì] No es perfecto, aunque cumple lo esperado.\n","\n","  [POSITIVO ‚úì] Ciertos detalles negativos, a√∫n as√≠ lo recomiendo.\n","\n","  [POSITIVO ‚úì] Fallos menores, en conjunto buena experiencia.\n","\n","================================================================================\n","TIPO: IRONIA_NEGATIVO\n","================================================================================\n","\n","  [NEGATIVO ‚úó] Claro, porque yo tengo plata para tirar. S√∫per recomendable.\n","\n","  [NEGATIVO ‚úó] Claro, porque yo tengo plata para tirar. S√∫per recomendable.\n","\n","  [NEGATIVO ‚úó] Fant√°stico, ahora tengo un pisapapeles muy caro.\n","\n","================================================================================\n","TIPO: IRONIA_POSITIVO\n","================================================================================\n","\n","  [POSITIVO ‚úì] Ven√≠a con dudas, result√≥ mejor de lo imaginado.\n","\n","  [POSITIVO ‚úì] Las primeras impresiones eran malas, termin√≥ siendo muy √∫til.\n","\n","  [POSITIVO ‚úì] Ven√≠a con dudas, result√≥ mejor de lo imaginado.\n","\n","================================================================================\n","TIPO: NEGACION_NEGATIVO\n","================================================================================\n","\n","  [NEGATIVO ‚úó] Para nada lo que esperaba, muy decepcionante.\n","\n","  [NEGATIVO ‚úó] Ni funciona ni vale lo que cuesta.\n","\n","  [NEGATIVO ‚úó] Para nada lo que esperaba, muy decepcionante.\n","\n","================================================================================\n","TIPO: NEGACION_POSITIVO\n","================================================================================\n","\n","  [POSITIVO ‚úì] No tengo quejas, cumple perfectamente su funci√≥n.\n","\n","  [POSITIVO ‚úì] No me arrepiento, fue buena compra.\n","\n","  [POSITIVO ‚úì] Nunca me fall√≥, siempre anda bien.\n","\n","================================================================================\n","TIPO: SIMPLE_NEGATIVO\n","================================================================================\n","\n","  [NEGATIVO ‚úó] p√©simo en todo sentido. no vale la pena. El material es pl√°stico barato de mala calidad.\n","\n","  [NEGATIVO ‚úó] choto en todo sentido. tuve que devolverlo. El vendedor no responde los mensajes.\n","\n","  [NEGATIVO ‚úó] qued√© re decepcionado, decepcionante experiencia. El vendedor no responde los mensajes.\n","\n","================================================================================\n","TIPO: SIMPLE_POSITIVO\n","================================================================================\n","\n","  [POSITIVO ‚úì] no me arrepiento, impecable compra. Mis amigos quedaron fascinados cuando lo vieron.\n","\n","  [POSITIVO ‚úì] lo recomiendo, perfecto compra. Mis amigos quedaron fascinados cuando lo vieron.\n","\n","  [POSITIVO ‚úì] El producto es genial. El vendedor fue muy atento y respondi√≥ todas mis dudas. me fascina.\n","\n","================================================================================\n","üí° NOTA PEDAG√ìGICA:\n","================================================================================\n","Los casos de 'iron√≠a' y 'negaci√≥n' son DESAFIANTES para el modelo.\n","Observ√° c√≥mo palabras positivas pueden expresar sentimiento negativo\n","(y viceversa) seg√∫n el contexto. ¬°Esto es clave para entender las\n","limitaciones de BoW/TF-IDF y motivar el uso de modelos m√°s avanzados!\n","================================================================================\n"]}],"source":["# Trabajamos con el dataset completo\n","df = df_full.copy()\n","\n","print(\"=\" * 80)\n","print(\"EJEMPLOS DE RESE√ëAS POR CATEGOR√çA\")\n","print(\"=\" * 80)\n","\n","# Mostramos ejemplos de cada tipo\n","tipos_unicos = df['tipo'].unique()\n","\n","for tipo in sorted(tipos_unicos):\n","    print(f\"\\n{'='*80}\")\n","    print(f\"TIPO: {tipo.upper()}\")\n","    print(f\"{'='*80}\")\n","\n","    # Mostramos 3 ejemplos de este tipo\n","    ejemplos = df[df['tipo'] == tipo].sample(min(3, len(df[df['tipo'] == tipo])), random_state=42)\n","\n","    for idx, row in ejemplos.iterrows():\n","        sentiment_label = \"POSITIVO ‚úì\" if row['sentiment'] == 1 else \"NEGATIVO ‚úó\"\n","        print(f\"\\n  [{sentiment_label}] {row['review_body']}\")\n","\n","print(f\"\\n{'='*80}\")\n","print(\"üí° NOTA PEDAG√ìGICA:\")\n","print(\"=\"*80)\n","print(\"Los casos de 'iron√≠a' y 'negaci√≥n' son DESAFIANTES para el modelo.\")\n","print(\"Observ√° c√≥mo palabras positivas pueden expresar sentimiento negativo\")\n","print(\"(y viceversa) seg√∫n el contexto. ¬°Esto es clave para entender las\")\n","print(\"limitaciones de BoW/TF-IDF y motivar el uso de modelos m√°s avanzados!\")\n","print(\"=\"*80)"]},{"cell_type":"markdown","metadata":{"id":"t7HTIa6lih3x"},"source":["### Ejemplos espec√≠ficos para la clase\n","\n","Veamos algunas rese√±as positivas y negativas para entender nuestros datos."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab0uW1glih3x","executionInfo":{"status":"ok","timestamp":1759443553181,"user_tz":180,"elapsed":51,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"9bfbaa39-eb66-472f-b70b-2251f25a4766"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","RESE√ëAS POSITIVAS (SIMPLES)\n","================================================================================\n","\n","‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ El vendedor fue muy atento y respondi√≥ todas mis dudas. Realmente divino, me encant√≥.\n","\n","‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ grosso en todo sentido. la rompe. Por este precio, es una ganga total.\n","\n","‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ Mis amigos quedaron fascinados cuando lo vieron. Realmente hermoso, no me arrepiento.\n","\n","‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ genial en todo sentido. vale la pena. Lo uso todos los d√≠as y sigue como nuevo.\n","\n","‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ perfecto en todo sentido. estoy re contento. Lleg√≥ antes de tiempo y en perfecto estado.\n","\n","================================================================================\n","RESE√ëAS NEGATIVAS (SIMPLES)\n","================================================================================\n","\n","‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ La calidad es muy inferior a la descripci√≥n. Realmente trucho, se rompi√≥ enseguida.\n","\n","‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ desastroso producto, no funciona. La calidad es muy inferior a la descripci√≥n.\n","\n","‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ El producto es mal√≠simo. Lleg√≥ todo golpeado y con partes faltantes. p√©rdida de plata.\n","\n","‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ lamentable en todo sentido. me arrepiento de comprarlo. La calidad es muy inferior a la descripci√≥n.\n","\n","‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ Se rompi√≥ a los pocos d√≠as de uso. Realmente espantoso, no lo recomiendo.\n","\n","================================================================================\n","CASOS DESAFIANTES (Iron√≠a/Sarcasmo)\n","================================================================================\n","\n","üî• IRON√çA NEGATIVA (dice 'excelente' pero es NEGATIVO):\n","  ‚úó Claro, porque yo tengo plata para tirar. S√∫per recomendable.\n","  ‚úó Hermoso, justo lo que necesitaba para decorar la basura.\n","  ‚úó Fant√°stico, ahora tengo un pisapapeles muy caro.\n","\n","üî• NEGACIONES COMPLEJAS:\n","  ‚úì No tengo quejas, cumple perfectamente su funci√≥n.\n","  ‚úó No funciona, no sirve, no lo compren.\n"]}],"source":["# Ejemplos de rese√±as positivas simples\n","print(\"=\" * 80)\n","print(\"RESE√ëAS POSITIVAS (SIMPLES)\")\n","print(\"=\" * 80)\n","for i, row in df[df['tipo'] == 'simple_positivo'].head(5).iterrows():\n","    print(f\"\\n‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ {row['review_body']}\")\n","\n","# Ejemplos de rese√±as negativas simples\n","print(\"\\n\" + \"=\" * 80)\n","print(\"RESE√ëAS NEGATIVAS (SIMPLES)\")\n","print(\"=\" * 80)\n","for i, row in df[df['tipo'] == 'simple_negativo'].head(5).iterrows():\n","    print(f\"\\n‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ {row['review_body']}\")\n","\n","# Casos especiales que el modelo puede fallar\n","print(\"\\n\" + \"=\" * 80)\n","print(\"CASOS DESAFIANTES (Iron√≠a/Sarcasmo)\")\n","print(\"=\" * 80)\n","print(\"\\nüî• IRON√çA NEGATIVA (dice 'excelente' pero es NEGATIVO):\")\n","for caso in casos_ironia_negativa[:3]:\n","    print(f\"  ‚úó {caso}\")\n","\n","print(\"\\nüî• NEGACIONES COMPLEJAS:\")\n","print(f\"  ‚úì {casos_negacion_positiva[0]}\")\n","print(f\"  ‚úó {casos_negacion_negativa[0]}\")"]},{"cell_type":"markdown","metadata":{"id":"U3Y3h2SYih3x"},"source":["---\n","\n","## 4Ô∏è‚É£ Divisi√≥n en Conjuntos de Entrenamiento y Prueba\n","\n","Un principio fundamental en Machine Learning es **nunca evaluar el modelo con los mismos datos que usamos para entrenarlo**. Si lo hacemos, el modelo podr√≠a simplemente memorizar los datos (overfitting) y no generalizar bien a datos nuevos.\n","\n","Por eso dividimos el dataset en dos conjuntos:\n","- **Entrenamiento (80%)**: Para que el modelo aprenda patrones\n","- **Prueba (20%)**: Para evaluar el rendimiento en datos no vistos"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GKcZeo6ih3x","executionInfo":{"status":"ok","timestamp":1759443583056,"user_tz":180,"elapsed":14,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"960b55db-b2c3-47fa-b4a6-fa4b75d1b10c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tama√±o del conjunto de entrenamiento: 656 rese√±as\n","Tama√±o del conjunto de prueba: 164 rese√±as\n","\n","Distribuci√≥n en entrenamiento:\n","  Positivas: 328 (50.0%)\n","  Negativas: 328 (50.0%)\n"]}],"source":["# Separamos caracter√≠sticas (X) de etiquetas (y)\n","# Usamos 'review_body' que contiene el texto completo de la rese√±a\n","reviews = df['review_body'].values\n","sentiments = df['sentiment'].values\n","\n","# train_test_split divide aleatoriamente los datos\n","# test_size=0.2 ‚Üí 20% prueba, 80% entrenamiento\n","# stratify=sentiments ‚Üí mantiene proporci√≥n de clases en ambos conjuntos\n","reviews_train, reviews_test, sentiment_train, sentiment_test = train_test_split(\n","    reviews,\n","    sentiments,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=sentiments\n",")\n","\n","print(f\"Tama√±o del conjunto de entrenamiento: {len(reviews_train):,} rese√±as\")\n","print(f\"Tama√±o del conjunto de prueba: {len(reviews_test):,} rese√±as\")\n","print(f\"\\nDistribuci√≥n en entrenamiento:\")\n","print(f\"  Positivas: {sum(sentiment_train==1):,} ({sum(sentiment_train==1)/len(sentiment_train)*100:.1f}%)\")\n","print(f\"  Negativas: {sum(sentiment_train==0):,} ({sum(sentiment_train==0)/len(sentiment_train)*100:.1f}%)\")"]},{"cell_type":"markdown","metadata":{"id":"zCLcR7kwih3y"},"source":["---\n","\n","## 5Ô∏è‚É£ Vectorizaci√≥n de Texto: De Palabras a N√∫meros\n","\n","Los algoritmos de Machine Learning trabajan con n√∫meros, no con texto. Necesitamos convertir las rese√±as en vectores num√©ricos. Vamos a explorar dos t√©cnicas:\n","\n","### 5.1. Bag of Words (BoW) con CountVectorizer\n","\n","Esta t√©cnica representa cada documento como un vector de conteos de palabras. Ignora el orden pero captura la frecuencia.\n","\n","**Ejemplo:**\n","```\n","Texto 1: \"Me gusta el producto\"\n","Texto 2: \"No me gusta nada\"\n","\n","Vocabulario: [\"me\", \"gusta\", \"el\", \"producto\", \"no\", \"nada\"]\n","\n","Vector Texto 1: [1, 1, 1, 1, 0, 0]  # Conteo de cada palabra\n","Vector Texto 2: [1, 1, 0, 0, 1, 1]\n","```"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ih_Hv4tbih3y","executionInfo":{"status":"ok","timestamp":1759443614935,"user_tz":180,"elapsed":78,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"a00cb796-4c35-47c8-f69c-f4cae9244375"},"outputs":[{"output_type":"stream","name":"stdout","text":["Forma de la matriz de entrenamiento: (656, 296)\n","Esto significa: 656 documentos √ó 296 palabras\n","\n","Primeras 10 palabras del vocabulario: ['ahora', 'al', 'alcanza', 'algo', 'alguien', 'algunos', 'alto', 'aman', 'amigos', 'anda']\n"]}],"source":["# Creamos el vectorizador CountVectorizer\n","# max_features=1000 limita el vocabulario a las 1000 palabras m√°s frecuentes\n","count_vectorizer = CountVectorizer(max_features=1000)\n","\n","# fit() construye el vocabulario desde los datos de entrenamiento\n","# transform() convierte textos en matrices de conteos\n","X_train_counts = count_vectorizer.fit_transform(reviews_train)\n","X_test_counts = count_vectorizer.transform(reviews_test)\n","\n","print(f\"Forma de la matriz de entrenamiento: {X_train_counts.shape}\")\n","print(f\"Esto significa: {X_train_counts.shape[0]} documentos √ó {X_train_counts.shape[1]} palabras\")\n","print(f\"\\nPrimeras 10 palabras del vocabulario: {list(count_vectorizer.get_feature_names_out()[:10])}\")"]},{"cell_type":"markdown","metadata":{"id":"SaZ4tzJ7ih3y"},"source":["### 5.2. TF-IDF (Term Frequency - Inverse Document Frequency)\n","\n","TF-IDF mejora BoW al ponderar las palabras seg√∫n su importancia:\n","- **TF (Term Frequency)**: Qu√© tan frecuente es una palabra en un documento\n","- **IDF (Inverse Document Frequency)**: Qu√© tan rara es esa palabra en todo el corpus\n","\n","**Intuici√≥n:** Palabras como \"el\", \"de\", \"la\" aparecen en casi todos los documentos, por lo que tienen poco valor discriminativo. TF-IDF les asigna pesos bajos. Palabras espec√≠ficas como \"excelente\" o \"horrible\" tienen pesos altos.\n","\n","**F√≥rmula:**\n","```\n","TF-IDF(palabra, documento) = TF(palabra, documento) √ó IDF(palabra)\n","```"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTnwUdsmih3y","executionInfo":{"status":"ok","timestamp":1759443655928,"user_tz":180,"elapsed":46,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"ffe783d6-2aef-46d9-c9f0-26bb4ac99d56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Forma de la matriz TF-IDF: (656, 296)\n","Tipo de matriz: <class 'scipy.sparse._csr.csr_matrix'> (sparse matrix para ahorrar memoria)\n"]}],"source":["# Creamos el vectorizador TF-IDF\n","tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n","\n","# fit_transform() combina fit() + transform()\n","X_train_tfidf = tfidf_vectorizer.fit_transform(reviews_train)\n","X_test_tfidf = tfidf_vectorizer.transform(reviews_test)\n","\n","print(f\"Forma de la matriz TF-IDF: {X_train_tfidf.shape}\")\n","print(f\"Tipo de matriz: {type(X_train_tfidf)} (sparse matrix para ahorrar memoria)\")"]},{"cell_type":"markdown","metadata":{"id":"K8bWMPLzih3y"},"source":["---\n","\n","## 6Ô∏è‚É£ Entrenamiento del Modelo: Regresi√≥n Log√≠stica\n","\n","Vamos a entrenar dos modelos (uno con BoW y otro con TF-IDF) y comparar su rendimiento.\n","\n","### ¬øPor qu√© Regresi√≥n Log√≠stica?\n","\n","Aunque el nombre dice \"regresi√≥n\", es un algoritmo de **clasificaci√≥n**. Es simple, r√°pido, interpretable y funciona sorprendentemente bien como baseline para clasificaci√≥n de texto.\n","\n","**Ventajas:**\n","- R√°pido de entrenar\n","- Requiere poca memoria\n","- Produce probabilidades calibradas\n","- Los pesos del modelo son interpretables"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrVWd2Dnih3y","executionInfo":{"status":"ok","timestamp":1759443664004,"user_tz":180,"elapsed":59,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"3c980f87-33b4-4a50-e2e3-2232b31a4248"},"outputs":[{"output_type":"stream","name":"stdout","text":["Entrenando modelo con Bag of Words...\n","‚úì Modelo BoW entrenado.\n","\n","Entrenando modelo con TF-IDF...\n","‚úì Modelo TF-IDF entrenado.\n"]}],"source":["# Modelo 1: Regresi√≥n Log√≠stica con Bag of Words\n","print(\"Entrenando modelo con Bag of Words...\")\n","clf_bow = LogisticRegression(max_iter=1000, random_state=42)\n","clf_bow.fit(X_train_counts, sentiment_train)\n","print(\"‚úì Modelo BoW entrenado.\\n\")\n","\n","# Modelo 2: Regresi√≥n Log√≠stica con TF-IDF\n","print(\"Entrenando modelo con TF-IDF...\")\n","clf_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n","clf_tfidf.fit(X_train_tfidf, sentiment_train)\n","print(\"‚úì Modelo TF-IDF entrenado.\")"]},{"cell_type":"markdown","metadata":{"id":"hCY7kLi0ih3y"},"source":["---\n","\n","## 7Ô∏è‚É£ Evaluaci√≥n de los Modelos\n","\n","Evaluamos ambos modelos en el conjunto de prueba (datos que nunca vieron durante el entrenamiento).\n","\n","### M√©tricas:\n","\n","1. **Accuracy**: Porcentaje de predicciones correctas\n","2. **Precision**: De las rese√±as que predijimos como positivas, ¬øcu√°ntas lo son realmente?\n","3. **Recall**: De todas las rese√±as positivas reales, ¬øcu√°ntas detectamos?\n","4. **F1-score**: Media arm√≥nica entre precision y recall"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4SS0uqpih3y","executionInfo":{"status":"ok","timestamp":1759443687204,"user_tz":180,"elapsed":18,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"1b77db86-16f3-44e9-c8b0-213e1f00e2ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","RESULTADOS DE EVALUACI√ìN\n","============================================================\n","\n","Accuracy con Bag of Words:  1.0000 (100.00%)\n","Accuracy con TF-IDF:        0.9939 (99.39%)\n","\n","============================================================\n"]}],"source":["# Predicciones de ambos modelos\n","y_pred_bow = clf_bow.predict(X_test_counts)\n","y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n","\n","accuracy_bow = accuracy_score(sentiment_test, y_pred_bow)\n","accuracy_tfidf = accuracy_score(sentiment_test, y_pred_tfidf)\n","\n","print(\"=\" * 60)\n","print(\"RESULTADOS DE EVALUACI√ìN\")\n","print(\"=\" * 60)\n","print(f\"\\nAccuracy con Bag of Words:  {accuracy_bow:.4f} ({accuracy_bow*100:.2f}%)\")\n","print(f\"Accuracy con TF-IDF:        {accuracy_tfidf:.4f} ({accuracy_tfidf*100:.2f}%)\")\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"markdown","metadata":{"id":"Pj8yNkrkih3y"},"source":["### Reporte de clasificaci√≥n detallado (TF-IDF)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8jdIDI0Uih3z","executionInfo":{"status":"ok","timestamp":1759443724872,"user_tz":180,"elapsed":17,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"47587938-c335-49ad-cb05-8b3632efbf41"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","REPORTE DETALLADO - MODELO TF-IDF\n","============================================================\n","              precision    recall  f1-score   support\n","\n","Negativo (0)       0.99      1.00      0.99        82\n","Positivo (1)       1.00      0.99      0.99        82\n","\n","    accuracy                           0.99       164\n","   macro avg       0.99      0.99      0.99       164\n","weighted avg       0.99      0.99      0.99       164\n","\n"]}],"source":["print(\"\\nREPORTE DETALLADO - MODELO TF-IDF\")\n","print(\"=\" * 60)\n","print(classification_report(sentiment_test, y_pred_tfidf,\n","                          target_names=['Negativo (0)', 'Positivo (1)']))"]},{"cell_type":"markdown","metadata":{"id":"QtcOI2lnih3z"},"source":["### Matriz de confusi√≥n\n","\n","La matriz de confusi√≥n muestra d√≥nde se equivoca el modelo:\n","\n","```\n","                Predicho Neg    Predicho Pos\n","Real Neg             VN              FP\n","Real Pos             FN              VP\n","```\n","\n","- **VP (Verdaderos Positivos)**: Correctamente clasificados como positivos\n","- **VN (Verdaderos Negativos)**: Correctamente clasificados como negativos\n","- **FP (Falsos Positivos)**: Negativos clasificados err√≥neamente como positivos\n","- **FN (Falsos Negativos)**: Positivos clasificados err√≥neamente como negativos"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wH7CIkBZih3z","executionInfo":{"status":"ok","timestamp":1759443734291,"user_tz":180,"elapsed":25,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"3cb25358-2fb6-4223-df55-129474cfcdd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["MATRIZ DE CONFUSI√ìN - MODELO TF-IDF\n","============================================================\n","\n","[[82  0]\n"," [ 1 81]]\n","\n","Verdaderos Negativos: 82\n","Falsos Positivos:     0\n","Falsos Negativos:     1\n","Verdaderos Positivos: 81\n"]}],"source":["cm = confusion_matrix(sentiment_test, y_pred_tfidf)\n","\n","print(\"MATRIZ DE CONFUSI√ìN - MODELO TF-IDF\")\n","print(\"=\" * 60)\n","print(f\"\\n{cm}\\n\")\n","print(f\"Verdaderos Negativos: {cm[0,0]}\")\n","print(f\"Falsos Positivos:     {cm[0,1]}\")\n","print(f\"Falsos Negativos:     {cm[1,0]}\")\n","print(f\"Verdaderos Positivos: {cm[1,1]}\")"]},{"cell_type":"markdown","metadata":{"id":"O4oJhptpih3z"},"source":["---\n","\n","## 8Ô∏è‚É£ Predicciones sobre Datos Nuevos en Espa√±ol\n","\n","Ahora que tenemos un modelo entrenado, podemos clasificar rese√±as nuevas en espa√±ol que nunca vio antes. Este es el objetivo final: generalizar a datos del mundo real."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwK5Iwslih3z","executionInfo":{"status":"ok","timestamp":1759443963471,"user_tz":180,"elapsed":13,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"ff38c10c-c5d6-4026-b44d-3d9ce8ec3e72"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","PREDICCIONES SOBRE RESE√ëAS NUEVAS EN ESPA√ëOL\n","================================================================================\n","\n","Rese√±a: \"Excelente producto, super√≥ mis expectativas. Lo recomiendo totalmente.\"\n","Predicci√≥n: POSITIVO ‚úì (Confianza: 87.1%)\n","\n","Rese√±a: \"Mal√≠sima calidad, se rompi√≥ a los pocos d√≠as. No lo compren.\"\n","Predicci√≥n: NEGATIVO ‚úó (Confianza: 88.0%)\n","\n","Rese√±a: \"Es aceptable, cumple su funci√≥n pero nada del otro mundo.\"\n","Predicci√≥n: POSITIVO ‚úì (Confianza: 62.9%)\n","\n","Rese√±a: \"Me encant√≥, justo lo que buscaba. Lleg√≥ r√°pido y bien empaquetado.\"\n","Predicci√≥n: POSITIVO ‚úì (Confianza: 66.9%)\n","\n","Rese√±a: \"Decepcionante, no funciona como dice la descripci√≥n. P√©rdida de dinero.\"\n","Predicci√≥n: NEGATIVO ‚úó (Confianza: 85.7%)\n","\n","Rese√±a: \"Buen√≠simo, la mejor compra que podes hacer si queres tirar tu dinero a la basura.\"\n","Predicci√≥n: NEGATIVO ‚úó (Confianza: 51.1%)\n","\n","Rese√±a: \"Horrible, el peor producto que compr√©. No sirve para nada.\"\n","Predicci√≥n: NEGATIVO ‚úó (Confianza: 89.9%)\n"]}],"source":["# Nuevas rese√±as de ejemplo en espa√±ol\n","new_reviews = [\n","    \"Excelente producto, super√≥ mis expectativas. Lo recomiendo totalmente.\",\n","    \"Mal√≠sima calidad, se rompi√≥ a los pocos d√≠as. No lo compren.\",\n","    \"Es aceptable, cumple su funci√≥n pero nada del otro mundo.\",\n","    \"Me encant√≥, justo lo que buscaba. Lleg√≥ r√°pido y bien empaquetado.\",\n","    \"Decepcionante, no funciona como dice la descripci√≥n. P√©rdida de dinero.\",\n","    \"Buen√≠simo, la mejor compra que podes hacer si queres tirar tu dinero a la basura.\",\n","    \"Horrible, el peor producto que compr√©. No sirve para nada.\"\n","]\n","\n","# Vectorizamos con el MISMO vectorizador entrenado\n","# ¬°NUNCA usar fit() en datos nuevos! Solo transform()\n","X_new = tfidf_vectorizer.transform(new_reviews)\n","\n","# Predicciones y probabilidades\n","predictions = clf_tfidf.predict(X_new)\n","probabilities = clf_tfidf.predict_proba(X_new)\n","\n","# Mostramos resultados\n","print(\"=\" * 80)\n","print(\"PREDICCIONES SOBRE RESE√ëAS NUEVAS EN ESPA√ëOL\")\n","print(\"=\" * 80)\n","for i, review in enumerate(new_reviews):\n","    sentiment_label = \"POSITIVO ‚úì\" if predictions[i] == 1 else \"NEGATIVO ‚úó\"\n","    confidence = probabilities[i][predictions[i]] * 100\n","    print(f\"\\nRese√±a: \\\"{review}\\\"\")\n","    print(f\"Predicci√≥n: {sentiment_label} (Confianza: {confidence:.1f}%)\")"]},{"cell_type":"markdown","metadata":{"id":"8bIp2YQ5ih3z"},"source":["---\n","\n","## 9Ô∏è‚É£ Interpretabilidad: ¬øQu√© Palabras Importan?\n","\n","Una ventaja de la Regresi√≥n Log√≠stica es que podemos inspeccionar los pesos del modelo para entender qu√© palabras en espa√±ol considera m√°s importantes para cada clase.\n","\n","**üí° Ejercicio pedag√≥gico**: Despu√©s de ver las palabras m√°s influyentes, analicemos por qu√© el modelo puede fallar en casos de iron√≠a y sarcasmo."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjoqq0pCih3z","executionInfo":{"status":"ok","timestamp":1759444050437,"user_tz":180,"elapsed":19,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"b402a648-a5d3-409d-8c05-618f5e63a672"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","PALABRAS M√ÅS INFLUYENTES EN LAS PREDICCIONES\n","============================================================\n","\n","Top 15 palabras asociadas con SENTIMIENTO POSITIVO:\n","  ‚úì mis                  (peso: 1.8547)\n","  ‚úì fue                  (peso: 1.6596)\n","  ‚úì este                 (peso: 1.6196)\n","  ‚úì me                   (peso: 1.5042)\n","  ‚úì compra               (peso: 1.4989)\n","  ‚úì perfecto             (peso: 1.4730)\n","  ‚úì todos                (peso: 1.4304)\n","  ‚úì sigue                (peso: 1.2932)\n","  ‚úì perfectamente        (peso: 1.1302)\n","  ‚úì estado               (peso: 1.1227)\n","  ‚úì antes                (peso: 1.1227)\n","  ‚úì result√≥              (peso: 1.0945)\n","  ‚úì total                (peso: 1.0659)\n","  ‚úì ganga                (peso: 1.0659)\n","  ‚úì ser                  (peso: 1.0384)\n","\n","Top 15 palabras asociadas con SENTIMIENTO NEGATIVO:\n","  ‚úó no                   (peso: -2.3939)\n","  ‚úó se                   (peso: -2.0986)\n","  ‚úó para                 (peso: -2.0375)\n","  ‚úó un                   (peso: -1.7465)\n","  ‚úó las                  (peso: -1.4123)\n","  ‚úó ni                   (peso: -1.3164)\n","  ‚úó rompi√≥               (peso: -1.3142)\n","  ‚úó descripci√≥n          (peso: -1.2254)\n","  ‚úó inferior             (peso: -1.2254)\n","  ‚úó plata                (peso: -1.2234)\n","  ‚úó algo                 (peso: -1.2174)\n","  ‚úó decepcionante        (peso: -1.2063)\n","  ‚úó partes               (peso: -1.1361)\n","  ‚úó golpeado             (peso: -1.1361)\n","  ‚úó faltantes            (peso: -1.1361)\n","\n","============================================================\n","üí° AN√ÅLISIS PEDAG√ìGICO\n","============================================================\n","\n","El modelo aprendi√≥ correctamente que palabras como 'excelente', 'perfecto',\n","'genial' est√°n asociadas con sentimiento POSITIVO.\n","\n","Sin embargo, esto es tambi√©n su DEBILIDAD:\n","\n","En una rese√±a ir√≥nica como:\n","  \"Excelente si quer√©s tirar la plata a la basura\"\n","  \n","El modelo ver√° 'excelente' (peso positivo alto) y probablemente \n","la clasifique INCORRECTAMENTE como positiva, porque:\n","\n","1. BoW/TF-IDF ignoran el ORDEN de las palabras\n","2. No capturan el CONTEXTO (\"si quer√©s tirar la plata\")\n","3. No entienden NEGACIONES ni IRON√çA\n","\n","Esto motiva el uso de modelos m√°s avanzados (LSTM, Transformers)\n","que veremos en los pr√≥ximos notebooks.\n","\n"]}],"source":["# Obtenemos features (palabras) y coeficientes\n","feature_names = tfidf_vectorizer.get_feature_names_out()\n","coefficients = clf_tfidf.coef_[0]\n","\n","# Top 15 palabras m√°s positivas y negativas\n","top_positive_indices = np.argsort(coefficients)[-15:]\n","top_negative_indices = np.argsort(coefficients)[:15]\n","\n","print(\"=\" * 60)\n","print(\"PALABRAS M√ÅS INFLUYENTES EN LAS PREDICCIONES\")\n","print(\"=\" * 60)\n","\n","print(\"\\nTop 15 palabras asociadas con SENTIMIENTO POSITIVO:\")\n","for idx in reversed(top_positive_indices):\n","    print(f\"  ‚úì {feature_names[idx]:20s} (peso: {coefficients[idx]:.4f})\")\n","\n","print(\"\\nTop 15 palabras asociadas con SENTIMIENTO NEGATIVO:\")\n","for idx in top_negative_indices:\n","    print(f\"  ‚úó {feature_names[idx]:20s} (peso: {coefficients[idx]:.4f})\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"üí° AN√ÅLISIS PEDAG√ìGICO\")\n","print(\"=\" * 60)\n","print(\"\"\"\n","El modelo aprendi√≥ correctamente que palabras como 'excelente', 'perfecto',\n","'genial' est√°n asociadas con sentimiento POSITIVO.\n","\n","Sin embargo, esto es tambi√©n su DEBILIDAD:\n","\n","En una rese√±a ir√≥nica como:\n","  \"Excelente si quer√©s tirar la plata a la basura\"\n","\n","El modelo ver√° 'excelente' (peso positivo alto) y probablemente\n","la clasifique INCORRECTAMENTE como positiva, porque:\n","\n","1. BoW/TF-IDF ignoran el ORDEN de las palabras\n","2. No capturan el CONTEXTO (\"si quer√©s tirar la plata\")\n","3. No entienden NEGACIONES ni IRON√çA\n","\n","Esto motiva el uso de modelos m√°s avanzados (LSTM, Transformers)\n","que veremos en los pr√≥ximos notebooks.\n","\"\"\")"]},{"cell_type":"code","source":["# Agregamos las predicciones al dataframe de test\n","# Necesitamos identificar los √≠ndices del test set en el df original\n","test_indices = []\n","for review in reviews_test:\n","    # Encontramos el √≠ndice en df\n","    idx = df[df['review_body'] == review].index[0]\n","    test_indices.append(idx)\n","\n","df_test = df.loc[test_indices].copy()\n","df_test['prediccion'] = y_pred_tfidf\n","\n","# Calculamos accuracy por tipo de review\n","print(\"=\" * 70)\n","print(\"RENDIMIENTO DEL MODELO POR TIPO DE RESE√ëA\")\n","print(\"=\" * 70)\n","\n","for tipo in sorted(df_test['tipo'].unique()):\n","    df_tipo = df_test[df_test['tipo'] == tipo]\n","    if len(df_tipo) > 0:\n","        aciertos = (df_tipo['sentiment'] == df_tipo['prediccion']).sum()\n","        total = len(df_tipo)\n","        accuracy_tipo = aciertos / total * 100\n","\n","        # Clasificamos dificultad\n","        if 'simple' in tipo:\n","            dificultad = \"F√ÅCIL     \"\n","        elif 'ironia' in tipo:\n","            dificultad = \"DIF√çCIL   \"\n","        else:  # negacion\n","            dificultad = \"MUY DIF√çCIL\"\n","\n","        print(f\"\\n{tipo:25s} [{dificultad}]: {accuracy_tipo:5.1f}% ({aciertos}/{total})\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"üí° OBSERVACIONES PEDAG√ìGICAS\")\n","print(\"=\" * 70)\n","print(\"\"\"\n","Como era de esperarse:\n","\n","‚úì CASOS SIMPLES: Alta precisi√≥n (~85-95%)\n","  El modelo funciona bien cuando las palabras coinciden con el sentimiento.\n","\n","‚ö† IRON√çA/SARCASMO: Precisi√≥n media-baja (~50-70%)\n","  El modelo se confunde porque las palabras no coinciden con el sentimiento real.\n","\n","‚úó NEGACIONES: Precisi√≥n variable\n","  \"No funciona\" vs \"No tengo quejas\" - ambas tienen \"no\", pero significan opuesto.\n","\n","CONCLUSI√ìN: Los modelos cl√°sicos (TF-IDF + Logistic Regression) son un\n","buen BASELINE, pero tienen limitaciones claras con casos complejos.\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oy0M7JNaih3z","executionInfo":{"status":"ok","timestamp":1759444160875,"user_tz":180,"elapsed":79,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"678da912-9f15-48eb-f7fc-77790d8fe9f4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","RENDIMIENTO DEL MODELO POR TIPO DE RESE√ëA\n","======================================================================\n","\n","ambiguo_negativo          [MUY DIF√çCIL]: 100.0% (6/6)\n","\n","ambiguo_positivo          [MUY DIF√çCIL]: 100.0% (7/7)\n","\n","ironia_negativo           [DIF√çCIL   ]: 100.0% (16/16)\n","\n","ironia_positivo           [DIF√çCIL   ]: 100.0% (11/11)\n","\n","negacion_negativo         [MUY DIF√çCIL]: 100.0% (7/7)\n","\n","negacion_positivo         [MUY DIF√çCIL]:  93.3% (14/15)\n","\n","simple_negativo           [F√ÅCIL     ]: 100.0% (53/53)\n","\n","simple_positivo           [F√ÅCIL     ]: 100.0% (49/49)\n","\n","======================================================================\n","üí° OBSERVACIONES PEDAG√ìGICAS\n","======================================================================\n","\n","Como era de esperarse:\n","\n","‚úì CASOS SIMPLES: Alta precisi√≥n (~85-95%)\n","  El modelo funciona bien cuando las palabras coinciden con el sentimiento.\n","\n","‚ö† IRON√çA/SARCASMO: Precisi√≥n media-baja (~50-70%)\n","  El modelo se confunde porque las palabras no coinciden con el sentimiento real.\n","\n","‚úó NEGACIONES: Precisi√≥n variable\n","  \"No funciona\" vs \"No tengo quejas\" - ambas tienen \"no\", pero significan opuesto.\n","\n","CONCLUSI√ìN: Los modelos cl√°sicos (TF-IDF + Logistic Regression) son un \n","buen BASELINE, pero tienen limitaciones claras con casos complejos.\n","\n"]}]},{"cell_type":"markdown","source":["### An√°lisis de Rendimiento por Tipo de Rese√±a\n","\n","Veamos c√≥mo le va al modelo en diferentes tipos de casos."],"metadata":{"id":"Ty_UnOeXih30"}},{"cell_type":"markdown","metadata":{"id":"enLatDUTih30"},"source":["---\n","\n","## üß† Gu√≠a Te√≥rico-Conceptual\n","\n","### 1. Flujo completo de un proyecto de clasificaci√≥n de texto\n","\n","**Paso 1: Recolecci√≥n de datos**  \n","Obtener un corpus etiquetado (en nuestro caso, rese√±as con sentimiento)\n","\n","**Paso 2: Preprocesamiento**  \n","Limpiar texto, tokenizaci√≥n, opcional: stemming/lemmatizaci√≥n\n","\n","**Paso 3: Vectorizaci√≥n**  \n","Convertir texto en representaci√≥n num√©rica (BoW, TF-IDF, embeddings)\n","\n","**Paso 4: Divisi√≥n train/test**  \n","Separar datos para entrenar y evaluar sin sesgo\n","\n","**Paso 5: Entrenamiento**  \n","Ajustar modelo a los datos de entrenamiento\n","\n","**Paso 6: Evaluaci√≥n**  \n","Medir rendimiento en datos de prueba\n","\n","**Paso 7: Optimizaci√≥n**  \n","Ajustar hiperpar√°metros, probar otros modelos\n","\n","**Paso 8: Despliegue**  \n","Usar el modelo en producci√≥n\n","\n","---\n","\n","### 2. Bag of Words vs. TF-IDF\n","\n","**Bag of Words (BoW):**\n","- Representa documentos como vectores de conteos de palabras\n","- Ignora orden y gram√°tica\n","- Simple pero efectivo como baseline\n","- **Problema**: Palabras muy frecuentes dominan la representaci√≥n\n","\n","**TF-IDF:**\n","- Balancea frecuencia local (documento) con rareza global (corpus)\n","- Palabras comunes reciben pesos bajos\n","- Palabras discriminativas reciben pesos altos\n","- Generalmente supera a BoW en clasificaci√≥n de texto\n","\n","---\n","\n","### 3. Regresi√≥n Log√≠stica para Clasificaci√≥n\n","\n","**Funcionamiento:**\n","- Aprende funci√≥n lineal: z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b\n","- Aplica sigmoide: P(y=1|x) = 1 / (1 + e‚Åª·∂ª)\n","- Salida es probabilidad entre 0 y 1\n","- Si P > 0.5 ‚Üí Clase 1, sino ‚Üí Clase 0\n","\n","**Ventajas:**\n","- R√°pido y eficiente\n","- Probabilidades calibradas\n","- Pesos interpretables\n","- Funciona bien con alta dimensionalidad\n","\n","**Limitaciones:**\n","- Asume relaciones lineales\n","- No captura interacciones complejas\n","- Ignora orden de palabras\n","\n","---\n","\n","### 4. M√©tricas de Evaluaci√≥n\n","\n","**Accuracy:** Porcentaje de predicciones correctas (cuidado con clases desbalanceadas)\n","\n","**Precision:** De las predichas positivas, ¬øcu√°ntas son realmente positivas?\n","\n","**Recall:** De las positivas reales, ¬øcu√°ntas detectamos?\n","\n","**F1-Score:** Media arm√≥nica entre precision y recall\n","\n","---\n","\n","### 5. Importancia del Baseline\n","\n","Antes de usar redes neuronales complejas, siempre establecemos un baseline simple para:\n","\n","1. Entender la dificultad del problema\n","2. Detectar problemas en los datos\n","3. Tener punto de comparaci√≥n cuantitativo\n","4. Justificar complejidad adicional\n","5. Iterar r√°pidamente\n","\n","En muchos casos, un modelo simple bien ajustado es suficiente y preferible (m√°s r√°pido, interpretable, f√°cil de mantener)."]},{"cell_type":"markdown","metadata":{"id":"xlDw1D1qih30"},"source":["---\n","\n","## ‚ùì Preguntas y Respuestas para Estudio\n","\n","### Preguntas Conceptuales\n","\n","**1. ¬øPor qu√© es importante dividir los datos en conjuntos de entrenamiento y prueba?**\n","\n","*Respuesta:* Para evaluar el rendimiento del modelo en datos que nunca vio durante el entrenamiento. Si evalu√°ramos con los mismos datos de entrenamiento, el modelo podr√≠a haber memorizado los ejemplos (overfitting) y no generalizar bien a datos nuevos del mundo real.\n","\n","---\n","\n","**2. ¬øCu√°l es la diferencia principal entre Bag of Words y TF-IDF?**\n","\n","*Respuesta:* BoW solo cuenta la frecuencia de cada palabra en el documento, mientras que TF-IDF pondera esa frecuencia seg√∫n qu√© tan rara es la palabra en todo el corpus. TF-IDF reduce la importancia de palabras muy comunes (como \"el\", \"de\") y aumenta la de palabras discriminativas.\n","\n","---\n","\n","**3. ¬øPor qu√© usamos Regresi√≥n Log√≠stica para clasificaci√≥n si su nombre dice \"regresi√≥n\"?**\n","\n","*Respuesta:* Aunque el nombre es confuso, la Regresi√≥n Log√≠stica es un algoritmo de clasificaci√≥n. Usa una funci√≥n log√≠stica (sigmoide) para convertir una combinaci√≥n lineal de features en una probabilidad entre 0 y 1, y luego clasifica seg√∫n un umbral (t√≠picamente 0.5).\n","\n","---\n","\n","**4. ¬øQu√© es el overfitting y c√≥mo lo evitamos en este notebook?**\n","\n","*Respuesta:* Overfitting ocurre cuando el modelo memoriza los datos de entrenamiento en lugar de aprender patrones generalizables. Lo evitamos mediante: (1) divisi√≥n train/test, (2) limitaci√≥n del vocabulario (max_features=1000), y (3) regularizaci√≥n impl√≠cita en LogisticRegression.\n","\n","---\n","\n","**5. ¬øPor qu√© nunca debemos usar fit() en los datos de prueba?**\n","\n","*Respuesta:* Porque fit() aprende par√°metros de los datos (vocabulario, escalas, etc.). Si lo usamos en datos de prueba, el modelo \"esp√≠a\" informaci√≥n que no deber√≠a conocer, invalidando la evaluaci√≥n. Solo debemos usar transform() en datos nuevos.\n","\n","---\n","\n","### Preguntas T√©cnicas\n","\n","**6. Si tenemos un dataset con 90% de rese√±as positivas y 10% negativas, ¬øqu√© problema tiene usar solo accuracy como m√©trica?**\n","\n","*Respuesta:* Un modelo trivial que prediga \"positivo\" para todo tendr√≠a 90% de accuracy sin aprender nada √∫til. En datasets desbalanceados, debemos usar precision, recall y F1-score para evaluar el rendimiento en cada clase.\n","\n","---\n","\n","**7. ¬øQu√© significa que TfidfVectorizer devuelva una \"matriz dispersa\" (sparse matrix)?**\n","\n","*Respuesta:* Como la mayor√≠a de las entradas son cero (cada documento solo contiene una peque√±a fracci√≥n del vocabulario total), scipy usa una representaci√≥n dispersa que solo almacena los valores no-cero. Esto ahorra memoria y acelera c√°lculos.\n","\n","---\n","\n","**8. ¬øC√≥mo interpretamos los coeficientes de la Regresi√≥n Log√≠stica?**\n","\n","*Respuesta:* Coeficientes positivos indican que la presencia de esa palabra aumenta la probabilidad de clase positiva. Coeficientes negativos indican asociaci√≥n con la clase negativa. La magnitud indica la fuerza de la asociaci√≥n.\n","\n","---\n","\n","**9. ¬øQu√© pasar√≠a si no us√°ramos random_state en train_test_split?**\n","\n","*Respuesta:* Cada ejecuci√≥n del notebook producir√≠a una divisi√≥n diferente, resultando en m√©tricas ligeramente distintas. Fijar random_state garantiza reproducibilidad, importante para debugging y comparaci√≥n de modelos.\n","\n","---\n","\n","**10. ¬øPor qu√© limitamos max_features a 1000 palabras?**\n","\n","*Respuesta:* Para reducir dimensionalidad y evitar overfitting. Palabras muy raras (que aparecen en 1-2 documentos) suelen ser ruido o typos. Mantener solo las m√°s frecuentes captura la mayor parte de la informaci√≥n con menor riesgo de sobreajuste.\n","\n","---\n","\n","### Preguntas de Aplicaci√≥n\n","\n","**11. Mencion√° tres limitaciones del enfoque BoW/TF-IDF que las redes neuronales podr√≠an superar.**\n","\n","*Respuesta:*\n","1. Ignoran el orden de las palabras (\"no es bueno\" vs \"es bueno\")\n","2. No capturan significado sem√°ntico (\"excelente\" y \"genial\" son tratadas como completamente diferentes)\n","3. No modelan dependencias largas ni contexto complejo\n","\n","---\n","\n","**12. Si tuvieras que clasificar tweets (textos muy cortos), ¬øqu√© ajustes har√≠as a este enfoque?**\n","\n","*Respuesta:*\n","- Incluir n-gramas (bigramas, trigramas) para capturar frases cortas\n","- Reducir max_features (menos palabras √∫nicas en tweets)\n","- Considerar preprocesamiento de hashtags, menciones y emojis\n","- Probar con char-level features para manejar jerga y typos\n","\n","---\n","\n","**13. ¬øEn qu√© casos preferir√≠as usar Regresi√≥n Log√≠stica sobre una red neuronal profunda?**\n","\n","*Respuesta:*\n","- Dataset peque√±o (pocas muestras)\n","- Necesidad de interpretabilidad (explicar decisiones)\n","- Recursos computacionales limitados\n","- Necesidad de entrenar/desplegar r√°pidamente\n","- Cuando el baseline ya da resultados satisfactorios"]},{"cell_type":"markdown","metadata":{"id":"-gvPmp6-ih30"},"source":["---\n","\n","## üéØ Ejercicios Propuestos\n","\n","### Ejercicio 1: Experimentaci√≥n con Hiperpar√°metros\n","Prob√° cambiar `max_features` en TfidfVectorizer a 500, 2000 y 5000. ¬øC√≥mo afecta al accuracy? ¬øObserv√°s overfitting con vocabularios muy grandes?\n","\n","### Ejercicio 2: N-gramas\n","Modific√° TfidfVectorizer para incluir bigramas: `TfidfVectorizer(max_features=1000, ngram_range=(1,2))`. ¬øMejora el rendimiento? ¬øPor qu√© los bigramas pueden ser √∫tiles en espa√±ol?\n","\n","### Ejercicio 3: Dataset Completo\n","Prob√° entrenar con el dataset completo (200,000 reviews) en lugar del subset de 10,000. ¬øMejora significativamente el accuracy? ¬øCu√°nto tarda el entrenamiento?\n","\n","### Ejercicio 4: An√°lisis de Errores\n","Identific√° 5 rese√±as del conjunto de prueba que el modelo clasific√≥ incorrectamente. ¬øQu√© tienen en com√∫n? ¬øSon casos dif√≠ciles incluso para humanos? (Tip: iron√≠a, sarcasmo, negaciones)\n","\n","### Ejercicio 5: Comparaci√≥n de Modelos\n","Prob√° otros clasificadores de sklearn: `MultinomialNB`, `SVC`, `RandomForestClassifier`. ¬øCu√°l da mejores resultados en espa√±ol? ¬øCu√°l es m√°s r√°pido?\n","\n","### Ejercicio 6: Dataset Propio\n","Busc√° otro dataset en espa√±ol (Twitter, reviews de apps, noticias) y aplic√° el mismo pipeline. ¬øEl modelo generaliza bien a otros dominios?\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"pfrigcGaih30"},"source":["## üéì Conclusi√≥n\n","\n","En este notebook establecimos un baseline s√≥lido para clasificaci√≥n de sentimientos en espa√±ol usando m√©todos cl√°sicos de Machine Learning. Aprendimos:\n","\n","1. ‚úÖ Cargar datasets de HuggingFace con reviews reales en espa√±ol\n","2. ‚úÖ Preprocesar datos y convertir problemas multiclase a binarios\n","3. ‚úÖ Vectorizar texto con BoW y TF-IDF\n","4. ‚úÖ Entrenar modelos de Regresi√≥n Log√≠stica\n","5. ‚úÖ Evaluar con m√©tricas apropiadas\n","6. ‚úÖ Interpretar qu√© palabras en espa√±ol influyen en las predicciones\n","\n","**Pr√≥ximo paso:** En el siguiente notebook vamos a explorar Naive Bayes y Pipelines de sklearn para construir flujos de trabajo m√°s modulares y profesionales.\n","\n","---\n","\n","### üí° Reflexi√≥n Final\n","\n","Este modelo cl√°sico (TF-IDF + Logistic Regression) es sorprendentemente efectivo para clasificaci√≥n de sentimientos. En muchos casos reales de la industria, un baseline bien ajustado como este es suficiente y preferible por su:\n","\n","- ‚ö° Velocidad de entrenamiento e inferencia\n","- üìä Interpretabilidad (podemos explicar por qu√© clasifica as√≠)\n","- üíª Bajos requisitos computacionales\n","- üîß Facilidad de mantenimiento\n","\n","Solo cuando este baseline no alcanza la performance requerida, justificamos la complejidad adicional de redes neuronales profundas.\n","\n","---\n","\n","*Este material fue desarrollado con fines educativos para la Tecnicatura en Ciencia de Datos del IFTS.*"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}