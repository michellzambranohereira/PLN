{"cells":[{"cell_type":"markdown","id":"cell-0","metadata":{"id":"cell-0"},"source":["# Introducci√≥n a APIs de Modelos de Lenguaje\n","\n","## Objetivos de Aprendizaje\n","\n","En este cuaderno vas a aprender:\n","- Qu√© es una API y c√≥mo nos permite acceder a modelos de lenguaje grandes (LLMs)\n","- C√≥mo configurar y autenticar tu conexi√≥n con OpenAI\n","- T√©cnicas de prompting b√°sicas para extraer informaci√≥n estructurada\n","- Casos de uso pr√°cticos del procesamiento del lenguaje natural\n","\n","## ¬øQu√© es una API?\n","\n","Una **API** (Application Programming Interface) es una interfaz que permite que dos sistemas se comuniquen entre s√≠. En nuestro caso, nos permite enviar texto a un modelo de lenguaje (como GPT-4) y recibir una respuesta procesada.\n","\n","**Analog√≠a**: Imaginate que est√°s en un restaurante. Vos sos el cliente (tu programa), el mozo es la API, y la cocina es el modelo de lenguaje. Vos le ped√≠s algo al mozo (envi√°s un prompt), el mozo se lo lleva a la cocina (el modelo procesa), y te trae de vuelta el plato (la respuesta).\n","\n","## Prerequisitos\n","\n","Para usar este cuaderno necesit√°s:\n","1. Una cuenta en OpenAI (https://platform.openai.com)\n","2. Una API key (se genera en https://platform.openai.com/account/api-keys)\n","3. Cr√©dito en tu cuenta de OpenAI (hay planes gratuitos para empezar)\n","\n","**Nota sobre costos**: Los modelos como `gpt-4o-mini` son muy econ√≥micos (menos de $0.01 por cada 1000 palabras procesadas)."]},{"cell_type":"markdown","id":"cell-1","metadata":{"id":"cell-1"},"source":["## Configuraci√≥n del Entorno\n","\n","Primero instalamos la librer√≠a de OpenAI y configuramos la autenticaci√≥n. Este c√≥digo detecta autom√°ticamente si est√°s en Google Colab o trabajando localmente, y carga la API key desde el lugar apropiado."]},{"cell_type":"code","execution_count":null,"id":"cell-2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-2","executionInfo":{"status":"ok","timestamp":1761827476430,"user_tz":180,"elapsed":23629,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"086dca6d-b44c-472f-8e0f-719b825dbd12"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.2/1.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hAPI key cargada correctamente. Entorno: Colab\n"]}],"source":["# Instalamos la librer√≠a oficial de OpenAI\n","!pip install --upgrade openai --quiet\n","\n","import os\n","from openai import OpenAI\n","\n","# Detectamos si estamos en Google Colab o en entorno local\n","IN_COLAB = False\n","try:\n","    import google.colab\n","    from google.colab import userdata\n","    IN_COLAB = True\n","except Exception:\n","    IN_COLAB = False\n","\n","# Cargamos la API key seg√∫n el entorno\n","OPENAI_API_KEY = None\n","if IN_COLAB:\n","    # En Colab: usar secrets (icono de llave en la barra lateral)\n","    try:\n","        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","    except Exception:\n","        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","else:\n","    # En local: usar variable de entorno o archivo .env\n","    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","\n","if not OPENAI_API_KEY:\n","    raise ValueError(\n","        'OPENAI_API_KEY no encontrada.\\n'\n","        'En Colab: agregala en Secrets (icono de llave)\\n'\n","        'En local: agregala a tus variables de entorno o archivo .env'\n","    )\n","\n","print(f\"API key cargada correctamente. Entorno: {'Colab' if IN_COLAB else 'Local'}\")"]},{"cell_type":"markdown","id":"cell-3","metadata":{"id":"cell-3"},"source":["### Notas T√©cnicas: Configuraci√≥n de API Key\n","\n","**En Google Colab**:\n","1. Clic en el icono de llave en la barra lateral izquierda\n","2. Agregar un nuevo secret con nombre `OPENAI_API_KEY`\n","3. Pegar tu API key como valor\n","\n","**En entorno local**:\n","```bash\n","# Opci√≥n 1: Variable de entorno (Linux/Mac)\n","export OPENAI_API_KEY='tu-api-key-aqui'\n","\n","# Opci√≥n 2: Archivo .env\n","# Crear archivo .env en la ra√≠z del proyecto:\n","OPENAI_API_KEY=tu-api-key-aqui\n","```\n","\n","**Seguridad**: Nunca subas tu API key a GitHub o la compartas p√∫blicamente. Las API keys son como contrase√±as y dan acceso a tu cuenta (y cr√©dito) de OpenAI."]},{"cell_type":"markdown","id":"cell-4","metadata":{"id":"cell-4"},"source":["## Funci√≥n Auxiliar: get_completion()\n","\n","Creamos una funci√≥n helper que simplifica el env√≠o de prompts a la API. Esta funci√≥n encapsula toda la l√≥gica de comunicaci√≥n y nos permite concentrarnos en el contenido de nuestros prompts.\n","\n","### Par√°metros configurables:\n","\n","- **prompt** (str): El texto que queremos enviar al modelo\n","- **model** (str): Qu√© modelo usar. Opciones comunes:\n","  - `gpt-4o-mini`: R√°pido, econ√≥mico, ideal para la mayor√≠a de tareas\n","  - `gpt-4o`: M√°s potente, mejor razonamiento, m√°s caro\n","  - `gpt-4-turbo`: Balance entre velocidad y capacidad\n","- **temperature** (float, 0-2): Controla la aleatoriedad de las respuestas\n","  - `0.0`: Determin√≠stico, siempre responde igual (ideal para extracci√≥n de datos)\n","  - `0.7`: Balance (bueno para texto general)\n","  - `1.5-2.0`: Creativo, m√°s variado (√∫til para generaci√≥n creativa)\n","\n","**Recomendaci√≥n**: Para tareas de extracci√≥n y an√°lisis, us√° temperature=0. Para generaci√≥n creativa, prob√° con valores entre 0.7 y 1.0."]},{"cell_type":"code","execution_count":null,"id":"cell-5","metadata":{"id":"cell-5"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0):\n","    \"\"\"\n","    Env√≠a un prompt a la API de OpenAI y devuelve la respuesta.\n","\n","    Par√°metros:\n","    -----------\n","    prompt : str\n","        El texto que queremos enviar al modelo\n","    model : str, default=\"gpt-4o-mini\"\n","        Modelo a utilizar (gpt-4o-mini es econ√≥mico y efectivo)\n","    temperature : float, default=0\n","        Grado de aleatoriedad (0 = determin√≠stico, 2 = muy creativo)\n","\n","    Returns:\n","    --------\n","    str\n","        La respuesta generada por el modelo\n","    \"\"\"\n","    # Creamos el cliente de OpenAI\n","    client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","    # Estructuramos el mensaje como conversaci√≥n\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","\n","    # Hacemos el request a la API\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature\n","    )\n","\n","    # Extraemos y devolvemos solo el contenido de la respuesta\n","    return response.choices[0].message.content"]},{"cell_type":"markdown","id":"cell-6","metadata":{"id":"cell-6"},"source":["## Ejemplo 1: An√°lisis de Sentimiento en Reviews\n","\n","Vamos a analizar una review de MercadoLibre y extraer informaci√≥n estructurada. Este es un caso de uso muy com√∫n en comercio electr√≥nico.\n","\n","**Objetivo**: Dado un comentario de un cliente, queremos extraer autom√°ticamente:\n","- El sentimiento general (positivo/negativo/neutro)\n","- Si el cliente est√° enojado\n","- Qu√© producto compr√≥\n","- Qu√© marca es\n","\n","Esto permite procesar miles de reviews autom√°ticamente para detectar problemas, medir satisfacci√≥n, etc."]},{"cell_type":"code","execution_count":null,"id":"cell-7","metadata":{"id":"cell-7"},"outputs":[],"source":["# Review real de un producto (simulada pero realista)\n","review_producto = \"\"\"\n","Compr√© estos auriculares porque ten√≠an buenas rese√±as y el precio era razonable.\n","La verdad que llegaron r√°pido, en dos d√≠as ya los ten√≠a. El sonido es bastante bueno\n","para el precio, se escucha claro y los graves est√°n bien. Lo que no me gust√≥ es que\n","despu√©s de un mes de uso, el auricular derecho empez√≥ a sonar m√°s bajo que el izquierdo.\n","Contact√© al vendedor y me mandaron otro par sin problema. El servicio de atenci√≥n fue\n","excelente, respondieron al toque y resolvieron todo. En general estoy conforme, pero\n","esperaba que duraran m√°s antes de tener problemas.\n","\"\"\""]},{"cell_type":"markdown","id":"cell-8","metadata":{"id":"cell-8"},"source":["### Construcci√≥n del Prompt\n","\n","Un buen prompt es espec√≠fico y claro sobre qu√© formato queremos en la respuesta. Ac√° aplicamos varias t√©cnicas:\n","\n","1. **Instrucciones claras**: Describimos exactamente qu√© queremos extraer\n","2. **Formato estructurado**: Pedimos JSON para poder parsear program√°ticamente\n","3. **Manejo de casos edge**: Indicamos qu√© hacer si falta informaci√≥n\n","4. **Delimitadores**: Usamos triple comillas para delimitar el texto a analizar"]},{"cell_type":"code","execution_count":null,"id":"cell-9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-9","executionInfo":{"status":"ok","timestamp":1761827499776,"user_tz":180,"elapsed":2908,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"d0bfd0bc-0eb4-4128-a653-04bfafdc845a"},"outputs":[{"output_type":"stream","name":"stdout","text":["AN√ÅLISIS DE LA REVIEW:\n","```json\n","{\n","  \"Sentimiento\": \"positivo\",\n","  \"Enojado\": false,\n","  \"Producto\": \"auriculares\",\n","  \"Problema\": \"el auricular derecho empez√≥ a sonar m√°s bajo que el izquierdo\",\n","  \"Calidad_atencion\": \"excelente\"\n","}\n","```\n"]}],"source":["prompt = f\"\"\"\n","Analiza la siguiente review de producto y extrae la informaci√≥n en formato JSON.\n","\n","Informaci√≥n a extraer:\n","- Sentimiento: positivo, negativo o neutro\n","- Enojado: true o false (¬øel cliente expresa enojo?)\n","- Producto: qu√© producto compr√≥\n","- Problema: si hubo alg√∫n problema, cu√°l fue\n","- Calidad_atencion: c√≥mo fue el servicio al cliente\n","\n","Si alguna informaci√≥n no est√° presente, us√° \"no_especificado\".\n","El campo \"Enojado\" debe ser booleano (true/false).\n","\n","Review: ```{review_producto}```\n","\n","Responde √∫nicamente con el JSON, sin texto adicional.\n","\"\"\"\n","\n","respuesta = get_completion(prompt)\n","print(\"AN√ÅLISIS DE LA REVIEW:\")\n","print(respuesta)"]},{"cell_type":"markdown","id":"cell-10","metadata":{"id":"cell-10"},"source":["### An√°lisis del Resultado\n","\n","Observ√° que el modelo pudo:\n","1. Identificar que el sentimiento es mixto/neutro (hay aspectos positivos y negativos)\n","2. Detectar que no hay enojo expl√≠cito\n","3. Extraer el producto espec√≠fico\n","4. Identificar el problema t√©cnico\n","5. Valorar positivamente la atenci√≥n al cliente\n","\n","Todo esto en formato JSON que podemos usar program√°ticamente:\n","\n","```python\n","import json\n","datos = json.loads(respuesta)\n","print(datos['Sentimiento'])  # Acceso a los datos\n","```"]},{"cell_type":"markdown","id":"cell-11","metadata":{"id":"cell-11"},"source":["## Ejemplo 2: An√°lisis de Noticias Period√≠sticas\n","\n","Ahora vamos a trabajar con un texto period√≠stico y extraer informaci√≥n estructurada relevante. Este tipo de an√°lisis es √∫til para:\n","- Sistemas de monitoreo de medios\n","- Agregadores de noticias\n","- An√°lisis de cobertura medi√°tica\n","- Detecci√≥n de temas trending"]},{"cell_type":"code","execution_count":null,"id":"cell-12","metadata":{"id":"cell-12"},"outputs":[],"source":["# Nota period√≠stica simulada\n","noticia = \"\"\"\n","BUENOS AIRES - El Ministerio de Cultura anunci√≥ ayer la apertura de tres nuevos\n","espacios culturales en barrios de la zona sur de la ciudad. Los centros culturales\n","se ubicar√°n en Parque Patricios, Pompeya y Nueva Pompeya, y comenzar√°n a funcionar\n","en marzo de 2024.\n","\n","Seg√∫n inform√≥ la ministra de Cultura, Mar√≠a Rodr√≠guez, los espacios contar√°n con\n","talleres gratuitos de m√∫sica, teatro, danza y artes visuales. \"Es fundamental\n","descentralizar la oferta cultural y llegar a todos los barrios de la ciudad\",\n","afirm√≥ la funcionaria durante la conferencia de prensa.\n","\n","La inversi√≥n total del proyecto asciende a $450 millones y se espera que beneficie\n","directamente a m√°s de 15.000 vecinos de la zona sur. Las inscripciones para los\n","talleres comenzar√°n en febrero a trav√©s de la web oficial del Ministerio.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"cell-13","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-13","executionInfo":{"status":"ok","timestamp":1761827525991,"user_tz":180,"elapsed":3898,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"4e488f83-2526-4493-97db-7519af2d7fe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["AN√ÅLISIS DE LA NOTICIA:\n","```json\n","{\n","  \"Tema_principal\": \"Apertura de nuevos espacios culturales\",\n","  \"Ubicacion\": \"Buenos Aires, zona sur\",\n","  \"Fecha_evento\": \"marzo de 2024\",\n","  \"Protagonistas\": [\"Ministerio de Cultura\", \"Mar√≠a Rodr√≠guez\"],\n","  \"Datos_numericos\": {\n","    \"inversion\": 450000000,\n","    \"beneficiarios\": 15000\n","  },\n","  \"Categoria\": \"cultura\"\n","}\n","```\n"]}],"source":["prompt_noticia = f\"\"\"\n","Analiza la siguiente noticia y extrae la informaci√≥n clave en formato JSON:\n","\n","- Tema_principal: tema central de la noticia\n","- Ubicacion: d√≥nde ocurre el hecho\n","- Fecha_evento: cu√°ndo ocurrir√° o ocurri√≥\n","- Protagonistas: personas u organizaciones mencionadas\n","- Datos_numericos: cifras relevantes (monto, cantidad de personas, etc.)\n","- Categoria: clasific√° en pol√≠tica, econom√≠a, cultura, sociedad, deportes, tecnolog√≠a\n","\n","Si no hay informaci√≥n, us√° \"no_especificado\".\n","\n","Noticia: ```{noticia}```\n","\n","Devuelve solo el JSON.\n","\"\"\"\n","\n","analisis_noticia = get_completion(prompt_noticia)\n","print(\"AN√ÅLISIS DE LA NOTICIA:\")\n","print(analisis_noticia)"]},{"cell_type":"markdown","id":"cell-14","metadata":{"id":"cell-14"},"source":["## Ejemplo 3: Clasificaci√≥n de Comentarios de Redes Sociales\n","\n","Las redes sociales generan millones de comentarios por d√≠a. Los LLMs pueden ayudarnos a clasificarlos autom√°ticamente seg√∫n diferentes criterios.\n","\n","**Caso de uso**: Moderaci√≥n de contenido, an√°lisis de opini√≥n p√∫blica, detecci√≥n de toxicidad."]},{"cell_type":"code","execution_count":null,"id":"cell-15","metadata":{"id":"cell-15"},"outputs":[],"source":["# Colecci√≥n de comentarios simulados\n","comentarios = [\n","    \"Excelente la nueva temporada! La mejor serie que vi en a√±os üî•\",\n","    \"No entiendo por qu√© le dan tanto hype, es bastante meh\",\n","    \"Alguien sabe d√≥nde puedo conseguir las zapatillas que usa el prota?\",\n","    \"SPOILER: No puedo creer que mataron a ese personaje!!! üò≠\",\n","    \"Qu√© basura, perd√≠ 3 horas de mi vida viendo esto\"\n","]"]},{"cell_type":"code","execution_count":null,"id":"cell-16","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-16","executionInfo":{"status":"ok","timestamp":1761827561980,"user_tz":180,"elapsed":10884,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"b52a6135-916e-42d4-9a57-9de00ffc4b68"},"outputs":[{"output_type":"stream","name":"stdout","text":["CLASIFICACI√ìN DE COMENTARIOS:\n","\n","Comentario 1: Excelente la nueva temporada! La mejor serie que vi en a√±os üî•\n","An√°lisis: ```json\n","{\n","    \"sentimiento\": \"positivo\",\n","    \"tipo\": \"opinion\",\n","    \"toxicidad\": \"baja\"\n","}\n","```\n","--------------------------------------------------------------------------------\n","Comentario 2: No entiendo por qu√© le dan tanto hype, es bastante meh\n","An√°lisis: ```json\n","{\n","    \"sentimiento\": \"negativo\",\n","    \"tipo\": \"opinion\",\n","    \"toxicidad\": \"baja\"\n","}\n","```\n","--------------------------------------------------------------------------------\n","Comentario 3: Alguien sabe d√≥nde puedo conseguir las zapatillas que usa el prota?\n","An√°lisis: ```json\n","{\n","    \"sentimiento\": \"neutral\",\n","    \"tipo\": \"pregunta\",\n","    \"toxicidad\": \"baja\"\n","}\n","```\n","--------------------------------------------------------------------------------\n","Comentario 4: SPOILER: No puedo creer que mataron a ese personaje!!! üò≠\n","An√°lisis: ```json\n","{\n","    \"sentimiento\": \"negativo\",\n","    \"tipo\": \"spoiler\",\n","    \"toxicidad\": \"baja\"\n","}\n","```\n","--------------------------------------------------------------------------------\n","Comentario 5: Qu√© basura, perd√≠ 3 horas de mi vida viendo esto\n","An√°lisis: ```json\n","{\n","    \"sentimiento\": \"negativo\",\n","    \"tipo\": \"opinion\",\n","    \"toxicidad\": \"media\"\n","}\n","```\n","--------------------------------------------------------------------------------\n"]}],"source":["# Procesamos m√∫ltiples comentarios\n","print(\"CLASIFICACI√ìN DE COMENTARIOS:\\n\")\n","\n","for i, comentario in enumerate(comentarios, 1):\n","    prompt_comentario = f\"\"\"\n","    Clasifica este comentario seg√∫n:\n","    - Sentimiento: positivo, negativo o neutral\n","    - Tipo: opinion, pregunta, spoiler, spam, otro\n","    - Toxicidad: baja, media, alta\n","\n","    Comentario: ```{comentario}```\n","\n","    Devuelve solo un JSON con esas tres claves.\n","    \"\"\"\n","\n","    resultado = get_completion(prompt_comentario)\n","    print(f\"Comentario {i}: {comentario}\")\n","    print(f\"An√°lisis: {resultado}\")\n","    print(\"-\" * 80)"]},{"cell_type":"markdown","id":"cell-17","metadata":{"id":"cell-17"},"source":["## Experimentaci√≥n: Prob√° Modificar los Par√°metros\n","\n","Esta secci√≥n est√° dise√±ada para que experimentes con diferentes configuraciones y veas c√≥mo cambian los resultados.\n","\n","### Ejercicio 1: Efecto de la temperatura\n","\n","Ejecut√° la siguiente celda varias veces cambiando el par√°metro `temperature` y observ√° c√≥mo var√≠an las respuestas."]},{"cell_type":"code","execution_count":null,"id":"cell-18","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cell-18","executionInfo":{"status":"ok","timestamp":1761827589224,"user_tz":180,"elapsed":1464,"user":{"displayName":"BARRETO MAT√çAS","userId":"15011433883683359534"}},"outputId":"bf6cbeab-f323-47e9-a1e5-e84b93620f4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Usando temperatura=0.0 y modelo=gpt-4o-mini\n","\n","Resultado:\n","1. El encuentro fue espectacular y se resolvi√≥ en el √∫ltimo instante.\n","2. El juego fue asombroso, y se decidi√≥ en el √∫ltimo minuto.\n","3. El partido fue impresionante, con un desenlace que lleg√≥ en el √∫ltimo segundo.\n"]}],"source":["# Zona de experimentaci√≥n - Modifica estos valores\n","TEMPERATURA = 0.0  # Prob√° con: 0.0, 0.5, 1.0, 1.5\n","MODELO = \"gpt-4o-mini\"  # Prob√° con: \"gpt-4o-mini\", \"gpt-4o\"\n","\n","texto_ejemplo = \"El partido estuvo incre√≠ble, se defini√≥ en el √∫ltimo minuto.\"\n","\n","prompt_exp = f\"\"\"\n","Reescribe este texto de tres formas diferentes manteniendo el significado:\n","{texto_ejemplo}\n","\"\"\"\n","\n","print(f\"Usando temperatura={TEMPERATURA} y modelo={MODELO}\")\n","print(\"\\nResultado:\")\n","print(get_completion(prompt_exp, model=MODELO, temperature=TEMPERATURA))"]},{"cell_type":"markdown","id":"cell-19","metadata":{"id":"cell-19"},"source":["### Ejercicio 2: Tus propios ejemplos\n","\n","Ahora prob√° con tus propios textos. Puede ser:\n","- Un comentario de YouTube\n","- Una review de un producto\n","- Un titular de noticia\n","- Un tweet\n","- Un fragmento de conversaci√≥n\n","\n","Modific√° las variables y experiment√° con diferentes prompts."]},{"cell_type":"code","execution_count":null,"id":"cell-20","metadata":{"id":"cell-20"},"outputs":[],"source":["# TU TURNO: Reemplaza este texto con el que quieras analizar\n","mi_texto = \"\"\"\n","Ac√° pega tu texto para analizar...\n","\"\"\"\n","\n","# Modifica este prompt seg√∫n lo que quieras hacer\n","mi_prompt = f\"\"\"\n","Analiza este texto y decime:\n","1. De qu√© se trata\n","2. Qu√© sentimiento expresa\n","3. Si hay algo interesante o relevante\n","\n","Texto: ```{mi_texto}```\n","\"\"\"\n","\n","print(get_completion(mi_prompt))"]},{"cell_type":"markdown","id":"cell-21","metadata":{"id":"cell-21"},"source":["## Resumen y Conceptos Clave\n","\n","### ¬øQu√© aprendimos?\n","\n","1. **APIs de LLMs**: Interfaces que nos permiten acceder a modelos de lenguaje potentes sin necesidad de entrenarlos nosotros\n","\n","2. **Configuraci√≥n segura**: C√≥mo manejar API keys sin exponerlas en el c√≥digo\n","\n","3. **Funci√≥n wrapper**: `get_completion()` simplifica el uso de la API\n","\n","4. **Par√°metros configurables**:\n","   - `model`: Qu√© modelo usar (calidad vs costo vs velocidad)\n","   - `temperature`: Control de creatividad/determinismo\n","\n","5. **Prompting estructurado**: T√©cnicas para obtener respuestas en formato JSON √∫til\n","\n","6. **Casos de uso reales**: Reviews, noticias, comentarios de redes sociales\n","\n","### T√©cnicas de Prompting Aprendidas\n","\n","- **Instrucciones claras**: Especificar exactamente qu√© queremos\n","- **Formato de salida**: Pedir JSON para procesar program√°ticamente\n","- **Manejo de casos edge**: Indicar qu√© hacer con informaci√≥n faltante\n","- **Delimitadores**: Usar ``` o \"\"\" para marcar el texto a procesar\n","- **Ejemplos espec√≠ficos**: Dar formato de respuesta esperada\n","\n","### Pr√≥ximos pasos\n","\n","En el siguiente cuaderno vamos a profundizar en:\n","- **System prompts**: C√≥mo definir el comportamiento del asistente\n","- **Conversaciones multi-turno**: Mantener contexto entre mensajes\n","- **Roles**: Diferencia entre system, user y assistant"]},{"cell_type":"markdown","id":"cell-22","metadata":{"id":"cell-22"},"source":["## Glosario\n","\n","**API (Application Programming Interface)**: Conjunto de definiciones y protocolos que permite que dos sistemas se comuniquen\n","\n","**LLM (Large Language Model)**: Modelo de lenguaje entrenado con grandes cantidades de texto que puede generar, analizar y transformar texto\n","\n","**Prompt**: Instrucci√≥n o pregunta que le damos al modelo de lenguaje\n","\n","**Temperature**: Par√°metro que controla la aleatoriedad de las respuestas (0=determin√≠stico, 2=muy creativo)\n","\n","**Token**: Unidad b√°sica de procesamiento de texto (aproximadamente 0.75 palabras en espa√±ol)\n","\n","**JSON**: Formato de intercambio de datos estructurado, f√°cil de leer para humanos y m√°quinas\n","\n","**Endpoint**: URL espec√≠fica de una API donde enviamos nuestros requests\n","\n","**Request**: Petici√≥n que hacemos a la API con nuestro prompt\n","\n","**Response**: Respuesta que recibimos de la API despu√©s de procesar nuestro request"]},{"cell_type":"markdown","id":"cell-23","metadata":{"id":"cell-23"},"source":["## Preguntas Frecuentes\n","\n","**P: ¬øPor qu√© usar temperature=0 en algunos casos?**\n","\n","R: Cuando necesitamos respuestas consistentes y determin√≠sticas, especialmente para extracci√≥n de datos estructurados. Con temperature=0, el modelo siempre va a dar la misma respuesta para el mismo prompt.\n","\n","---\n","\n","**P: ¬øCu√°nto cuesta usar la API de OpenAI?**\n","\n","R: Depende del modelo. GPT-4o-mini es el m√°s econ√≥mico (~$0.15 por mill√≥n de tokens de entrada). Para este curso, $5 USD es m√°s que suficiente.\n","\n","---\n","\n","**P: ¬øQu√© pasa si mi API key se vence o me quedo sin cr√©dito?**\n","\n","R: La API va a devolver un error. Podes cargar m√°s cr√©dito en tu cuenta de OpenAI o esperar a que se renueve si ten√©s un plan de subscripci√≥n.\n","\n","---\n","\n","**P: ¬øPuedo usar estos modelos sin conexi√≥n a internet?**\n","\n","R: No, la API de OpenAI requiere conexi√≥n. Sin embargo, en clases posteriores vamos a ver Ollama, que permite ejecutar modelos localmente.\n","\n","---\n","\n","**P: ¬øEl modelo tiene acceso a internet o a informaci√≥n actualizada?**\n","\n","R: No, el modelo solo tiene conocimiento hasta su fecha de entrenamiento (t√≠picamente varios meses atr√°s). En el √∫ltimo cuaderno del m√≥dulo veremos c√≥mo darle acceso a informaci√≥n actualizada mediante b√∫squeda web."]},{"cell_type":"markdown","id":"cell-24","metadata":{"id":"cell-24"},"source":["## Referencias y Recursos Adicionales\n","\n","**Documentaci√≥n oficial**:\n","- OpenAI API Documentation: https://platform.openai.com/docs\n","- Gu√≠a de modelos: https://platform.openai.com/docs/models\n","- Pricing: https://openai.com/pricing\n","\n","**Recursos recomendados**:\n","- Curso de DeepLearning.AI sobre Prompt Engineering (gratuito)\n","- OpenAI Cookbook: Ejemplos pr√°cticos en GitHub\n","- Comunidad de OpenAI en Discord\n","\n","**Papers relevantes**:\n","- \"Language Models are Few-Shot Learners\" (GPT-3)\n","- \"Training language models to follow instructions\" (InstructGPT)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}