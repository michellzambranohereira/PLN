{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "23026057",
      "metadata": {
        "id": "23026057"
      },
      "source": [
        "# Ejercicios embeddings de oraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a1e365e",
      "metadata": {
        "id": "4a1e365e"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!pip install scikit-learn\n",
        "!python -m spacy download es_core_news_md"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b960b83e",
      "metadata": {
        "id": "b960b83e"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "Desarrolla una función que tome dos argumentos: una oración objetivo y una lista de oraciones. Esta función debe calcular y devolver la oración de la lista que es más similar a la oración objetivo, basándose en la medida de la similitud coseno. Además, la función también debe retornar el puntaje de similitud obtenido por esta oración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc14d42f",
      "metadata": {
        "id": "bc14d42f"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Cargar el modelo de lenguaje en español\n",
        "nlp = spacy.load('es_core_news_md')\n",
        "\n",
        "def encontrar_frase_similar(frase_objetivo, lista_de_frases):\n",
        "    # Crear un embedding para la frase objetivo\n",
        "    objetivo_embedding = nlp(frase_objetivo)\n",
        "\n",
        "    mayor_similitud = -1\n",
        "    frase_similar = None\n",
        "\n",
        "    # Iterar sobre todas las frases en la lista\n",
        "    for frase in lista_de_frases:\n",
        "        # Crear un embedding para la frase actual\n",
        "        frase_embedding = nlp(frase)\n",
        "\n",
        "        # Calcular la similitud coseno entre la frase objetivo y la frase actual\n",
        "        similitud = objetivo_embedding.similarity(frase_embedding)\n",
        "\n",
        "        # Si la similitud es mayor que la similitud más alta encontrada hasta ahora,\n",
        "        # actualizamos la similitud más alta y la frase más similar\n",
        "        if similitud > mayor_similitud:\n",
        "            mayor_similitud = similitud\n",
        "            frase_similar = frase\n",
        "\n",
        "    # Devolver la frase más similar y su similitud con la frase objetivo\n",
        "    return frase_similar, mayor_similitud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0de9564",
      "metadata": {
        "id": "e0de9564"
      },
      "outputs": [],
      "source": [
        "encontrar_frase_similar('amo el helado de chocolate', ['amo el helado de vainilla', 'amo la ensalada de pepino'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "440e631b",
      "metadata": {
        "id": "440e631b"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Desarrolla la misma funcion, pero esta vez utilizando TF-IDF en lugar de Spacy para crear los vectores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eeb8f6f",
      "metadata": {
        "id": "6eeb8f6f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def encontrar_frase_similar_tfidf(frase_objetivo, lista_de_frases_input):\n",
        "    # Incluir la frase objetivo en la lista de frases\n",
        "    lista_de_frases = lista_de_frases_input.copy()\n",
        "    lista_de_frases.append(frase_objetivo)\n",
        "\n",
        "    # Crear el TfidfVectorizer y transformar la lista de frases\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(lista_de_frases)\n",
        "\n",
        "    # Calcular la similitud coseno entre la frase objetivo (la última en la matriz)\n",
        "    # y todas las demás frases\n",
        "    similitudes = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix)\n",
        "\n",
        "    # Obtener el índice de la frase con la mayor similitud (excluyendo la última)\n",
        "    indice_similar = similitudes.argsort()[0][-2]\n",
        "\n",
        "    # Normalizar el puntaje de similitud a que esté entre 0 y 1\n",
        "    puntaje_similar = similitudes[0, indice_similar]\n",
        "\n",
        "    # Devolver la frase más similar y su puntaje de similitud\n",
        "    return lista_de_frases[indice_similar], puntaje_similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573760f2",
      "metadata": {
        "id": "573760f2"
      },
      "outputs": [],
      "source": [
        "encontrar_frase_similar_tfidf('amo el helado de chocolate', ['amo el helado de vainilla', 'amo la ensalada de pepino'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64638f45",
      "metadata": {
        "id": "64638f45"
      },
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Prueba ambas funciones con el siguiente dataset. Encuentras una diferencia en el rendimiento? A qué se debe? Cuándo sería mejor utilizar una respecto a otra?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4275a0",
      "metadata": {
        "id": "6c4275a0"
      },
      "outputs": [],
      "source": [
        "oracion_objetivo = \"Me gusta mucho el fútbol, mi equipo favorito es River Plate.\"\n",
        "\n",
        "dataset = [\"A él también le gusta mucho el fútbol, siempre lo está viendo.\",\n",
        "            \"El deporte favorito de María es el baloncesto, y su equipo es River Plate.\",\n",
        "            \"El fútbol es un deporte muy popular en el mundo.\",\n",
        "            \"Nunca he entendido por qué a la gente le gusta tanto el fútbol.\",\n",
        "            \"El helado de vainilla es mi sabor favorito.\",\n",
        "            \"Estoy aprendiendo a tocar la guitarra.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mRreVywu58Vi",
      "metadata": {
        "id": "mRreVywu58Vi"
      },
      "outputs": [],
      "source": [
        "encontrar_frase_similar_tfidf(oracion_objetivo, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HgrVYe7j5-y-",
      "metadata": {
        "id": "HgrVYe7j5-y-"
      },
      "outputs": [],
      "source": [
        "encontrar_frase_similar(oracion_objetivo, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ekyivr7obt9",
      "source": [
        "# GUÍA DE ESTUDIO - EJERCICIOS DE SIMILITUD\n",
        "\n",
        "## Preguntas y Respuestas Clave\n",
        "\n",
        "### **Comparación de Enfoques**\n",
        "\n",
        "**P: ¿Cuál es la diferencia principal entre spaCy y TF-IDF para similitud de oraciones?**  \n",
        "R: spaCy usa embeddings pre-entrenados que capturan semántica global. TF-IDF solo considera frecuencia de palabras exactas sin contexto semántico.\n",
        "\n",
        "**P: ¿Por qué spaCy puede encontrar similitud entre sinónimos?**  \n",
        "R: Sus embeddings están entrenados para que palabras con significados similares tengan vectores cercanos, mientras que TF-IDF trata \"coche\" y \"auto\" como completamente diferentes.\n",
        "\n",
        "**P: ¿En qué casos TF-IDF podría superar a spaCy?**  \n",
        "R: Cuando necesitas similitud lexical exacta, tienes vocabulario muy específico del dominio, o cuando las palabras clave literales son más importantes que el significado.\n",
        "\n",
        "### **Implementación Técnica**\n",
        "\n",
        "**P: ¿Por qué en TF-IDF agregamos la oración objetivo a la lista?**  \n",
        "R: Para que el vectorizador aprenda el vocabulario completo y pueda comparar todas las oraciones en el mismo espacio vectorial.\n",
        "\n",
        "**P: ¿Qué hace `argsort()[0][-2]` en la función TF-IDF?**  \n",
        "R: Obtiene el índice del segundo valor más alto de similitud (excluye la oración objetivo que sería la más similar a sí misma).\n",
        "\n",
        "**P: ¿Cómo procesa spaCy una oración completa?**  \n",
        "R: Combina los embeddings de palabras individuales (típicamente promediando) para crear un vector representativo de toda la oración.\n",
        "\n",
        "### **Análisis de Rendimiento**\n",
        "\n",
        "**P: ¿Qué patrón observas en el dataset de fútbol entre ambos métodos?**  \n",
        "R: spaCy encuentra mejor similitud semántica profunda. TF-IDF se enfoca en palabras compartidas literalmente (\"fútbol\", \"River Plate\").\n",
        "\n",
        "**P: ¿Cuándo usarías cada método en una aplicación real?**  \n",
        "R: spaCy para chatbots, búsqueda semántica, recomendaciones. TF-IDF para búsqueda de documentos, keywords matching, clasificación por temas específicos.\n",
        "\n",
        "### **Casos de Uso Prácticos**\n",
        "\n",
        "**P: ¿Cómo mejorarías la función de spaCy para mayor precisión?**  \n",
        "R: Usar modelos más grandes (es_core_news_lg), preprocesar texto, considerar pesos por importancia de palabras, o usar embeddings especializados del dominio.\n",
        "\n",
        "**P: ¿Qué limitaciones tiene cada approach?**  \n",
        "R: spaCy: dependiente del modelo pre-entrenado, puede perder especificidad del dominio. TF-IDF: ignora semántica, sensible al vocabulario exacto.\n",
        "\n",
        "## Puntos Clave para Recordar\n",
        "\n",
        "1. **spaCy = semántica global** vs **TF-IDF = frecuencia local**\n",
        "2. **Embeddings capturan significado** más allá de palabras exactas\n",
        "3. **TF-IDF mejor para matching literal** y vocabulario específico\n",
        "4. **Preprocessing afecta ambos métodos** pero diferentemente\n",
        "5. **Elección depende del caso de uso** específico\n",
        "6. **Combinar ambos approaches** puede ser óptimo en algunos casos\n",
        "\n",
        "## Consideraciones Importantes\n",
        "\n",
        "- spaCy requiere modelos pre-descargados y más memoria\n",
        "- TF-IDF es más rápido y liviano pero menos \"inteligente\"\n",
        "- La calidad del modelo spaCy afecta directamente resultados\n",
        "- TF-IDF puede funcionar mejor con preprocesamiento agresivo\n",
        "- Ambos son sensibles a la longitud de las oraciones\n",
        "\n",
        "## Conexión con Próxima Clase\n",
        "\n",
        "Estas técnicas de similitud son la base para **aplicaciones avanzadas**: sistemas de recomendación, búsqueda semántica, y extracción de información estructurada de textos.\n",
        "\n",
        "---\n",
        "*Consejo: Prueba ambos métodos con tus propias oraciones en español argentino. ¿Cuál maneja mejor lunfardo y referencias culturales locales?*"
      ],
      "metadata": {
        "id": "ekyivr7obt9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_humai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}